start all test
start bs8
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.1', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.1, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=8, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.1/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.1/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 5.380 (5.380)	Data 4.638 (4.638)	
[2/123]	Time 0.021 (2.700)	Data 0.000 (2.319)	
[3/123]	Time 0.016 (1.806)	Data 0.000 (1.546)	
[4/123]	Time 0.019 (1.359)	Data 0.002 (1.160)	
[5/123]	Time 0.017 (1.090)	Data 0.000 (0.928)	
[6/123]	Time 0.020 (0.912)	Data 0.002 (0.774)	
[7/123]	Time 0.018 (0.784)	Data 0.000 (0.663)	
[8/123]	Time 0.019 (0.689)	Data 0.002 (0.581)	
[9/123]	Time 0.019 (0.614)	Data 0.000 (0.516)	
[10/123]	Time 0.018 (0.555)	Data 0.002 (0.465)	
[11/123]	Time 0.017 (0.506)	Data 0.001 (0.423)	
[12/123]	Time 0.020 (0.465)	Data 0.002 (0.387)	
[13/123]	Time 0.033 (0.432)	Data 0.001 (0.358)	
[14/123]	Time 0.042 (0.404)	Data 0.008 (0.333)	
[15/123]	Time 0.031 (0.379)	Data 0.001 (0.311)	
[16/123]	Time 0.033 (0.358)	Data 0.005 (0.292)	
[17/123]	Time 0.044 (0.339)	Data 0.004 (0.275)	
[18/123]	Time 0.028 (0.322)	Data 0.003 (0.259)	
[19/123]	Time 0.050 (0.308)	Data 0.007 (0.246)	
[20/123]	Time 0.025 (0.293)	Data 0.003 (0.234)	
[21/123]	Time 0.049 (0.282)	Data 0.002 (0.223)	
[22/123]	Time 0.027 (0.270)	Data 0.005 (0.213)	
[23/123]	Time 0.019 (0.259)	Data 0.001 (0.204)	
[24/123]	Time 0.042 (0.250)	Data 0.010 (0.196)	
[25/123]	Time 0.036 (0.242)	Data 0.001 (0.188)	
[26/123]	Time 0.033 (0.234)	Data 0.003 (0.181)	
[27/123]	Time 0.018 (0.226)	Data 0.002 (0.174)	
[28/123]	Time 0.027 (0.219)	Data 0.010 (0.168)	
[29/123]	Time 0.044 (0.213)	Data 0.005 (0.163)	
[30/123]	Time 0.036 (0.207)	Data 0.015 (0.158)	
[31/123]	Time 0.021 (0.201)	Data 0.003 (0.153)	
[32/123]	Time 0.041 (0.196)	Data 0.015 (0.148)	
[33/123]	Time 0.019 (0.190)	Data 0.001 (0.144)	
[34/123]	Time 0.886 (0.211)	Data 0.857 (0.165)	
[35/123]	Time 0.245 (0.212)	Data 0.220 (0.167)	
[36/123]	Time 0.026 (0.207)	Data 0.001 (0.162)	
[37/123]	Time 0.135 (0.205)	Data 0.110 (0.161)	
[38/123]	Time 0.276 (0.207)	Data 0.260 (0.163)	
[39/123]	Time 0.079 (0.203)	Data 0.047 (0.160)	
[40/123]	Time 0.027 (0.199)	Data 0.000 (0.156)	
[41/123]	Time 0.022 (0.195)	Data 0.005 (0.152)	
[42/123]	Time 0.020 (0.190)	Data 0.002 (0.149)	
[43/123]	Time 0.024 (0.187)	Data 0.004 (0.146)	
[44/123]	Time 0.020 (0.183)	Data 0.005 (0.142)	
[45/123]	Time 0.034 (0.179)	Data 0.001 (0.139)	
[46/123]	Time 0.082 (0.177)	Data 0.066 (0.138)	
[47/123]	Time 0.057 (0.175)	Data 0.003 (0.135)	
[48/123]	Time 0.049 (0.172)	Data 0.017 (0.132)	
[49/123]	Time 0.017 (0.169)	Data 0.001 (0.130)	
[50/123]	Time 0.607 (0.178)	Data 0.585 (0.139)	
[51/123]	Time 0.293 (0.180)	Data 0.268 (0.141)	
[52/123]	Time 0.027 (0.177)	Data 0.001 (0.139)	
[53/123]	Time 0.232 (0.178)	Data 0.216 (0.140)	
[54/123]	Time 0.048 (0.176)	Data 0.011 (0.138)	
[55/123]	Time 0.176 (0.176)	Data 0.160 (0.138)	
[56/123]	Time 0.046 (0.173)	Data 0.013 (0.136)	
[57/123]	Time 0.041 (0.171)	Data 0.016 (0.134)	
[58/123]	Time 0.049 (0.169)	Data 0.004 (0.131)	
[59/123]	Time 0.035 (0.167)	Data 0.006 (0.129)	
[60/123]	Time 0.017 (0.164)	Data 0.001 (0.127)	
[61/123]	Time 0.029 (0.162)	Data 0.004 (0.125)	
[62/123]	Time 0.065 (0.160)	Data 0.026 (0.124)	
[63/123]	Time 0.038 (0.158)	Data 0.003 (0.122)	
[64/123]	Time 0.109 (0.158)	Data 0.077 (0.121)	
[65/123]	Time 0.078 (0.156)	Data 0.033 (0.120)	
[66/123]	Time 0.560 (0.163)	Data 0.542 (0.126)	
[67/123]	Time 0.367 (0.166)	Data 0.351 (0.129)	
[68/123]	Time 0.028 (0.164)	Data 0.003 (0.127)	
[69/123]	Time 0.123 (0.163)	Data 0.106 (0.127)	
[70/123]	Time 0.042 (0.161)	Data 0.012 (0.126)	
[71/123]	Time 0.439 (0.165)	Data 0.423 (0.130)	
[72/123]	Time 0.032 (0.163)	Data 0.002 (0.128)	
[73/123]	Time 0.027 (0.161)	Data 0.001 (0.126)	
[74/123]	Time 0.030 (0.160)	Data 0.002 (0.125)	
[75/123]	Time 0.020 (0.158)	Data 0.003 (0.123)	
[76/123]	Time 0.021 (0.156)	Data 0.002 (0.121)	
[77/123]	Time 0.017 (0.154)	Data 0.001 (0.120)	
[78/123]	Time 0.024 (0.153)	Data 0.004 (0.118)	
[79/123]	Time 0.017 (0.151)	Data 0.001 (0.117)	
[80/123]	Time 0.021 (0.149)	Data 0.002 (0.115)	
[81/123]	Time 0.031 (0.148)	Data 0.005 (0.114)	
[82/123]	Time 0.446 (0.151)	Data 0.425 (0.118)	
[83/123]	Time 0.199 (0.152)	Data 0.164 (0.118)	
[84/123]	Time 0.214 (0.153)	Data 0.179 (0.119)	
[85/123]	Time 0.213 (0.153)	Data 0.178 (0.120)	
[86/123]	Time 0.048 (0.152)	Data 0.001 (0.118)	
[87/123]	Time 0.335 (0.154)	Data 0.318 (0.121)	
[88/123]	Time 0.037 (0.153)	Data 0.009 (0.119)	
[89/123]	Time 0.037 (0.152)	Data 0.011 (0.118)	
[90/123]	Time 0.029 (0.150)	Data 0.001 (0.117)	
[91/123]	Time 0.060 (0.149)	Data 0.003 (0.116)	
[92/123]	Time 0.026 (0.148)	Data 0.000 (0.114)	
[93/123]	Time 0.018 (0.147)	Data 0.001 (0.113)	
[94/123]	Time 0.021 (0.145)	Data 0.001 (0.112)	
[95/123]	Time 0.027 (0.144)	Data 0.001 (0.111)	
[96/123]	Time 0.018 (0.143)	Data 0.001 (0.110)	
[97/123]	Time 0.023 (0.141)	Data 0.003 (0.109)	
[98/123]	Time 0.515 (0.145)	Data 0.499 (0.113)	
[99/123]	Time 0.129 (0.145)	Data 0.110 (0.112)	
[100/123]	Time 0.166 (0.145)	Data 0.145 (0.113)	
[101/123]	Time 0.237 (0.146)	Data 0.203 (0.114)	
[102/123]	Time 0.152 (0.146)	Data 0.127 (0.114)	
[103/123]	Time 0.079 (0.146)	Data 0.063 (0.113)	
[104/123]	Time 0.021 (0.144)	Data 0.003 (0.112)	
[105/123]	Time 0.022 (0.143)	Data 0.001 (0.111)	
[106/123]	Time 0.018 (0.142)	Data 0.001 (0.110)	
[107/123]	Time 0.017 (0.141)	Data 0.000 (0.109)	
[108/123]	Time 0.021 (0.140)	Data 0.004 (0.108)	
[109/123]	Time 0.017 (0.139)	Data 0.000 (0.107)	
[110/123]	Time 0.020 (0.138)	Data 0.001 (0.106)	
[111/123]	Time 0.016 (0.136)	Data 0.000 (0.105)	
[112/123]	Time 0.019 (0.135)	Data 0.001 (0.104)	
[113/123]	Time 0.016 (0.134)	Data 0.000 (0.103)	
[114/123]	Time 0.396 (0.137)	Data 0.380 (0.106)	
[115/123]	Time 0.045 (0.136)	Data 0.028 (0.105)	
[116/123]	Time 0.018 (0.135)	Data 0.001 (0.104)	
[117/123]	Time 0.093 (0.134)	Data 0.079 (0.104)	
[118/123]	Time 0.039 (0.134)	Data 0.026 (0.103)	
[119/123]	Time 0.054 (0.133)	Data 0.041 (0.103)	
[120/123]	Time 0.013 (0.132)	Data 0.000 (0.102)	
[121/123]	Time 0.013 (0.131)	Data 0.000 (0.101)	
[122/123]	Time 0.013 (0.130)	Data 0.000 (0.100)	
[123/123]	Time 0.014 (0.129)	Data 0.000 (0.100)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.1', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.1, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=8, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.1/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.1/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.561 (4.561)	Data 3.717 (3.717)	
[2/123]	Time 0.025 (2.293)	Data 0.001 (1.859)	
[3/123]	Time 0.018 (1.535)	Data 0.001 (1.239)	
[4/123]	Time 0.019 (1.156)	Data 0.000 (0.930)	
[5/123]	Time 0.023 (0.929)	Data 0.001 (0.744)	
[6/123]	Time 0.028 (0.779)	Data 0.001 (0.620)	
[7/123]	Time 0.297 (0.710)	Data 0.268 (0.570)	
[8/123]	Time 0.033 (0.626)	Data 0.000 (0.499)	
[9/123]	Time 0.031 (0.559)	Data 0.001 (0.443)	
[10/123]	Time 0.026 (0.506)	Data 0.001 (0.399)	
[11/123]	Time 0.034 (0.463)	Data 0.001 (0.363)	
[12/123]	Time 0.056 (0.429)	Data 0.010 (0.333)	
[13/123]	Time 0.054 (0.400)	Data 0.001 (0.308)	
[14/123]	Time 0.055 (0.376)	Data 0.015 (0.287)	
[15/123]	Time 0.055 (0.354)	Data 0.017 (0.269)	
[16/123]	Time 0.071 (0.337)	Data 0.007 (0.252)	
[17/123]	Time 0.086 (0.322)	Data 0.012 (0.238)	
[18/123]	Time 0.057 (0.307)	Data 0.001 (0.225)	
[19/123]	Time 0.081 (0.295)	Data 0.014 (0.214)	
[20/123]	Time 0.051 (0.283)	Data 0.001 (0.203)	
[21/123]	Time 0.061 (0.273)	Data 0.001 (0.194)	
[22/123]	Time 0.107 (0.265)	Data 0.012 (0.185)	
[23/123]	Time 0.071 (0.257)	Data 0.001 (0.177)	
[24/123]	Time 0.057 (0.248)	Data 0.011 (0.171)	
[25/123]	Time 0.038 (0.240)	Data 0.001 (0.164)	
[26/123]	Time 0.040 (0.232)	Data 0.001 (0.157)	
[27/123]	Time 0.039 (0.225)	Data 0.001 (0.152)	
[28/123]	Time 0.038 (0.218)	Data 0.001 (0.146)	
[29/123]	Time 0.056 (0.213)	Data 0.001 (0.141)	
[30/123]	Time 0.036 (0.207)	Data 0.001 (0.137)	
[31/123]	Time 0.051 (0.202)	Data 0.014 (0.133)	
[32/123]	Time 0.041 (0.197)	Data 0.000 (0.128)	
[33/123]	Time 0.062 (0.193)	Data 0.016 (0.125)	
[34/123]	Time 0.071 (0.189)	Data 0.017 (0.122)	
[35/123]	Time 0.060 (0.185)	Data 0.011 (0.119)	
[36/123]	Time 0.048 (0.182)	Data 0.001 (0.115)	
[37/123]	Time 0.037 (0.178)	Data 0.001 (0.112)	
[38/123]	Time 0.058 (0.175)	Data 0.007 (0.110)	
[39/123]	Time 0.155 (0.174)	Data 0.108 (0.110)	
[40/123]	Time 0.917 (0.193)	Data 0.864 (0.128)	
[41/123]	Time 0.096 (0.190)	Data 0.015 (0.126)	
[42/123]	Time 0.064 (0.187)	Data 0.013 (0.123)	
[43/123]	Time 0.051 (0.184)	Data 0.001 (0.120)	
[44/123]	Time 0.088 (0.182)	Data 0.023 (0.118)	
[45/123]	Time 0.046 (0.179)	Data 0.001 (0.115)	
[46/123]	Time 0.055 (0.176)	Data 0.013 (0.113)	
[47/123]	Time 0.056 (0.174)	Data 0.014 (0.111)	
[48/123]	Time 0.056 (0.171)	Data 0.011 (0.109)	
[49/123]	Time 0.094 (0.170)	Data 0.017 (0.107)	
[50/123]	Time 0.055 (0.167)	Data 0.001 (0.105)	
[51/123]	Time 0.092 (0.166)	Data 0.017 (0.103)	
[52/123]	Time 0.052 (0.164)	Data 0.001 (0.101)	
[53/123]	Time 0.050 (0.162)	Data 0.008 (0.099)	
[54/123]	Time 0.075 (0.160)	Data 0.015 (0.098)	
[55/123]	Time 0.044 (0.158)	Data 0.001 (0.096)	
[56/123]	Time 1.070 (0.174)	Data 1.027 (0.113)	
[57/123]	Time 0.042 (0.172)	Data 0.001 (0.111)	
[58/123]	Time 0.101 (0.171)	Data 0.032 (0.109)	
[59/123]	Time 0.037 (0.168)	Data 0.000 (0.108)	
[60/123]	Time 0.055 (0.166)	Data 0.010 (0.106)	
[61/123]	Time 0.041 (0.164)	Data 0.001 (0.104)	
[62/123]	Time 0.048 (0.163)	Data 0.001 (0.103)	
[63/123]	Time 0.065 (0.161)	Data 0.005 (0.101)	
[64/123]	Time 0.058 (0.159)	Data 0.017 (0.100)	
[65/123]	Time 0.043 (0.158)	Data 0.001 (0.098)	
[66/123]	Time 0.047 (0.156)	Data 0.010 (0.097)	
[67/123]	Time 0.043 (0.154)	Data 0.001 (0.095)	
[68/123]	Time 0.072 (0.153)	Data 0.011 (0.094)	
[69/123]	Time 0.057 (0.152)	Data 0.013 (0.093)	
[70/123]	Time 0.070 (0.150)	Data 0.007 (0.092)	
[71/123]	Time 0.044 (0.149)	Data 0.001 (0.090)	
[72/123]	Time 0.692 (0.156)	Data 0.663 (0.098)	
[73/123]	Time 0.085 (0.156)	Data 0.022 (0.097)	
[74/123]	Time 0.091 (0.155)	Data 0.032 (0.096)	
[75/123]	Time 0.083 (0.154)	Data 0.016 (0.095)	
[76/123]	Time 0.068 (0.153)	Data 0.011 (0.094)	
[77/123]	Time 0.048 (0.151)	Data 0.001 (0.093)	
[78/123]	Time 0.057 (0.150)	Data 0.012 (0.092)	
[79/123]	Time 0.067 (0.149)	Data 0.014 (0.091)	
[80/123]	Time 0.060 (0.148)	Data 0.012 (0.090)	
[81/123]	Time 0.073 (0.147)	Data 0.012 (0.089)	
[82/123]	Time 0.060 (0.146)	Data 0.001 (0.088)	
[83/123]	Time 0.052 (0.145)	Data 0.001 (0.087)	
[84/123]	Time 0.079 (0.144)	Data 0.017 (0.086)	
[85/123]	Time 0.057 (0.143)	Data 0.013 (0.085)	
[86/123]	Time 0.036 (0.142)	Data 0.012 (0.084)	
[87/123]	Time 0.054 (0.141)	Data 0.016 (0.084)	
[88/123]	Time 0.811 (0.148)	Data 0.765 (0.091)	
[89/123]	Time 0.068 (0.147)	Data 0.011 (0.090)	
[90/123]	Time 0.043 (0.146)	Data 0.000 (0.089)	
[91/123]	Time 0.065 (0.145)	Data 0.016 (0.089)	
[92/123]	Time 0.040 (0.144)	Data 0.000 (0.088)	
[93/123]	Time 0.063 (0.143)	Data 0.000 (0.087)	
[94/123]	Time 0.062 (0.142)	Data 0.001 (0.086)	
[95/123]	Time 0.064 (0.142)	Data 0.001 (0.085)	
[96/123]	Time 0.064 (0.141)	Data 0.001 (0.084)	
[97/123]	Time 0.043 (0.140)	Data 0.000 (0.083)	
[98/123]	Time 0.052 (0.139)	Data 0.000 (0.082)	
[99/123]	Time 0.056 (0.138)	Data 0.001 (0.082)	
[100/123]	Time 0.033 (0.137)	Data 0.001 (0.081)	
[101/123]	Time 0.042 (0.136)	Data 0.001 (0.080)	
[102/123]	Time 0.028 (0.135)	Data 0.001 (0.079)	
[103/123]	Time 0.018 (0.134)	Data 0.000 (0.078)	
[104/123]	Time 0.240 (0.135)	Data 0.213 (0.080)	
[105/123]	Time 0.018 (0.134)	Data 0.000 (0.079)	
[106/123]	Time 0.025 (0.133)	Data 0.000 (0.078)	
[107/123]	Time 0.018 (0.132)	Data 0.000 (0.077)	
[108/123]	Time 0.018 (0.131)	Data 0.000 (0.077)	
[109/123]	Time 0.018 (0.130)	Data 0.000 (0.076)	
[110/123]	Time 0.021 (0.129)	Data 0.000 (0.075)	
[111/123]	Time 0.027 (0.128)	Data 0.010 (0.075)	
[112/123]	Time 0.017 (0.127)	Data 0.000 (0.074)	
[113/123]	Time 0.017 (0.126)	Data 0.000 (0.073)	
[114/123]	Time 0.016 (0.125)	Data 0.000 (0.073)	
[115/123]	Time 0.016 (0.124)	Data 0.000 (0.072)	
[116/123]	Time 0.016 (0.123)	Data 0.000 (0.072)	
[117/123]	Time 0.016 (0.122)	Data 0.000 (0.071)	
[118/123]	Time 0.016 (0.121)	Data 0.000 (0.070)	
[119/123]	Time 0.016 (0.120)	Data 0.000 (0.070)	
[120/123]	Time 0.196 (0.121)	Data 0.180 (0.071)	
[121/123]	Time 0.016 (0.120)	Data 0.000 (0.070)	
[122/123]	Time 0.016 (0.119)	Data 0.000 (0.070)	
[123/123]	Time 0.016 (0.118)	Data 0.000 (0.069)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.01', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.01, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=8, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.01/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.01/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.245 (4.245)	Data 3.090 (3.090)	
[2/123]	Time 0.014 (2.130)	Data 0.001 (1.545)	
[3/123]	Time 0.266 (1.508)	Data 0.252 (1.114)	
[4/123]	Time 0.014 (1.135)	Data 0.000 (0.836)	
[5/123]	Time 0.015 (0.911)	Data 0.001 (0.669)	
[6/123]	Time 0.014 (0.761)	Data 0.001 (0.557)	
[7/123]	Time 0.015 (0.655)	Data 0.001 (0.478)	
[8/123]	Time 0.016 (0.575)	Data 0.000 (0.418)	
[9/123]	Time 0.016 (0.513)	Data 0.001 (0.372)	
[10/123]	Time 0.016 (0.463)	Data 0.001 (0.335)	
[11/123]	Time 0.015 (0.422)	Data 0.001 (0.304)	
[12/123]	Time 0.015 (0.388)	Data 0.001 (0.279)	
[13/123]	Time 0.014 (0.360)	Data 0.001 (0.258)	
[14/123]	Time 0.017 (0.335)	Data 0.001 (0.239)	
[15/123]	Time 0.029 (0.315)	Data 0.015 (0.224)	
[16/123]	Time 0.028 (0.297)	Data 0.014 (0.211)	
[17/123]	Time 0.071 (0.283)	Data 0.024 (0.200)	
[18/123]	Time 0.147 (0.276)	Data 0.133 (0.196)	
[19/123]	Time 0.542 (0.290)	Data 0.524 (0.214)	
[20/123]	Time 0.063 (0.279)	Data 0.012 (0.204)	
[21/123]	Time 0.015 (0.266)	Data 0.001 (0.194)	
[22/123]	Time 0.034 (0.255)	Data 0.013 (0.186)	
[23/123]	Time 0.021 (0.245)	Data 0.001 (0.178)	
[24/123]	Time 0.028 (0.236)	Data 0.013 (0.171)	
[25/123]	Time 0.030 (0.228)	Data 0.007 (0.164)	
[26/123]	Time 0.033 (0.220)	Data 0.009 (0.158)	
[27/123]	Time 0.019 (0.213)	Data 0.005 (0.153)	
[28/123]	Time 0.030 (0.206)	Data 0.016 (0.148)	
[29/123]	Time 0.043 (0.201)	Data 0.017 (0.143)	
[30/123]	Time 0.017 (0.195)	Data 0.001 (0.138)	
[31/123]	Time 0.018 (0.189)	Data 0.001 (0.134)	
[32/123]	Time 0.015 (0.184)	Data 0.001 (0.130)	
[33/123]	Time 0.017 (0.178)	Data 0.000 (0.126)	
[34/123]	Time 0.015 (0.174)	Data 0.001 (0.122)	
[35/123]	Time 0.298 (0.177)	Data 0.276 (0.127)	
[36/123]	Time 0.166 (0.177)	Data 0.152 (0.127)	
[37/123]	Time 0.027 (0.173)	Data 0.013 (0.124)	
[38/123]	Time 0.301 (0.176)	Data 0.282 (0.128)	
[39/123]	Time 0.046 (0.173)	Data 0.011 (0.125)	
[40/123]	Time 0.057 (0.170)	Data 0.006 (0.122)	
[41/123]	Time 0.031 (0.167)	Data 0.001 (0.119)	
[42/123]	Time 0.032 (0.163)	Data 0.001 (0.117)	
[43/123]	Time 0.016 (0.160)	Data 0.000 (0.114)	
[44/123]	Time 0.031 (0.157)	Data 0.016 (0.112)	
[45/123]	Time 0.150 (0.157)	Data 0.135 (0.112)	
[46/123]	Time 0.030 (0.154)	Data 0.016 (0.110)	
[47/123]	Time 0.032 (0.152)	Data 0.017 (0.108)	
[48/123]	Time 0.028 (0.149)	Data 0.014 (0.106)	
[49/123]	Time 0.032 (0.147)	Data 0.017 (0.104)	
[50/123]	Time 0.024 (0.144)	Data 0.010 (0.102)	
[51/123]	Time 0.037 (0.142)	Data 0.022 (0.101)	
[52/123]	Time 0.261 (0.144)	Data 0.231 (0.103)	
[53/123]	Time 0.032 (0.142)	Data 0.001 (0.101)	
[54/123]	Time 0.624 (0.151)	Data 0.595 (0.111)	
[55/123]	Time 0.019 (0.149)	Data 0.001 (0.109)	
[56/123]	Time 0.032 (0.147)	Data 0.005 (0.107)	
[57/123]	Time 0.023 (0.144)	Data 0.007 (0.105)	
[58/123]	Time 0.040 (0.143)	Data 0.026 (0.104)	
[59/123]	Time 0.021 (0.141)	Data 0.006 (0.102)	
[60/123]	Time 0.044 (0.139)	Data 0.029 (0.101)	
[61/123]	Time 0.443 (0.144)	Data 0.429 (0.106)	
[62/123]	Time 0.027 (0.142)	Data 0.011 (0.105)	
[63/123]	Time 0.039 (0.140)	Data 0.012 (0.103)	
[64/123]	Time 0.024 (0.139)	Data 0.009 (0.102)	
[65/123]	Time 0.023 (0.137)	Data 0.001 (0.100)	
[66/123]	Time 0.015 (0.135)	Data 0.001 (0.099)	
[67/123]	Time 0.026 (0.133)	Data 0.011 (0.097)	
[68/123]	Time 0.044 (0.132)	Data 0.015 (0.096)	
[69/123]	Time 0.015 (0.130)	Data 0.000 (0.095)	
[70/123]	Time 0.580 (0.137)	Data 0.566 (0.101)	
[71/123]	Time 0.025 (0.135)	Data 0.004 (0.100)	
[72/123]	Time 0.024 (0.134)	Data 0.010 (0.099)	
[73/123]	Time 0.016 (0.132)	Data 0.001 (0.097)	
[74/123]	Time 0.040 (0.131)	Data 0.011 (0.096)	
[75/123]	Time 0.029 (0.129)	Data 0.001 (0.095)	
[76/123]	Time 0.025 (0.128)	Data 0.001 (0.094)	
[77/123]	Time 0.682 (0.135)	Data 0.666 (0.101)	
[78/123]	Time 0.031 (0.134)	Data 0.017 (0.100)	
[79/123]	Time 0.038 (0.133)	Data 0.014 (0.099)	
[80/123]	Time 0.015 (0.131)	Data 0.001 (0.098)	
[81/123]	Time 0.037 (0.130)	Data 0.006 (0.097)	
[82/123]	Time 0.015 (0.129)	Data 0.001 (0.096)	
[83/123]	Time 0.043 (0.128)	Data 0.028 (0.095)	
[84/123]	Time 0.029 (0.126)	Data 0.015 (0.094)	
[85/123]	Time 0.035 (0.125)	Data 0.013 (0.093)	
[86/123]	Time 0.475 (0.129)	Data 0.460 (0.097)	
[87/123]	Time 0.028 (0.128)	Data 0.001 (0.096)	
[88/123]	Time 0.030 (0.127)	Data 0.015 (0.095)	
[89/123]	Time 0.037 (0.126)	Data 0.022 (0.094)	
[90/123]	Time 0.033 (0.125)	Data 0.011 (0.093)	
[91/123]	Time 0.023 (0.124)	Data 0.004 (0.092)	
[92/123]	Time 0.028 (0.123)	Data 0.004 (0.091)	
[93/123]	Time 0.434 (0.126)	Data 0.419 (0.095)	
[94/123]	Time 0.060 (0.126)	Data 0.012 (0.094)	
[95/123]	Time 0.016 (0.124)	Data 0.000 (0.093)	
[96/123]	Time 0.032 (0.123)	Data 0.001 (0.092)	
[97/123]	Time 0.019 (0.122)	Data 0.001 (0.091)	
[98/123]	Time 0.029 (0.121)	Data 0.000 (0.090)	
[99/123]	Time 0.036 (0.121)	Data 0.014 (0.089)	
[100/123]	Time 0.021 (0.120)	Data 0.001 (0.089)	
[101/123]	Time 0.022 (0.119)	Data 0.001 (0.088)	
[102/123]	Time 0.246 (0.120)	Data 0.231 (0.089)	
[103/123]	Time 0.015 (0.119)	Data 0.001 (0.088)	
[104/123]	Time 0.017 (0.118)	Data 0.001 (0.087)	
[105/123]	Time 0.014 (0.117)	Data 0.000 (0.087)	
[106/123]	Time 0.014 (0.116)	Data 0.000 (0.086)	
[107/123]	Time 0.015 (0.115)	Data 0.001 (0.085)	
[108/123]	Time 0.014 (0.114)	Data 0.000 (0.084)	
[109/123]	Time 0.253 (0.115)	Data 0.240 (0.086)	
[110/123]	Time 0.013 (0.114)	Data 0.000 (0.085)	
[111/123]	Time 0.014 (0.113)	Data 0.000 (0.084)	
[112/123]	Time 0.013 (0.113)	Data 0.000 (0.083)	
[113/123]	Time 0.013 (0.112)	Data 0.000 (0.083)	
[114/123]	Time 0.013 (0.111)	Data 0.000 (0.082)	
[115/123]	Time 0.014 (0.110)	Data 0.000 (0.081)	
[116/123]	Time 0.013 (0.109)	Data 0.000 (0.080)	
[117/123]	Time 0.013 (0.108)	Data 0.000 (0.080)	
[118/123]	Time 0.145 (0.109)	Data 0.131 (0.080)	
[119/123]	Time 0.013 (0.108)	Data 0.000 (0.080)	
[120/123]	Time 0.013 (0.107)	Data 0.000 (0.079)	
[121/123]	Time 0.013 (0.106)	Data 0.000 (0.078)	
[122/123]	Time 0.013 (0.105)	Data 0.000 (0.078)	
[123/123]	Time 0.013 (0.105)	Data 0.000 (0.077)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.01', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.01, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=8, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.01/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.01/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.490 (4.490)	Data 3.898 (3.898)	
[2/123]	Time 0.020 (2.255)	Data 0.000 (1.949)	
[3/123]	Time 0.017 (1.509)	Data 0.000 (1.299)	
[4/123]	Time 0.018 (1.136)	Data 0.000 (0.975)	
[5/123]	Time 0.018 (0.913)	Data 0.000 (0.780)	
[6/123]	Time 0.019 (0.764)	Data 0.001 (0.650)	
[7/123]	Time 0.020 (0.657)	Data 0.000 (0.557)	
[8/123]	Time 0.021 (0.578)	Data 0.001 (0.488)	
[9/123]	Time 0.025 (0.516)	Data 0.001 (0.433)	
[10/123]	Time 0.029 (0.468)	Data 0.001 (0.390)	
[11/123]	Time 0.025 (0.427)	Data 0.001 (0.355)	
[12/123]	Time 0.028 (0.394)	Data 0.001 (0.325)	
[13/123]	Time 0.026 (0.366)	Data 0.001 (0.300)	
[14/123]	Time 0.087 (0.346)	Data 0.015 (0.280)	
[15/123]	Time 0.051 (0.326)	Data 0.012 (0.262)	
[16/123]	Time 0.071 (0.310)	Data 0.029 (0.247)	
[17/123]	Time 0.088 (0.297)	Data 0.029 (0.235)	
[18/123]	Time 0.037 (0.283)	Data 0.001 (0.222)	
[19/123]	Time 0.078 (0.272)	Data 0.037 (0.212)	
[20/123]	Time 0.082 (0.263)	Data 0.006 (0.202)	
[21/123]	Time 0.073 (0.254)	Data 0.006 (0.192)	
[22/123]	Time 0.048 (0.244)	Data 0.007 (0.184)	
[23/123]	Time 0.046 (0.236)	Data 0.006 (0.176)	
[24/123]	Time 0.053 (0.228)	Data 0.013 (0.169)	
[25/123]	Time 0.045 (0.221)	Data 0.006 (0.163)	
[26/123]	Time 0.067 (0.215)	Data 0.006 (0.157)	
[27/123]	Time 0.064 (0.209)	Data 0.011 (0.151)	
[28/123]	Time 0.051 (0.204)	Data 0.001 (0.146)	
[29/123]	Time 0.030 (0.198)	Data 0.001 (0.141)	
[30/123]	Time 0.041 (0.192)	Data 0.001 (0.136)	
[31/123]	Time 0.037 (0.187)	Data 0.001 (0.132)	
[32/123]	Time 0.044 (0.183)	Data 0.001 (0.128)	
[33/123]	Time 0.078 (0.180)	Data 0.005 (0.124)	
[34/123]	Time 0.044 (0.176)	Data 0.001 (0.121)	
[35/123]	Time 0.065 (0.173)	Data 0.009 (0.117)	
[36/123]	Time 0.047 (0.169)	Data 0.001 (0.114)	
[37/123]	Time 0.358 (0.174)	Data 0.314 (0.120)	
[38/123]	Time 0.050 (0.171)	Data 0.010 (0.117)	
[39/123]	Time 0.056 (0.168)	Data 0.018 (0.114)	
[40/123]	Time 0.070 (0.165)	Data 0.005 (0.111)	
[41/123]	Time 0.066 (0.163)	Data 0.010 (0.109)	
[42/123]	Time 0.048 (0.160)	Data 0.006 (0.106)	
[43/123]	Time 0.066 (0.158)	Data 0.012 (0.104)	
[44/123]	Time 0.055 (0.156)	Data 0.014 (0.102)	
[45/123]	Time 0.069 (0.154)	Data 0.009 (0.100)	
[46/123]	Time 0.042 (0.151)	Data 0.014 (0.098)	
[47/123]	Time 0.028 (0.149)	Data 0.001 (0.096)	
[48/123]	Time 0.061 (0.147)	Data 0.017 (0.095)	
[49/123]	Time 0.084 (0.146)	Data 0.012 (0.093)	
[50/123]	Time 0.178 (0.146)	Data 0.106 (0.093)	
[51/123]	Time 0.052 (0.144)	Data 0.001 (0.091)	
[52/123]	Time 0.110 (0.144)	Data 0.071 (0.091)	
[53/123]	Time 0.698 (0.154)	Data 0.654 (0.102)	
[54/123]	Time 0.059 (0.152)	Data 0.002 (0.100)	
[55/123]	Time 0.040 (0.150)	Data 0.001 (0.098)	
[56/123]	Time 0.057 (0.149)	Data 0.015 (0.096)	
[57/123]	Time 0.030 (0.147)	Data 0.001 (0.095)	
[58/123]	Time 0.066 (0.145)	Data 0.001 (0.093)	
[59/123]	Time 0.033 (0.143)	Data 0.001 (0.092)	
[60/123]	Time 0.069 (0.142)	Data 0.000 (0.090)	
[61/123]	Time 0.061 (0.141)	Data 0.015 (0.089)	
[62/123]	Time 0.042 (0.139)	Data 0.001 (0.087)	
[63/123]	Time 0.065 (0.138)	Data 0.004 (0.086)	
[64/123]	Time 0.042 (0.137)	Data 0.000 (0.085)	
[65/123]	Time 0.058 (0.135)	Data 0.013 (0.084)	
[66/123]	Time 0.142 (0.135)	Data 0.091 (0.084)	
[67/123]	Time 0.075 (0.135)	Data 0.012 (0.083)	
[68/123]	Time 0.027 (0.133)	Data 0.001 (0.081)	
[69/123]	Time 0.672 (0.141)	Data 0.595 (0.089)	
[70/123]	Time 0.041 (0.139)	Data 0.000 (0.088)	
[71/123]	Time 0.076 (0.138)	Data 0.019 (0.087)	
[72/123]	Time 0.048 (0.137)	Data 0.001 (0.085)	
[73/123]	Time 0.051 (0.136)	Data 0.006 (0.084)	
[74/123]	Time 0.079 (0.135)	Data 0.012 (0.083)	
[75/123]	Time 0.046 (0.134)	Data 0.001 (0.082)	
[76/123]	Time 0.056 (0.133)	Data 0.015 (0.081)	
[77/123]	Time 0.071 (0.132)	Data 0.013 (0.081)	
[78/123]	Time 0.067 (0.131)	Data 0.013 (0.080)	
[79/123]	Time 0.050 (0.130)	Data 0.013 (0.079)	
[80/123]	Time 0.105 (0.130)	Data 0.013 (0.078)	
[81/123]	Time 0.068 (0.129)	Data 0.001 (0.077)	
[82/123]	Time 0.441 (0.133)	Data 0.399 (0.081)	
[83/123]	Time 0.052 (0.132)	Data 0.001 (0.080)	
[84/123]	Time 0.066 (0.131)	Data 0.022 (0.079)	
[85/123]	Time 0.062 (0.130)	Data 0.008 (0.078)	
[86/123]	Time 0.044 (0.129)	Data 0.007 (0.078)	
[87/123]	Time 0.020 (0.128)	Data 0.001 (0.077)	
[88/123]	Time 0.373 (0.131)	Data 0.330 (0.080)	
[89/123]	Time 0.053 (0.130)	Data 0.001 (0.079)	
[90/123]	Time 0.070 (0.129)	Data 0.001 (0.078)	
[91/123]	Time 0.072 (0.129)	Data 0.001 (0.077)	
[92/123]	Time 0.043 (0.128)	Data 0.000 (0.076)	
[93/123]	Time 0.065 (0.127)	Data 0.016 (0.076)	
[94/123]	Time 0.074 (0.127)	Data 0.000 (0.075)	
[95/123]	Time 0.039 (0.126)	Data 0.001 (0.074)	
[96/123]	Time 0.045 (0.125)	Data 0.001 (0.073)	
[97/123]	Time 0.027 (0.124)	Data 0.000 (0.072)	
[98/123]	Time 0.302 (0.126)	Data 0.265 (0.074)	
[99/123]	Time 0.018 (0.125)	Data 0.000 (0.074)	
[100/123]	Time 0.022 (0.124)	Data 0.001 (0.073)	
[101/123]	Time 0.034 (0.123)	Data 0.001 (0.072)	
[102/123]	Time 0.027 (0.122)	Data 0.001 (0.072)	
[103/123]	Time 0.031 (0.121)	Data 0.001 (0.071)	
[104/123]	Time 0.320 (0.123)	Data 0.297 (0.073)	
[105/123]	Time 0.021 (0.122)	Data 0.000 (0.072)	
[106/123]	Time 0.019 (0.121)	Data 0.000 (0.072)	
[107/123]	Time 0.018 (0.120)	Data 0.000 (0.071)	
[108/123]	Time 0.018 (0.119)	Data 0.000 (0.070)	
[109/123]	Time 0.018 (0.118)	Data 0.000 (0.070)	
[110/123]	Time 0.017 (0.117)	Data 0.000 (0.069)	
[111/123]	Time 0.017 (0.116)	Data 0.000 (0.068)	
[112/123]	Time 0.017 (0.115)	Data 0.000 (0.068)	
[113/123]	Time 0.017 (0.114)	Data 0.000 (0.067)	
[114/123]	Time 0.080 (0.114)	Data 0.064 (0.067)	
[115/123]	Time 0.016 (0.113)	Data 0.000 (0.067)	
[116/123]	Time 0.016 (0.112)	Data 0.000 (0.066)	
[117/123]	Time 0.016 (0.112)	Data 0.000 (0.065)	
[118/123]	Time 0.016 (0.111)	Data 0.000 (0.065)	
[119/123]	Time 0.016 (0.110)	Data 0.000 (0.064)	
[120/123]	Time 0.110 (0.110)	Data 0.094 (0.065)	
[121/123]	Time 0.016 (0.109)	Data 0.000 (0.064)	
[122/123]	Time 0.016 (0.108)	Data 0.000 (0.064)	
[123/123]	Time 0.016 (0.108)	Data 0.000 (0.063)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.001', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.001, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=8, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.001/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs8_lr0.001/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.532 (4.532)	Data 3.828 (3.828)	
[2/123]	Time 0.014 (2.273)	Data 0.000 (1.914)	
[3/123]	Time 0.014 (1.520)	Data 0.000 (1.276)	
[4/123]	Time 0.280 (1.210)	Data 0.266 (1.024)	
[5/123]	Time 0.014 (0.971)	Data 0.000 (0.819)	
[6/123]	Time 0.015 (0.811)	Data 0.001 (0.683)	
[7/123]	Time 0.015 (0.698)	Data 0.001 (0.585)	
[8/123]	Time 0.015 (0.612)	Data 0.001 (0.512)	
[9/123]	Time 0.019 (0.546)	Data 0.003 (0.455)	
[10/123]	Time 0.014 (0.493)	Data 0.000 (0.410)	
[11/123]	Time 0.018 (0.450)	Data 0.003 (0.373)	
[12/123]	Time 0.015 (0.414)	Data 0.001 (0.342)	
[13/123]	Time 0.016 (0.383)	Data 0.001 (0.316)	
[14/123]	Time 0.027 (0.358)	Data 0.009 (0.294)	
[15/123]	Time 0.036 (0.336)	Data 0.009 (0.275)	
[16/123]	Time 0.028 (0.317)	Data 0.015 (0.259)	
[17/123]	Time 0.020 (0.300)	Data 0.006 (0.244)	
[18/123]	Time 0.015 (0.284)	Data 0.001 (0.230)	
[19/123]	Time 0.015 (0.270)	Data 0.001 (0.218)	
[20/123]	Time 0.015 (0.257)	Data 0.001 (0.207)	
[21/123]	Time 0.030 (0.246)	Data 0.017 (0.198)	
[22/123]	Time 0.033 (0.236)	Data 0.001 (0.189)	
[23/123]	Time 0.027 (0.227)	Data 0.013 (0.182)	
[24/123]	Time 0.028 (0.219)	Data 0.014 (0.175)	
[25/123]	Time 0.030 (0.211)	Data 0.016 (0.168)	
[26/123]	Time 0.045 (0.205)	Data 0.012 (0.162)	
[27/123]	Time 0.038 (0.199)	Data 0.011 (0.157)	
[28/123]	Time 0.054 (0.194)	Data 0.026 (0.152)	
[29/123]	Time 0.040 (0.188)	Data 0.006 (0.147)	
[30/123]	Time 0.036 (0.183)	Data 0.001 (0.142)	
[31/123]	Time 0.024 (0.178)	Data 0.001 (0.138)	
[32/123]	Time 0.014 (0.173)	Data 0.001 (0.133)	
[33/123]	Time 0.023 (0.169)	Data 0.001 (0.129)	
[34/123]	Time 0.051 (0.165)	Data 0.022 (0.126)	
[35/123]	Time 0.027 (0.161)	Data 0.001 (0.123)	
[36/123]	Time 0.445 (0.169)	Data 0.424 (0.131)	
[37/123]	Time 0.470 (0.177)	Data 0.457 (0.140)	
[38/123]	Time 0.327 (0.181)	Data 0.313 (0.144)	
[39/123]	Time 0.047 (0.178)	Data 0.010 (0.141)	
[40/123]	Time 0.031 (0.174)	Data 0.006 (0.137)	
[41/123]	Time 0.353 (0.178)	Data 0.323 (0.142)	
[42/123]	Time 0.027 (0.175)	Data 0.001 (0.139)	
[43/123]	Time 0.028 (0.171)	Data 0.001 (0.135)	
[44/123]	Time 0.054 (0.169)	Data 0.006 (0.132)	
[45/123]	Time 0.028 (0.166)	Data 0.001 (0.130)	
[46/123]	Time 0.018 (0.162)	Data 0.003 (0.127)	
[47/123]	Time 0.018 (0.159)	Data 0.002 (0.124)	
[48/123]	Time 0.030 (0.157)	Data 0.015 (0.122)	
[49/123]	Time 0.028 (0.154)	Data 0.013 (0.120)	
[50/123]	Time 0.022 (0.151)	Data 0.001 (0.117)	
[51/123]	Time 0.025 (0.149)	Data 0.002 (0.115)	
[52/123]	Time 0.039 (0.147)	Data 0.024 (0.113)	
[53/123]	Time 0.266 (0.149)	Data 0.252 (0.116)	
[54/123]	Time 0.106 (0.148)	Data 0.087 (0.115)	
[55/123]	Time 0.038 (0.146)	Data 0.007 (0.113)	
[56/123]	Time 0.151 (0.146)	Data 0.137 (0.114)	
[57/123]	Time 0.801 (0.158)	Data 0.787 (0.126)	
[58/123]	Time 0.019 (0.155)	Data 0.001 (0.123)	
[59/123]	Time 0.015 (0.153)	Data 0.001 (0.121)	
[60/123]	Time 0.028 (0.151)	Data 0.001 (0.119)	
[61/123]	Time 0.025 (0.149)	Data 0.011 (0.118)	
[62/123]	Time 0.040 (0.147)	Data 0.026 (0.116)	
[63/123]	Time 0.031 (0.145)	Data 0.001 (0.114)	
[64/123]	Time 0.036 (0.143)	Data 0.011 (0.113)	
[65/123]	Time 0.014 (0.141)	Data 0.001 (0.111)	
[66/123]	Time 0.034 (0.140)	Data 0.004 (0.109)	
[67/123]	Time 0.015 (0.138)	Data 0.001 (0.108)	
[68/123]	Time 0.018 (0.136)	Data 0.004 (0.106)	
[69/123]	Time 0.044 (0.135)	Data 0.015 (0.105)	
[70/123]	Time 0.030 (0.133)	Data 0.009 (0.103)	
[71/123]	Time 0.022 (0.132)	Data 0.008 (0.102)	
[72/123]	Time 0.242 (0.133)	Data 0.229 (0.104)	
[73/123]	Time 0.805 (0.143)	Data 0.791 (0.113)	
[74/123]	Time 0.034 (0.141)	Data 0.014 (0.112)	
[75/123]	Time 0.015 (0.139)	Data 0.001 (0.110)	
[76/123]	Time 0.015 (0.138)	Data 0.002 (0.109)	
[77/123]	Time 0.015 (0.136)	Data 0.001 (0.108)	
[78/123]	Time 0.029 (0.135)	Data 0.014 (0.106)	
[79/123]	Time 0.032 (0.134)	Data 0.018 (0.105)	
[80/123]	Time 0.043 (0.132)	Data 0.014 (0.104)	
[81/123]	Time 0.018 (0.131)	Data 0.001 (0.103)	
[82/123]	Time 0.024 (0.130)	Data 0.006 (0.102)	
[83/123]	Time 0.019 (0.128)	Data 0.005 (0.101)	
[84/123]	Time 0.028 (0.127)	Data 0.010 (0.099)	
[85/123]	Time 0.045 (0.126)	Data 0.009 (0.098)	
[86/123]	Time 0.014 (0.125)	Data 0.001 (0.097)	
[87/123]	Time 0.029 (0.124)	Data 0.016 (0.096)	
[88/123]	Time 0.288 (0.126)	Data 0.270 (0.098)	
[89/123]	Time 0.833 (0.134)	Data 0.820 (0.106)	
[90/123]	Time 0.024 (0.132)	Data 0.004 (0.105)	
[91/123]	Time 0.041 (0.131)	Data 0.019 (0.104)	
[92/123]	Time 0.027 (0.130)	Data 0.011 (0.103)	
[93/123]	Time 0.040 (0.129)	Data 0.001 (0.102)	
[94/123]	Time 0.025 (0.128)	Data 0.001 (0.101)	
[95/123]	Time 0.029 (0.127)	Data 0.001 (0.100)	
[96/123]	Time 0.019 (0.126)	Data 0.001 (0.099)	
[97/123]	Time 0.019 (0.125)	Data 0.001 (0.098)	
[98/123]	Time 0.029 (0.124)	Data 0.001 (0.097)	
[99/123]	Time 0.014 (0.123)	Data 0.001 (0.096)	
[100/123]	Time 0.031 (0.122)	Data 0.017 (0.095)	
[101/123]	Time 0.024 (0.121)	Data 0.001 (0.094)	
[102/123]	Time 0.015 (0.120)	Data 0.000 (0.093)	
[103/123]	Time 0.025 (0.119)	Data 0.001 (0.093)	
[104/123]	Time 0.014 (0.118)	Data 0.000 (0.092)	
[105/123]	Time 0.496 (0.122)	Data 0.484 (0.095)	
[106/123]	Time 0.014 (0.121)	Data 0.001 (0.095)	
[107/123]	Time 0.013 (0.120)	Data 0.000 (0.094)	
[108/123]	Time 0.013 (0.119)	Data 0.000 (0.093)	
[109/123]	Time 0.013 (0.118)	Data 0.000 (0.092)	
[110/123]	Time 0.013 (0.117)	Data 0.000 (0.091)	
[111/123]	Time 0.012 (0.116)	Data 0.000 (0.090)	
[112/123]	Time 0.012 (0.115)	Data 0.000 (0.089)	
[113/123]	Time 0.012 (0.114)	Data 0.000 (0.089)	
[114/123]	Time 0.012 (0.113)	Data 0.000 (0.088)	
[115/123]	Time 0.012 (0.112)	Data 0.000 (0.087)	
[116/123]	Time 0.012 (0.111)	Data 0.000 (0.086)	
[117/123]	Time 0.012 (0.110)	Data 0.000 (0.086)	
[118/123]	Time 0.012 (0.110)	Data 0.000 (0.085)	
[119/123]	Time 0.012 (0.109)	Data 0.000 (0.084)	
[120/123]	Time 0.012 (0.108)	Data 0.000 (0.084)	
[121/123]	Time 0.220 (0.109)	Data 0.207 (0.085)	
[122/123]	Time 0.012 (0.108)	Data 0.000 (0.084)	
[123/123]	Time 0.012 (0.107)	Data 0.000 (0.083)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.001', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.001, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=8, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.001/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs8_lr0.001/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.551 (4.551)	Data 3.957 (3.957)	
[2/123]	Time 0.018 (2.284)	Data 0.000 (1.979)	
[3/123]	Time 0.017 (1.529)	Data 0.000 (1.319)	
[4/123]	Time 0.017 (1.151)	Data 0.000 (0.990)	
[5/123]	Time 0.018 (0.924)	Data 0.000 (0.792)	
[6/123]	Time 0.018 (0.773)	Data 0.000 (0.660)	
[7/123]	Time 0.019 (0.665)	Data 0.001 (0.566)	
[8/123]	Time 0.023 (0.585)	Data 0.001 (0.495)	
[9/123]	Time 0.029 (0.523)	Data 0.000 (0.440)	
[10/123]	Time 0.026 (0.474)	Data 0.001 (0.396)	
[11/123]	Time 0.027 (0.433)	Data 0.001 (0.360)	
[12/123]	Time 0.070 (0.403)	Data 0.015 (0.331)	
[13/123]	Time 0.058 (0.376)	Data 0.001 (0.306)	
[14/123]	Time 0.053 (0.353)	Data 0.001 (0.284)	
[15/123]	Time 0.075 (0.335)	Data 0.014 (0.266)	
[16/123]	Time 0.097 (0.320)	Data 0.015 (0.250)	
[17/123]	Time 0.052 (0.304)	Data 0.001 (0.236)	
[18/123]	Time 0.064 (0.291)	Data 0.001 (0.223)	
[19/123]	Time 0.097 (0.280)	Data 0.010 (0.211)	
[20/123]	Time 0.050 (0.269)	Data 0.009 (0.201)	
[21/123]	Time 0.060 (0.259)	Data 0.010 (0.192)	
[22/123]	Time 0.054 (0.250)	Data 0.004 (0.184)	
[23/123]	Time 0.055 (0.241)	Data 0.001 (0.176)	
[24/123]	Time 0.065 (0.234)	Data 0.012 (0.169)	
[25/123]	Time 0.055 (0.227)	Data 0.019 (0.163)	
[26/123]	Time 0.070 (0.221)	Data 0.006 (0.157)	
[27/123]	Time 0.065 (0.215)	Data 0.001 (0.151)	
[28/123]	Time 0.037 (0.209)	Data 0.008 (0.146)	
[29/123]	Time 0.092 (0.204)	Data 0.023 (0.142)	
[30/123]	Time 0.045 (0.199)	Data 0.001 (0.137)	
[31/123]	Time 0.099 (0.196)	Data 0.006 (0.133)	
[32/123]	Time 0.061 (0.192)	Data 0.000 (0.129)	
[33/123]	Time 0.051 (0.187)	Data 0.002 (0.125)	
[34/123]	Time 0.062 (0.184)	Data 0.016 (0.122)	
[35/123]	Time 0.086 (0.181)	Data 0.027 (0.119)	
[36/123]	Time 0.095 (0.179)	Data 0.008 (0.116)	
[37/123]	Time 0.040 (0.175)	Data 0.002 (0.113)	
[38/123]	Time 0.061 (0.172)	Data 0.012 (0.110)	
[39/123]	Time 0.052 (0.169)	Data 0.011 (0.108)	
[40/123]	Time 0.045 (0.166)	Data 0.001 (0.105)	
[41/123]	Time 0.068 (0.163)	Data 0.011 (0.103)	
[42/123]	Time 0.186 (0.164)	Data 0.133 (0.103)	
[43/123]	Time 0.059 (0.161)	Data 0.020 (0.101)	
[44/123]	Time 0.063 (0.159)	Data 0.016 (0.099)	
[45/123]	Time 0.053 (0.157)	Data 0.014 (0.098)	
[46/123]	Time 0.050 (0.154)	Data 0.008 (0.096)	
[47/123]	Time 0.126 (0.154)	Data 0.083 (0.095)	
[48/123]	Time 0.047 (0.152)	Data 0.017 (0.094)	
[49/123]	Time 0.169 (0.152)	Data 0.097 (0.094)	
[50/123]	Time 0.066 (0.150)	Data 0.001 (0.092)	
[51/123]	Time 0.040 (0.148)	Data 0.001 (0.090)	
[52/123]	Time 0.062 (0.146)	Data 0.014 (0.089)	
[53/123]	Time 0.060 (0.145)	Data 0.012 (0.087)	
[54/123]	Time 0.034 (0.143)	Data 0.003 (0.086)	
[55/123]	Time 0.252 (0.145)	Data 0.194 (0.088)	
[56/123]	Time 0.059 (0.143)	Data 0.000 (0.086)	
[57/123]	Time 0.032 (0.141)	Data 0.001 (0.085)	
[58/123]	Time 0.696 (0.151)	Data 0.663 (0.095)	
[59/123]	Time 0.077 (0.150)	Data 0.015 (0.093)	
[60/123]	Time 0.068 (0.148)	Data 0.010 (0.092)	
[61/123]	Time 0.042 (0.147)	Data 0.001 (0.090)	
[62/123]	Time 0.026 (0.145)	Data 0.001 (0.089)	
[63/123]	Time 0.052 (0.143)	Data 0.001 (0.087)	
[64/123]	Time 0.039 (0.141)	Data 0.001 (0.086)	
[65/123]	Time 0.058 (0.140)	Data 0.015 (0.085)	
[66/123]	Time 0.041 (0.139)	Data 0.001 (0.084)	
[67/123]	Time 0.045 (0.137)	Data 0.006 (0.083)	
[68/123]	Time 0.061 (0.136)	Data 0.015 (0.082)	
[69/123]	Time 0.051 (0.135)	Data 0.001 (0.080)	
[70/123]	Time 0.059 (0.134)	Data 0.001 (0.079)	
[71/123]	Time 0.662 (0.141)	Data 0.608 (0.087)	
[72/123]	Time 0.042 (0.140)	Data 0.014 (0.086)	
[73/123]	Time 0.075 (0.139)	Data 0.015 (0.085)	
[74/123]	Time 0.309 (0.141)	Data 0.277 (0.087)	
[75/123]	Time 0.060 (0.140)	Data 0.016 (0.086)	
[76/123]	Time 0.041 (0.139)	Data 0.001 (0.085)	
[77/123]	Time 0.041 (0.138)	Data 0.011 (0.084)	
[78/123]	Time 0.039 (0.136)	Data 0.015 (0.083)	
[79/123]	Time 0.053 (0.135)	Data 0.004 (0.082)	
[80/123]	Time 0.029 (0.134)	Data 0.000 (0.081)	
[81/123]	Time 0.037 (0.133)	Data 0.001 (0.080)	
[82/123]	Time 0.054 (0.132)	Data 0.025 (0.080)	
[83/123]	Time 0.058 (0.131)	Data 0.015 (0.079)	
[84/123]	Time 0.049 (0.130)	Data 0.008 (0.078)	
[85/123]	Time 0.041 (0.129)	Data 0.001 (0.077)	
[86/123]	Time 0.049 (0.128)	Data 0.007 (0.076)	
[87/123]	Time 0.700 (0.135)	Data 0.675 (0.083)	
[88/123]	Time 0.062 (0.134)	Data 0.001 (0.082)	
[89/123]	Time 0.082 (0.133)	Data 0.017 (0.082)	
[90/123]	Time 0.053 (0.132)	Data 0.001 (0.081)	
[91/123]	Time 0.043 (0.131)	Data 0.001 (0.080)	
[92/123]	Time 0.059 (0.130)	Data 0.000 (0.079)	
[93/123]	Time 0.023 (0.129)	Data 0.000 (0.078)	
[94/123]	Time 0.058 (0.129)	Data 0.001 (0.077)	
[95/123]	Time 0.041 (0.128)	Data 0.000 (0.076)	
[96/123]	Time 0.049 (0.127)	Data 0.005 (0.076)	
[97/123]	Time 0.056 (0.126)	Data 0.000 (0.075)	
[98/123]	Time 0.040 (0.125)	Data 0.000 (0.074)	
[99/123]	Time 0.027 (0.124)	Data 0.001 (0.073)	
[100/123]	Time 0.030 (0.123)	Data 0.000 (0.073)	
[101/123]	Time 0.034 (0.122)	Data 0.000 (0.072)	
[102/123]	Time 0.026 (0.121)	Data 0.001 (0.071)	
[103/123]	Time 0.397 (0.124)	Data 0.379 (0.074)	
[104/123]	Time 0.017 (0.123)	Data 0.000 (0.074)	
[105/123]	Time 0.017 (0.122)	Data 0.000 (0.073)	
[106/123]	Time 0.017 (0.121)	Data 0.000 (0.072)	
[107/123]	Time 0.017 (0.120)	Data 0.000 (0.072)	
[108/123]	Time 0.017 (0.119)	Data 0.000 (0.071)	
[109/123]	Time 0.017 (0.118)	Data 0.000 (0.070)	
[110/123]	Time 0.016 (0.117)	Data 0.000 (0.070)	
[111/123]	Time 0.017 (0.116)	Data 0.000 (0.069)	
[112/123]	Time 0.016 (0.116)	Data 0.000 (0.068)	
[113/123]	Time 0.016 (0.115)	Data 0.000 (0.068)	
[114/123]	Time 0.016 (0.114)	Data 0.000 (0.067)	
[115/123]	Time 0.016 (0.113)	Data 0.000 (0.067)	
[116/123]	Time 0.016 (0.112)	Data 0.000 (0.066)	
[117/123]	Time 0.016 (0.111)	Data 0.000 (0.065)	
[118/123]	Time 0.016 (0.110)	Data 0.000 (0.065)	
[119/123]	Time 0.172 (0.111)	Data 0.156 (0.066)	
[120/123]	Time 0.016 (0.110)	Data 0.000 (0.065)	
[121/123]	Time 0.016 (0.109)	Data 0.000 (0.065)	
[122/123]	Time 0.016 (0.109)	Data 0.000 (0.064)	
[123/123]	Time 0.016 (0.108)	Data 0.000 (0.064)	
end bs8
start bs16
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.1', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.1, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=16, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.1/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.1/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 5.132 (5.132)	Data 4.430 (4.430)	
[2/123]	Time 0.016 (2.574)	Data 0.001 (2.215)	
[3/123]	Time 0.014 (1.721)	Data 0.000 (1.477)	
[4/123]	Time 0.014 (1.294)	Data 0.001 (1.108)	
[5/123]	Time 0.014 (1.038)	Data 0.000 (0.886)	
[6/123]	Time 0.014 (0.868)	Data 0.000 (0.739)	
[7/123]	Time 0.015 (0.746)	Data 0.001 (0.633)	
[8/123]	Time 0.015 (0.654)	Data 0.001 (0.554)	
[9/123]	Time 0.015 (0.583)	Data 0.001 (0.493)	
[10/123]	Time 0.015 (0.526)	Data 0.001 (0.443)	
[11/123]	Time 0.014 (0.480)	Data 0.000 (0.403)	
[12/123]	Time 0.014 (0.441)	Data 0.001 (0.370)	
[13/123]	Time 0.015 (0.408)	Data 0.001 (0.341)	
[14/123]	Time 0.035 (0.382)	Data 0.009 (0.318)	
[15/123]	Time 0.025 (0.358)	Data 0.011 (0.297)	
[16/123]	Time 0.018 (0.337)	Data 0.004 (0.279)	
[17/123]	Time 0.043 (0.319)	Data 0.029 (0.264)	
[18/123]	Time 0.028 (0.303)	Data 0.014 (0.250)	
[19/123]	Time 0.037 (0.289)	Data 0.006 (0.237)	
[20/123]	Time 0.018 (0.276)	Data 0.001 (0.226)	
[21/123]	Time 0.029 (0.264)	Data 0.016 (0.216)	
[22/123]	Time 0.018 (0.253)	Data 0.004 (0.206)	
[23/123]	Time 0.032 (0.243)	Data 0.019 (0.198)	
[24/123]	Time 0.030 (0.234)	Data 0.007 (0.190)	
[25/123]	Time 0.025 (0.226)	Data 0.011 (0.183)	
[26/123]	Time 0.043 (0.219)	Data 0.016 (0.176)	
[27/123]	Time 0.025 (0.212)	Data 0.011 (0.170)	
[28/123]	Time 0.034 (0.205)	Data 0.006 (0.164)	
[29/123]	Time 0.016 (0.199)	Data 0.001 (0.159)	
[30/123]	Time 0.035 (0.193)	Data 0.017 (0.154)	
[31/123]	Time 0.038 (0.188)	Data 0.009 (0.149)	
[32/123]	Time 0.014 (0.183)	Data 0.001 (0.145)	
[33/123]	Time 0.025 (0.178)	Data 0.011 (0.141)	
[34/123]	Time 0.272 (0.181)	Data 0.258 (0.144)	
[35/123]	Time 0.239 (0.182)	Data 0.225 (0.146)	
[36/123]	Time 0.560 (0.193)	Data 0.546 (0.157)	
[37/123]	Time 0.025 (0.188)	Data 0.006 (0.153)	
[38/123]	Time 0.031 (0.184)	Data 0.009 (0.150)	
[39/123]	Time 0.018 (0.180)	Data 0.001 (0.146)	
[40/123]	Time 0.344 (0.184)	Data 0.329 (0.150)	
[41/123]	Time 0.029 (0.180)	Data 0.001 (0.147)	
[42/123]	Time 0.026 (0.177)	Data 0.003 (0.143)	
[43/123]	Time 0.026 (0.173)	Data 0.004 (0.140)	
[44/123]	Time 0.016 (0.170)	Data 0.001 (0.137)	
[45/123]	Time 0.023 (0.166)	Data 0.001 (0.134)	
[46/123]	Time 0.027 (0.163)	Data 0.011 (0.131)	
[47/123]	Time 0.046 (0.161)	Data 0.012 (0.129)	
[48/123]	Time 0.036 (0.158)	Data 0.012 (0.126)	
[49/123]	Time 0.025 (0.155)	Data 0.001 (0.124)	
[50/123]	Time 0.046 (0.153)	Data 0.031 (0.122)	
[51/123]	Time 0.190 (0.154)	Data 0.162 (0.123)	
[52/123]	Time 0.832 (0.167)	Data 0.818 (0.136)	
[53/123]	Time 0.029 (0.164)	Data 0.015 (0.134)	
[54/123]	Time 0.053 (0.162)	Data 0.021 (0.132)	
[55/123]	Time 0.022 (0.160)	Data 0.001 (0.129)	
[56/123]	Time 0.028 (0.157)	Data 0.001 (0.127)	
[57/123]	Time 0.031 (0.155)	Data 0.016 (0.125)	
[58/123]	Time 0.031 (0.153)	Data 0.001 (0.123)	
[59/123]	Time 0.027 (0.151)	Data 0.001 (0.121)	
[60/123]	Time 0.029 (0.149)	Data 0.000 (0.119)	
[61/123]	Time 0.015 (0.147)	Data 0.001 (0.117)	
[62/123]	Time 0.038 (0.145)	Data 0.009 (0.115)	
[63/123]	Time 0.090 (0.144)	Data 0.075 (0.114)	
[64/123]	Time 0.038 (0.142)	Data 0.009 (0.113)	
[65/123]	Time 0.051 (0.141)	Data 0.023 (0.111)	
[66/123]	Time 0.015 (0.139)	Data 0.001 (0.110)	
[67/123]	Time 0.535 (0.145)	Data 0.519 (0.116)	
[68/123]	Time 0.710 (0.153)	Data 0.696 (0.124)	
[69/123]	Time 0.029 (0.152)	Data 0.001 (0.123)	
[70/123]	Time 0.029 (0.150)	Data 0.015 (0.121)	
[71/123]	Time 0.050 (0.148)	Data 0.006 (0.119)	
[72/123]	Time 0.015 (0.147)	Data 0.001 (0.118)	
[73/123]	Time 0.043 (0.145)	Data 0.028 (0.117)	
[74/123]	Time 0.028 (0.144)	Data 0.008 (0.115)	
[75/123]	Time 0.036 (0.142)	Data 0.021 (0.114)	
[76/123]	Time 0.048 (0.141)	Data 0.013 (0.113)	
[77/123]	Time 0.015 (0.139)	Data 0.000 (0.111)	
[78/123]	Time 0.015 (0.138)	Data 0.001 (0.110)	
[79/123]	Time 0.029 (0.136)	Data 0.014 (0.108)	
[80/123]	Time 0.032 (0.135)	Data 0.017 (0.107)	
[81/123]	Time 0.030 (0.134)	Data 0.011 (0.106)	
[82/123]	Time 0.015 (0.132)	Data 0.001 (0.105)	
[83/123]	Time 0.327 (0.135)	Data 0.313 (0.107)	
[84/123]	Time 0.625 (0.140)	Data 0.611 (0.113)	
[85/123]	Time 0.035 (0.139)	Data 0.001 (0.112)	
[86/123]	Time 0.038 (0.138)	Data 0.013 (0.111)	
[87/123]	Time 0.029 (0.137)	Data 0.011 (0.110)	
[88/123]	Time 0.020 (0.135)	Data 0.001 (0.108)	
[89/123]	Time 0.019 (0.134)	Data 0.005 (0.107)	
[90/123]	Time 0.040 (0.133)	Data 0.014 (0.106)	
[91/123]	Time 0.024 (0.132)	Data 0.010 (0.105)	
[92/123]	Time 0.030 (0.131)	Data 0.000 (0.104)	
[93/123]	Time 0.029 (0.130)	Data 0.001 (0.103)	
[94/123]	Time 0.015 (0.128)	Data 0.001 (0.102)	
[95/123]	Time 0.030 (0.127)	Data 0.000 (0.101)	
[96/123]	Time 0.069 (0.127)	Data 0.000 (0.100)	
[97/123]	Time 0.037 (0.126)	Data 0.000 (0.099)	
[98/123]	Time 0.044 (0.125)	Data 0.022 (0.098)	
[99/123]	Time 0.056 (0.124)	Data 0.042 (0.097)	
[100/123]	Time 0.507 (0.128)	Data 0.494 (0.101)	
[101/123]	Time 0.023 (0.127)	Data 0.001 (0.100)	
[102/123]	Time 0.017 (0.126)	Data 0.001 (0.099)	
[103/123]	Time 0.014 (0.125)	Data 0.001 (0.098)	
[104/123]	Time 0.015 (0.124)	Data 0.001 (0.097)	
[105/123]	Time 0.099 (0.124)	Data 0.085 (0.097)	
[106/123]	Time 0.013 (0.123)	Data 0.000 (0.096)	
[107/123]	Time 0.014 (0.122)	Data 0.000 (0.096)	
[108/123]	Time 0.014 (0.121)	Data 0.001 (0.095)	
[109/123]	Time 0.014 (0.120)	Data 0.000 (0.094)	
[110/123]	Time 0.014 (0.119)	Data 0.001 (0.093)	
[111/123]	Time 0.014 (0.118)	Data 0.001 (0.092)	
[112/123]	Time 0.014 (0.117)	Data 0.000 (0.091)	
[113/123]	Time 0.013 (0.116)	Data 0.000 (0.091)	
[114/123]	Time 0.014 (0.115)	Data 0.000 (0.090)	
[115/123]	Time 0.092 (0.115)	Data 0.079 (0.090)	
[116/123]	Time 0.314 (0.117)	Data 0.302 (0.091)	
[117/123]	Time 0.012 (0.116)	Data 0.000 (0.091)	
[118/123]	Time 0.013 (0.115)	Data 0.000 (0.090)	
[119/123]	Time 0.012 (0.114)	Data 0.000 (0.089)	
[120/123]	Time 0.012 (0.113)	Data 0.000 (0.088)	
[121/123]	Time 0.012 (0.112)	Data 0.000 (0.088)	
[122/123]	Time 0.012 (0.111)	Data 0.000 (0.087)	
[123/123]	Time 0.012 (0.111)	Data 0.000 (0.086)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.1', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.1, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=16, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.1/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.1/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.550 (4.550)	Data 3.918 (3.918)	
[2/123]	Time 0.021 (2.286)	Data 0.001 (1.959)	
[3/123]	Time 0.030 (1.534)	Data 0.012 (1.310)	
[4/123]	Time 0.017 (1.155)	Data 0.000 (0.983)	
[5/123]	Time 0.018 (0.927)	Data 0.000 (0.786)	
[6/123]	Time 0.019 (0.776)	Data 0.001 (0.655)	
[7/123]	Time 0.020 (0.668)	Data 0.001 (0.562)	
[8/123]	Time 0.024 (0.587)	Data 0.001 (0.492)	
[9/123]	Time 0.024 (0.525)	Data 0.001 (0.437)	
[10/123]	Time 0.025 (0.475)	Data 0.001 (0.393)	
[11/123]	Time 0.028 (0.434)	Data 0.001 (0.358)	
[12/123]	Time 0.029 (0.400)	Data 0.010 (0.329)	
[13/123]	Time 0.066 (0.375)	Data 0.013 (0.305)	
[14/123]	Time 0.046 (0.351)	Data 0.008 (0.283)	
[15/123]	Time 0.055 (0.331)	Data 0.000 (0.265)	
[16/123]	Time 0.060 (0.314)	Data 0.010 (0.249)	
[17/123]	Time 0.041 (0.298)	Data 0.001 (0.234)	
[18/123]	Time 0.066 (0.285)	Data 0.009 (0.222)	
[19/123]	Time 0.024 (0.272)	Data 0.001 (0.210)	
[20/123]	Time 0.027 (0.259)	Data 0.001 (0.199)	
[21/123]	Time 0.046 (0.249)	Data 0.001 (0.190)	
[22/123]	Time 0.045 (0.240)	Data 0.014 (0.182)	
[23/123]	Time 0.054 (0.232)	Data 0.013 (0.175)	
[24/123]	Time 0.050 (0.224)	Data 0.012 (0.168)	
[25/123]	Time 0.032 (0.217)	Data 0.001 (0.161)	
[26/123]	Time 0.031 (0.210)	Data 0.001 (0.155)	
[27/123]	Time 0.044 (0.203)	Data 0.015 (0.150)	
[28/123]	Time 0.054 (0.198)	Data 0.011 (0.145)	
[29/123]	Time 0.078 (0.194)	Data 0.014 (0.140)	
[30/123]	Time 0.033 (0.189)	Data 0.001 (0.136)	
[31/123]	Time 0.054 (0.184)	Data 0.014 (0.132)	
[32/123]	Time 0.054 (0.180)	Data 0.011 (0.128)	
[33/123]	Time 0.072 (0.177)	Data 0.003 (0.124)	
[34/123]	Time 0.197 (0.177)	Data 0.148 (0.125)	
[35/123]	Time 0.080 (0.175)	Data 0.013 (0.122)	
[36/123]	Time 0.179 (0.175)	Data 0.130 (0.122)	
[37/123]	Time 0.260 (0.177)	Data 0.233 (0.125)	
[38/123]	Time 0.083 (0.175)	Data 0.017 (0.122)	
[39/123]	Time 0.037 (0.171)	Data 0.001 (0.119)	
[40/123]	Time 0.032 (0.168)	Data 0.002 (0.116)	
[41/123]	Time 0.074 (0.165)	Data 0.021 (0.114)	
[42/123]	Time 0.046 (0.163)	Data 0.006 (0.111)	
[43/123]	Time 0.094 (0.161)	Data 0.052 (0.110)	
[44/123]	Time 0.060 (0.159)	Data 0.008 (0.108)	
[45/123]	Time 0.041 (0.156)	Data 0.015 (0.105)	
[46/123]	Time 0.026 (0.153)	Data 0.001 (0.103)	
[47/123]	Time 0.028 (0.151)	Data 0.001 (0.101)	
[48/123]	Time 0.033 (0.148)	Data 0.001 (0.099)	
[49/123]	Time 0.068 (0.146)	Data 0.015 (0.097)	
[50/123]	Time 0.861 (0.161)	Data 0.835 (0.112)	
[51/123]	Time 0.041 (0.158)	Data 0.001 (0.110)	
[52/123]	Time 0.056 (0.156)	Data 0.025 (0.108)	
[53/123]	Time 0.083 (0.155)	Data 0.009 (0.106)	
[54/123]	Time 0.132 (0.155)	Data 0.092 (0.106)	
[55/123]	Time 0.104 (0.154)	Data 0.033 (0.105)	
[56/123]	Time 0.052 (0.152)	Data 0.010 (0.103)	
[57/123]	Time 0.092 (0.151)	Data 0.031 (0.102)	
[58/123]	Time 0.084 (0.150)	Data 0.013 (0.100)	
[59/123]	Time 0.044 (0.148)	Data 0.009 (0.099)	
[60/123]	Time 0.057 (0.146)	Data 0.015 (0.097)	
[61/123]	Time 0.067 (0.145)	Data 0.033 (0.096)	
[62/123]	Time 0.044 (0.143)	Data 0.001 (0.095)	
[63/123]	Time 0.055 (0.142)	Data 0.013 (0.093)	
[64/123]	Time 0.054 (0.141)	Data 0.014 (0.092)	
[65/123]	Time 0.053 (0.139)	Data 0.001 (0.091)	
[66/123]	Time 0.994 (0.152)	Data 0.969 (0.104)	
[67/123]	Time 0.043 (0.151)	Data 0.001 (0.102)	
[68/123]	Time 0.028 (0.149)	Data 0.002 (0.101)	
[69/123]	Time 0.036 (0.147)	Data 0.001 (0.100)	
[70/123]	Time 0.046 (0.146)	Data 0.002 (0.098)	
[71/123]	Time 0.102 (0.145)	Data 0.017 (0.097)	
[72/123]	Time 0.037 (0.144)	Data 0.001 (0.096)	
[73/123]	Time 0.030 (0.142)	Data 0.001 (0.094)	
[74/123]	Time 0.056 (0.141)	Data 0.016 (0.093)	
[75/123]	Time 0.059 (0.140)	Data 0.016 (0.092)	
[76/123]	Time 0.056 (0.139)	Data 0.012 (0.091)	
[77/123]	Time 0.060 (0.138)	Data 0.012 (0.090)	
[78/123]	Time 0.056 (0.137)	Data 0.017 (0.089)	
[79/123]	Time 0.070 (0.136)	Data 0.011 (0.088)	
[80/123]	Time 0.049 (0.135)	Data 0.001 (0.087)	
[81/123]	Time 0.035 (0.133)	Data 0.001 (0.086)	
[82/123]	Time 0.257 (0.135)	Data 0.235 (0.088)	
[83/123]	Time 0.076 (0.134)	Data 0.026 (0.087)	
[84/123]	Time 0.087 (0.134)	Data 0.001 (0.086)	
[85/123]	Time 0.094 (0.133)	Data 0.001 (0.085)	
[86/123]	Time 0.197 (0.134)	Data 0.133 (0.086)	
[87/123]	Time 0.052 (0.133)	Data 0.001 (0.085)	
[88/123]	Time 0.061 (0.132)	Data 0.008 (0.084)	
[89/123]	Time 0.065 (0.131)	Data 0.001 (0.083)	
[90/123]	Time 0.048 (0.131)	Data 0.009 (0.082)	
[91/123]	Time 0.059 (0.130)	Data 0.012 (0.081)	
[92/123]	Time 0.041 (0.129)	Data 0.000 (0.080)	
[93/123]	Time 0.052 (0.128)	Data 0.000 (0.080)	
[94/123]	Time 0.042 (0.127)	Data 0.001 (0.079)	
[95/123]	Time 0.060 (0.126)	Data 0.001 (0.078)	
[96/123]	Time 0.042 (0.125)	Data 0.001 (0.077)	
[97/123]	Time 0.043 (0.125)	Data 0.000 (0.076)	
[98/123]	Time 0.314 (0.127)	Data 0.283 (0.078)	
[99/123]	Time 0.054 (0.126)	Data 0.001 (0.078)	
[100/123]	Time 0.037 (0.125)	Data 0.001 (0.077)	
[101/123]	Time 0.044 (0.124)	Data 0.001 (0.076)	
[102/123]	Time 0.047 (0.123)	Data 0.008 (0.075)	
[103/123]	Time 0.024 (0.122)	Data 0.001 (0.075)	
[104/123]	Time 0.027 (0.121)	Data 0.001 (0.074)	
[105/123]	Time 0.021 (0.121)	Data 0.000 (0.073)	
[106/123]	Time 0.021 (0.120)	Data 0.001 (0.073)	
[107/123]	Time 0.018 (0.119)	Data 0.000 (0.072)	
[108/123]	Time 0.020 (0.118)	Data 0.000 (0.071)	
[109/123]	Time 0.027 (0.117)	Data 0.000 (0.071)	
[110/123]	Time 0.017 (0.116)	Data 0.000 (0.070)	
[111/123]	Time 0.043 (0.115)	Data 0.026 (0.070)	
[112/123]	Time 0.017 (0.114)	Data 0.000 (0.069)	
[113/123]	Time 0.016 (0.114)	Data 0.000 (0.068)	
[114/123]	Time 0.240 (0.115)	Data 0.224 (0.070)	
[115/123]	Time 0.016 (0.114)	Data 0.000 (0.069)	
[116/123]	Time 0.016 (0.113)	Data 0.000 (0.069)	
[117/123]	Time 0.015 (0.112)	Data 0.000 (0.068)	
[118/123]	Time 0.016 (0.111)	Data 0.000 (0.067)	
[119/123]	Time 0.016 (0.111)	Data 0.000 (0.067)	
[120/123]	Time 0.016 (0.110)	Data 0.000 (0.066)	
[121/123]	Time 0.016 (0.109)	Data 0.000 (0.066)	
[122/123]	Time 0.016 (0.108)	Data 0.000 (0.065)	
[123/123]	Time 0.016 (0.107)	Data 0.000 (0.065)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.01', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.01, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=16, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.01/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.01/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 5.201 (5.201)	Data 4.472 (4.472)	
[2/123]	Time 0.015 (2.608)	Data 0.001 (2.236)	
[3/123]	Time 0.014 (1.743)	Data 0.000 (1.491)	
[4/123]	Time 0.014 (1.311)	Data 0.000 (1.118)	
[5/123]	Time 0.014 (1.052)	Data 0.001 (0.895)	
[6/123]	Time 0.015 (0.879)	Data 0.001 (0.746)	
[7/123]	Time 0.014 (0.755)	Data 0.000 (0.639)	
[8/123]	Time 0.015 (0.663)	Data 0.001 (0.559)	
[9/123]	Time 0.015 (0.591)	Data 0.000 (0.497)	
[10/123]	Time 0.015 (0.533)	Data 0.000 (0.448)	
[11/123]	Time 0.014 (0.486)	Data 0.000 (0.407)	
[12/123]	Time 0.021 (0.447)	Data 0.007 (0.374)	
[13/123]	Time 0.014 (0.414)	Data 0.001 (0.345)	
[14/123]	Time 0.028 (0.386)	Data 0.015 (0.321)	
[15/123]	Time 0.028 (0.362)	Data 0.015 (0.301)	
[16/123]	Time 0.035 (0.342)	Data 0.005 (0.282)	
[17/123]	Time 0.027 (0.323)	Data 0.001 (0.266)	
[18/123]	Time 0.029 (0.307)	Data 0.001 (0.251)	
[19/123]	Time 0.014 (0.292)	Data 0.001 (0.238)	
[20/123]	Time 0.015 (0.278)	Data 0.001 (0.226)	
[21/123]	Time 0.015 (0.265)	Data 0.001 (0.215)	
[22/123]	Time 0.015 (0.254)	Data 0.001 (0.206)	
[23/123]	Time 0.015 (0.244)	Data 0.001 (0.197)	
[24/123]	Time 0.015 (0.234)	Data 0.001 (0.189)	
[25/123]	Time 0.016 (0.225)	Data 0.001 (0.181)	
[26/123]	Time 0.015 (0.217)	Data 0.001 (0.174)	
[27/123]	Time 0.017 (0.210)	Data 0.001 (0.168)	
[28/123]	Time 0.015 (0.203)	Data 0.001 (0.162)	
[29/123]	Time 0.029 (0.197)	Data 0.015 (0.157)	
[30/123]	Time 0.028 (0.191)	Data 0.014 (0.152)	
[31/123]	Time 0.047 (0.187)	Data 0.014 (0.148)	
[32/123]	Time 0.024 (0.181)	Data 0.001 (0.143)	
[33/123]	Time 0.028 (0.177)	Data 0.001 (0.139)	
[34/123]	Time 0.546 (0.188)	Data 0.532 (0.150)	
[35/123]	Time 0.294 (0.191)	Data 0.280 (0.154)	
[36/123]	Time 0.406 (0.197)	Data 0.392 (0.161)	
[37/123]	Time 0.062 (0.193)	Data 0.010 (0.156)	
[38/123]	Time 0.014 (0.188)	Data 0.001 (0.152)	
[39/123]	Time 0.020 (0.184)	Data 0.006 (0.149)	
[40/123]	Time 0.024 (0.180)	Data 0.011 (0.145)	
[41/123]	Time 0.243 (0.182)	Data 0.230 (0.147)	
[42/123]	Time 0.026 (0.178)	Data 0.013 (0.144)	
[43/123]	Time 0.034 (0.175)	Data 0.010 (0.141)	
[44/123]	Time 0.029 (0.171)	Data 0.001 (0.138)	
[45/123]	Time 0.016 (0.168)	Data 0.001 (0.135)	
[46/123]	Time 0.040 (0.165)	Data 0.016 (0.132)	
[47/123]	Time 0.031 (0.162)	Data 0.001 (0.129)	
[48/123]	Time 0.031 (0.159)	Data 0.001 (0.127)	
[49/123]	Time 0.024 (0.157)	Data 0.001 (0.124)	
[50/123]	Time 0.062 (0.155)	Data 0.047 (0.123)	
[51/123]	Time 0.378 (0.159)	Data 0.346 (0.127)	
[52/123]	Time 0.292 (0.162)	Data 0.278 (0.130)	
[53/123]	Time 0.184 (0.162)	Data 0.153 (0.130)	
[54/123]	Time 0.016 (0.159)	Data 0.001 (0.128)	
[55/123]	Time 0.030 (0.157)	Data 0.016 (0.126)	
[56/123]	Time 0.026 (0.155)	Data 0.001 (0.124)	
[57/123]	Time 0.173 (0.155)	Data 0.147 (0.124)	
[58/123]	Time 0.032 (0.153)	Data 0.001 (0.122)	
[59/123]	Time 0.025 (0.151)	Data 0.002 (0.120)	
[60/123]	Time 0.028 (0.149)	Data 0.001 (0.118)	
[61/123]	Time 0.015 (0.147)	Data 0.001 (0.116)	
[62/123]	Time 0.032 (0.145)	Data 0.018 (0.114)	
[63/123]	Time 0.053 (0.143)	Data 0.020 (0.113)	
[64/123]	Time 0.015 (0.141)	Data 0.000 (0.111)	
[65/123]	Time 0.031 (0.140)	Data 0.016 (0.110)	
[66/123]	Time 0.092 (0.139)	Data 0.077 (0.109)	
[67/123]	Time 0.372 (0.142)	Data 0.357 (0.113)	
[68/123]	Time 0.396 (0.146)	Data 0.382 (0.117)	
[69/123]	Time 0.045 (0.145)	Data 0.013 (0.115)	
[70/123]	Time 0.028 (0.143)	Data 0.012 (0.114)	
[71/123]	Time 0.044 (0.142)	Data 0.017 (0.112)	
[72/123]	Time 0.015 (0.140)	Data 0.000 (0.111)	
[73/123]	Time 0.264 (0.141)	Data 0.249 (0.113)	
[74/123]	Time 0.036 (0.140)	Data 0.013 (0.111)	
[75/123]	Time 0.042 (0.139)	Data 0.008 (0.110)	
[76/123]	Time 0.015 (0.137)	Data 0.001 (0.109)	
[77/123]	Time 0.023 (0.136)	Data 0.008 (0.107)	
[78/123]	Time 0.043 (0.134)	Data 0.028 (0.106)	
[79/123]	Time 0.028 (0.133)	Data 0.013 (0.105)	
[80/123]	Time 0.036 (0.132)	Data 0.022 (0.104)	
[81/123]	Time 0.020 (0.130)	Data 0.006 (0.103)	
[82/123]	Time 0.294 (0.132)	Data 0.273 (0.105)	
[83/123]	Time 0.031 (0.131)	Data 0.001 (0.104)	
[84/123]	Time 0.490 (0.136)	Data 0.475 (0.108)	
[85/123]	Time 0.028 (0.134)	Data 0.014 (0.107)	
[86/123]	Time 0.028 (0.133)	Data 0.014 (0.106)	
[87/123]	Time 0.029 (0.132)	Data 0.001 (0.105)	
[88/123]	Time 0.033 (0.131)	Data 0.006 (0.104)	
[89/123]	Time 0.614 (0.136)	Data 0.599 (0.109)	
[90/123]	Time 0.030 (0.135)	Data 0.001 (0.108)	
[91/123]	Time 0.030 (0.134)	Data 0.016 (0.107)	
[92/123]	Time 0.019 (0.133)	Data 0.000 (0.106)	
[93/123]	Time 0.015 (0.131)	Data 0.001 (0.105)	
[94/123]	Time 0.015 (0.130)	Data 0.000 (0.104)	
[95/123]	Time 0.015 (0.129)	Data 0.000 (0.102)	
[96/123]	Time 0.016 (0.128)	Data 0.001 (0.101)	
[97/123]	Time 0.017 (0.127)	Data 0.001 (0.100)	
[98/123]	Time 0.015 (0.125)	Data 0.000 (0.099)	
[99/123]	Time 0.033 (0.124)	Data 0.000 (0.098)	
[100/123]	Time 0.254 (0.126)	Data 0.240 (0.100)	
[101/123]	Time 0.021 (0.125)	Data 0.000 (0.099)	
[102/123]	Time 0.093 (0.124)	Data 0.080 (0.099)	
[103/123]	Time 0.014 (0.123)	Data 0.000 (0.098)	
[104/123]	Time 0.118 (0.123)	Data 0.105 (0.098)	
[105/123]	Time 0.437 (0.126)	Data 0.424 (0.101)	
[106/123]	Time 0.013 (0.125)	Data 0.000 (0.100)	
[107/123]	Time 0.013 (0.124)	Data 0.000 (0.099)	
[108/123]	Time 0.014 (0.123)	Data 0.000 (0.098)	
[109/123]	Time 0.013 (0.122)	Data 0.000 (0.097)	
[110/123]	Time 0.013 (0.121)	Data 0.000 (0.096)	
[111/123]	Time 0.013 (0.120)	Data 0.000 (0.095)	
[112/123]	Time 0.012 (0.119)	Data 0.000 (0.095)	
[113/123]	Time 0.013 (0.118)	Data 0.000 (0.094)	
[114/123]	Time 0.013 (0.117)	Data 0.000 (0.093)	
[115/123]	Time 0.013 (0.116)	Data 0.000 (0.092)	
[116/123]	Time 0.013 (0.116)	Data 0.000 (0.091)	
[117/123]	Time 0.013 (0.115)	Data 0.000 (0.091)	
[118/123]	Time 0.012 (0.114)	Data 0.000 (0.090)	
[119/123]	Time 0.012 (0.113)	Data 0.000 (0.089)	
[120/123]	Time 0.012 (0.112)	Data 0.000 (0.088)	
[121/123]	Time 0.270 (0.113)	Data 0.257 (0.090)	
[122/123]	Time 0.012 (0.113)	Data 0.000 (0.089)	
[123/123]	Time 0.012 (0.112)	Data 0.000 (0.088)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.01', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.01, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=16, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.01/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.01/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.320 (4.320)	Data 3.268 (3.268)	
[2/123]	Time 0.018 (2.169)	Data 0.001 (1.634)	
[3/123]	Time 0.018 (1.452)	Data 0.001 (1.090)	
[4/123]	Time 0.018 (1.094)	Data 0.001 (0.818)	
[5/123]	Time 0.018 (0.879)	Data 0.000 (0.654)	
[6/123]	Time 0.018 (0.735)	Data 0.000 (0.545)	
[7/123]	Time 0.019 (0.633)	Data 0.001 (0.467)	
[8/123]	Time 0.020 (0.556)	Data 0.001 (0.409)	
[9/123]	Time 0.075 (0.503)	Data 0.047 (0.369)	
[10/123]	Time 0.030 (0.455)	Data 0.000 (0.332)	
[11/123]	Time 0.026 (0.416)	Data 0.001 (0.302)	
[12/123]	Time 0.039 (0.385)	Data 0.001 (0.277)	
[13/123]	Time 0.059 (0.360)	Data 0.001 (0.256)	
[14/123]	Time 0.075 (0.339)	Data 0.010 (0.238)	
[15/123]	Time 0.043 (0.320)	Data 0.001 (0.222)	
[16/123]	Time 0.063 (0.304)	Data 0.025 (0.210)	
[17/123]	Time 0.069 (0.290)	Data 0.013 (0.198)	
[18/123]	Time 0.066 (0.277)	Data 0.013 (0.188)	
[19/123]	Time 0.134 (0.270)	Data 0.095 (0.183)	
[20/123]	Time 0.054 (0.259)	Data 0.008 (0.174)	
[21/123]	Time 0.045 (0.249)	Data 0.019 (0.167)	
[22/123]	Time 0.072 (0.241)	Data 0.030 (0.161)	
[23/123]	Time 0.043 (0.232)	Data 0.003 (0.154)	
[24/123]	Time 0.057 (0.225)	Data 0.015 (0.148)	
[25/123]	Time 0.070 (0.219)	Data 0.011 (0.143)	
[26/123]	Time 0.042 (0.212)	Data 0.001 (0.137)	
[27/123]	Time 0.026 (0.205)	Data 0.001 (0.132)	
[28/123]	Time 0.067 (0.200)	Data 0.028 (0.128)	
[29/123]	Time 0.045 (0.195)	Data 0.002 (0.124)	
[30/123]	Time 0.061 (0.190)	Data 0.021 (0.121)	
[31/123]	Time 0.032 (0.185)	Data 0.001 (0.117)	
[32/123]	Time 0.042 (0.181)	Data 0.001 (0.113)	
[33/123]	Time 0.111 (0.179)	Data 0.013 (0.110)	
[34/123]	Time 0.098 (0.176)	Data 0.017 (0.107)	
[35/123]	Time 0.110 (0.174)	Data 0.087 (0.107)	
[36/123]	Time 0.071 (0.172)	Data 0.033 (0.105)	
[37/123]	Time 0.086 (0.169)	Data 0.014 (0.102)	
[38/123]	Time 0.049 (0.166)	Data 0.000 (0.100)	
[39/123]	Time 0.075 (0.164)	Data 0.022 (0.098)	
[40/123]	Time 0.062 (0.161)	Data 0.007 (0.095)	
[41/123]	Time 0.066 (0.159)	Data 0.012 (0.093)	
[42/123]	Time 0.063 (0.157)	Data 0.006 (0.091)	
[43/123]	Time 0.066 (0.155)	Data 0.006 (0.089)	
[44/123]	Time 0.074 (0.153)	Data 0.006 (0.087)	
[45/123]	Time 0.042 (0.150)	Data 0.001 (0.085)	
[46/123]	Time 0.057 (0.148)	Data 0.017 (0.084)	
[47/123]	Time 0.067 (0.146)	Data 0.013 (0.082)	
[48/123]	Time 0.050 (0.144)	Data 0.028 (0.081)	
[49/123]	Time 0.055 (0.143)	Data 0.010 (0.080)	
[50/123]	Time 0.111 (0.142)	Data 0.089 (0.080)	
[51/123]	Time 0.784 (0.155)	Data 0.713 (0.092)	
[52/123]	Time 0.054 (0.153)	Data 0.001 (0.091)	
[53/123]	Time 0.039 (0.151)	Data 0.001 (0.089)	
[54/123]	Time 0.080 (0.149)	Data 0.006 (0.087)	
[55/123]	Time 0.058 (0.148)	Data 0.007 (0.086)	
[56/123]	Time 0.040 (0.146)	Data 0.001 (0.084)	
[57/123]	Time 0.065 (0.144)	Data 0.013 (0.083)	
[58/123]	Time 0.043 (0.142)	Data 0.001 (0.082)	
[59/123]	Time 0.057 (0.141)	Data 0.016 (0.081)	
[60/123]	Time 0.053 (0.140)	Data 0.016 (0.080)	
[61/123]	Time 0.067 (0.138)	Data 0.022 (0.079)	
[62/123]	Time 0.064 (0.137)	Data 0.015 (0.078)	
[63/123]	Time 0.061 (0.136)	Data 0.001 (0.076)	
[64/123]	Time 0.040 (0.134)	Data 0.001 (0.075)	
[65/123]	Time 0.066 (0.133)	Data 0.018 (0.074)	
[66/123]	Time 0.303 (0.136)	Data 0.238 (0.077)	
[67/123]	Time 0.331 (0.139)	Data 0.283 (0.080)	
[68/123]	Time 0.055 (0.138)	Data 0.013 (0.079)	
[69/123]	Time 0.053 (0.136)	Data 0.001 (0.078)	
[70/123]	Time 0.093 (0.136)	Data 0.014 (0.077)	
[71/123]	Time 0.046 (0.135)	Data 0.001 (0.076)	
[72/123]	Time 0.054 (0.133)	Data 0.015 (0.075)	
[73/123]	Time 0.068 (0.133)	Data 0.010 (0.074)	
[74/123]	Time 0.053 (0.131)	Data 0.013 (0.073)	
[75/123]	Time 0.054 (0.130)	Data 0.012 (0.072)	
[76/123]	Time 0.042 (0.129)	Data 0.018 (0.072)	
[77/123]	Time 0.054 (0.128)	Data 0.001 (0.071)	
[78/123]	Time 0.055 (0.127)	Data 0.006 (0.070)	
[79/123]	Time 0.060 (0.127)	Data 0.006 (0.069)	
[80/123]	Time 0.068 (0.126)	Data 0.015 (0.068)	
[81/123]	Time 0.168 (0.126)	Data 0.088 (0.069)	
[82/123]	Time 0.671 (0.133)	Data 0.601 (0.075)	
[83/123]	Time 0.053 (0.132)	Data 0.011 (0.074)	
[84/123]	Time 0.049 (0.131)	Data 0.014 (0.074)	
[85/123]	Time 0.064 (0.130)	Data 0.006 (0.073)	
[86/123]	Time 0.053 (0.129)	Data 0.013 (0.072)	
[87/123]	Time 0.041 (0.128)	Data 0.001 (0.071)	
[88/123]	Time 0.076 (0.128)	Data 0.031 (0.071)	
[89/123]	Time 0.048 (0.127)	Data 0.010 (0.070)	
[90/123]	Time 0.058 (0.126)	Data 0.014 (0.070)	
[91/123]	Time 0.036 (0.125)	Data 0.001 (0.069)	
[92/123]	Time 0.044 (0.124)	Data 0.001 (0.068)	
[93/123]	Time 0.309 (0.126)	Data 0.267 (0.070)	
[94/123]	Time 0.067 (0.126)	Data 0.000 (0.070)	
[95/123]	Time 0.040 (0.125)	Data 0.000 (0.069)	
[96/123]	Time 0.049 (0.124)	Data 0.000 (0.068)	
[97/123]	Time 0.061 (0.123)	Data 0.000 (0.067)	
[98/123]	Time 0.402 (0.126)	Data 0.360 (0.070)	
[99/123]	Time 0.066 (0.125)	Data 0.000 (0.070)	
[100/123]	Time 0.046 (0.125)	Data 0.001 (0.069)	
[101/123]	Time 0.038 (0.124)	Data 0.000 (0.068)	
[102/123]	Time 0.024 (0.123)	Data 0.000 (0.068)	
[103/123]	Time 0.028 (0.122)	Data 0.001 (0.067)	
[104/123]	Time 0.025 (0.121)	Data 0.001 (0.066)	
[105/123]	Time 0.025 (0.120)	Data 0.001 (0.066)	
[106/123]	Time 0.024 (0.119)	Data 0.001 (0.065)	
[107/123]	Time 0.021 (0.118)	Data 0.001 (0.065)	
[108/123]	Time 0.018 (0.117)	Data 0.000 (0.064)	
[109/123]	Time 0.078 (0.117)	Data 0.060 (0.064)	
[110/123]	Time 0.017 (0.116)	Data 0.000 (0.063)	
[111/123]	Time 0.017 (0.115)	Data 0.000 (0.063)	
[112/123]	Time 0.016 (0.114)	Data 0.000 (0.062)	
[113/123]	Time 0.016 (0.113)	Data 0.000 (0.062)	
[114/123]	Time 0.186 (0.114)	Data 0.170 (0.063)	
[115/123]	Time 0.016 (0.113)	Data 0.000 (0.062)	
[116/123]	Time 0.016 (0.112)	Data 0.000 (0.062)	
[117/123]	Time 0.016 (0.111)	Data 0.000 (0.061)	
[118/123]	Time 0.016 (0.111)	Data 0.000 (0.060)	
[119/123]	Time 0.016 (0.110)	Data 0.000 (0.060)	
[120/123]	Time 0.016 (0.109)	Data 0.000 (0.059)	
[121/123]	Time 0.016 (0.108)	Data 0.000 (0.059)	
[122/123]	Time 0.016 (0.108)	Data 0.000 (0.058)	
[123/123]	Time 0.016 (0.107)	Data 0.000 (0.058)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.001', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.001, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=16, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.001/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs16_lr0.001/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.546 (4.546)	Data 3.757 (3.757)	
[2/123]	Time 0.014 (2.280)	Data 0.001 (1.879)	
[3/123]	Time 0.014 (1.525)	Data 0.000 (1.253)	
[4/123]	Time 0.014 (1.147)	Data 0.000 (0.939)	
[5/123]	Time 0.014 (0.920)	Data 0.000 (0.752)	
[6/123]	Time 0.014 (0.769)	Data 0.000 (0.626)	
[7/123]	Time 0.015 (0.662)	Data 0.001 (0.537)	
[8/123]	Time 0.015 (0.581)	Data 0.001 (0.470)	
[9/123]	Time 0.015 (0.518)	Data 0.001 (0.418)	
[10/123]	Time 0.015 (0.468)	Data 0.001 (0.376)	
[11/123]	Time 0.016 (0.426)	Data 0.001 (0.342)	
[12/123]	Time 0.014 (0.392)	Data 0.001 (0.314)	
[13/123]	Time 0.019 (0.363)	Data 0.006 (0.290)	
[14/123]	Time 0.029 (0.339)	Data 0.015 (0.270)	
[15/123]	Time 0.040 (0.320)	Data 0.014 (0.253)	
[16/123]	Time 0.215 (0.313)	Data 0.201 (0.250)	
[17/123]	Time 0.029 (0.296)	Data 0.015 (0.236)	
[18/123]	Time 0.028 (0.281)	Data 0.014 (0.224)	
[19/123]	Time 0.032 (0.268)	Data 0.007 (0.212)	
[20/123]	Time 0.267 (0.268)	Data 0.238 (0.214)	
[21/123]	Time 0.015 (0.256)	Data 0.001 (0.203)	
[22/123]	Time 0.037 (0.246)	Data 0.003 (0.194)	
[23/123]	Time 0.014 (0.236)	Data 0.001 (0.186)	
[24/123]	Time 0.031 (0.228)	Data 0.002 (0.178)	
[25/123]	Time 0.057 (0.221)	Data 0.038 (0.173)	
[26/123]	Time 0.030 (0.213)	Data 0.001 (0.166)	
[27/123]	Time 0.028 (0.206)	Data 0.001 (0.160)	
[28/123]	Time 0.014 (0.200)	Data 0.001 (0.154)	
[29/123]	Time 0.043 (0.194)	Data 0.018 (0.150)	
[30/123]	Time 0.015 (0.188)	Data 0.001 (0.145)	
[31/123]	Time 0.030 (0.183)	Data 0.006 (0.140)	
[32/123]	Time 0.040 (0.179)	Data 0.005 (0.136)	
[33/123]	Time 0.031 (0.174)	Data 0.001 (0.132)	
[34/123]	Time 0.160 (0.174)	Data 0.138 (0.132)	
[35/123]	Time 0.174 (0.174)	Data 0.160 (0.133)	
[36/123]	Time 0.333 (0.178)	Data 0.319 (0.138)	
[37/123]	Time 0.088 (0.176)	Data 0.074 (0.136)	
[38/123]	Time 0.047 (0.172)	Data 0.015 (0.133)	
[39/123]	Time 0.203 (0.173)	Data 0.189 (0.134)	
[40/123]	Time 0.014 (0.169)	Data 0.000 (0.131)	
[41/123]	Time 0.030 (0.166)	Data 0.001 (0.128)	
[42/123]	Time 0.027 (0.162)	Data 0.001 (0.125)	
[43/123]	Time 0.028 (0.159)	Data 0.009 (0.122)	
[44/123]	Time 0.015 (0.156)	Data 0.001 (0.119)	
[45/123]	Time 0.031 (0.153)	Data 0.001 (0.117)	
[46/123]	Time 0.153 (0.153)	Data 0.139 (0.117)	
[47/123]	Time 0.032 (0.151)	Data 0.018 (0.115)	
[48/123]	Time 0.042 (0.148)	Data 0.001 (0.113)	
[49/123]	Time 0.017 (0.146)	Data 0.001 (0.111)	
[50/123]	Time 0.569 (0.154)	Data 0.555 (0.119)	
[51/123]	Time 0.035 (0.152)	Data 0.012 (0.117)	
[52/123]	Time 0.031 (0.150)	Data 0.007 (0.115)	
[53/123]	Time 0.017 (0.147)	Data 0.004 (0.113)	
[54/123]	Time 0.054 (0.145)	Data 0.026 (0.112)	
[55/123]	Time 0.361 (0.149)	Data 0.342 (0.116)	
[56/123]	Time 0.030 (0.147)	Data 0.012 (0.114)	
[57/123]	Time 0.038 (0.145)	Data 0.013 (0.112)	
[58/123]	Time 0.024 (0.143)	Data 0.011 (0.110)	
[59/123]	Time 0.030 (0.141)	Data 0.017 (0.109)	
[60/123]	Time 0.049 (0.140)	Data 0.017 (0.107)	
[61/123]	Time 0.026 (0.138)	Data 0.012 (0.106)	
[62/123]	Time 0.229 (0.139)	Data 0.201 (0.107)	
[63/123]	Time 0.035 (0.138)	Data 0.001 (0.106)	
[64/123]	Time 0.027 (0.136)	Data 0.001 (0.104)	
[65/123]	Time 0.016 (0.134)	Data 0.001 (0.102)	
[66/123]	Time 0.551 (0.140)	Data 0.521 (0.109)	
[67/123]	Time 0.029 (0.139)	Data 0.000 (0.107)	
[68/123]	Time 0.031 (0.137)	Data 0.001 (0.105)	
[69/123]	Time 0.056 (0.136)	Data 0.001 (0.104)	
[70/123]	Time 0.031 (0.134)	Data 0.001 (0.102)	
[71/123]	Time 0.353 (0.138)	Data 0.338 (0.106)	
[72/123]	Time 0.016 (0.136)	Data 0.001 (0.104)	
[73/123]	Time 0.048 (0.135)	Data 0.001 (0.103)	
[74/123]	Time 0.018 (0.133)	Data 0.001 (0.102)	
[75/123]	Time 0.018 (0.131)	Data 0.001 (0.100)	
[76/123]	Time 0.031 (0.130)	Data 0.016 (0.099)	
[77/123]	Time 0.021 (0.129)	Data 0.006 (0.098)	
[78/123]	Time 0.016 (0.127)	Data 0.001 (0.097)	
[79/123]	Time 0.230 (0.129)	Data 0.214 (0.098)	
[80/123]	Time 0.037 (0.127)	Data 0.007 (0.097)	
[81/123]	Time 0.037 (0.126)	Data 0.002 (0.096)	
[82/123]	Time 0.525 (0.131)	Data 0.510 (0.101)	
[83/123]	Time 0.035 (0.130)	Data 0.020 (0.100)	
[84/123]	Time 0.027 (0.129)	Data 0.002 (0.099)	
[85/123]	Time 0.030 (0.128)	Data 0.012 (0.098)	
[86/123]	Time 0.031 (0.127)	Data 0.001 (0.097)	
[87/123]	Time 0.344 (0.129)	Data 0.329 (0.099)	
[88/123]	Time 0.028 (0.128)	Data 0.013 (0.098)	
[89/123]	Time 0.032 (0.127)	Data 0.017 (0.097)	
[90/123]	Time 0.028 (0.126)	Data 0.013 (0.096)	
[91/123]	Time 0.028 (0.125)	Data 0.013 (0.096)	
[92/123]	Time 0.031 (0.124)	Data 0.001 (0.094)	
[93/123]	Time 0.028 (0.123)	Data 0.000 (0.093)	
[94/123]	Time 0.027 (0.122)	Data 0.000 (0.092)	
[95/123]	Time 0.152 (0.122)	Data 0.135 (0.093)	
[96/123]	Time 0.022 (0.121)	Data 0.001 (0.092)	
[97/123]	Time 0.021 (0.120)	Data 0.006 (0.091)	
[98/123]	Time 0.660 (0.125)	Data 0.639 (0.097)	
[99/123]	Time 0.016 (0.124)	Data 0.001 (0.096)	
[100/123]	Time 0.017 (0.123)	Data 0.001 (0.095)	
[101/123]	Time 0.022 (0.122)	Data 0.000 (0.094)	
[102/123]	Time 0.015 (0.121)	Data 0.001 (0.093)	
[103/123]	Time 0.128 (0.121)	Data 0.114 (0.093)	
[104/123]	Time 0.015 (0.120)	Data 0.001 (0.092)	
[105/123]	Time 0.015 (0.119)	Data 0.001 (0.091)	
[106/123]	Time 0.015 (0.118)	Data 0.001 (0.091)	
[107/123]	Time 0.015 (0.117)	Data 0.001 (0.090)	
[108/123]	Time 0.015 (0.116)	Data 0.001 (0.089)	
[109/123]	Time 0.014 (0.115)	Data 0.001 (0.088)	
[110/123]	Time 0.015 (0.114)	Data 0.000 (0.087)	
[111/123]	Time 0.166 (0.115)	Data 0.152 (0.088)	
[112/123]	Time 0.014 (0.114)	Data 0.000 (0.087)	
[113/123]	Time 0.015 (0.113)	Data 0.000 (0.086)	
[114/123]	Time 0.209 (0.114)	Data 0.196 (0.087)	
[115/123]	Time 0.026 (0.113)	Data 0.013 (0.087)	
[116/123]	Time 0.013 (0.112)	Data 0.000 (0.086)	
[117/123]	Time 0.013 (0.111)	Data 0.000 (0.085)	
[118/123]	Time 0.013 (0.111)	Data 0.000 (0.084)	
[119/123]	Time 0.015 (0.110)	Data 0.002 (0.084)	
[120/123]	Time 0.013 (0.109)	Data 0.000 (0.083)	
[121/123]	Time 0.013 (0.108)	Data 0.000 (0.082)	
[122/123]	Time 0.013 (0.107)	Data 0.000 (0.082)	
[123/123]	Time 0.013 (0.107)	Data 0.000 (0.081)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.001', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.001, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=16, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.001/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs16_lr0.001/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.568 (4.568)	Data 3.902 (3.902)	
[2/123]	Time 0.024 (2.296)	Data 0.000 (1.951)	
[3/123]	Time 0.019 (1.537)	Data 0.001 (1.301)	
[4/123]	Time 0.019 (1.157)	Data 0.001 (0.976)	
[5/123]	Time 0.019 (0.930)	Data 0.001 (0.781)	
[6/123]	Time 0.019 (0.778)	Data 0.000 (0.651)	
[7/123]	Time 0.025 (0.670)	Data 0.000 (0.558)	
[8/123]	Time 0.030 (0.590)	Data 0.000 (0.488)	
[9/123]	Time 0.029 (0.528)	Data 0.000 (0.434)	
[10/123]	Time 0.031 (0.478)	Data 0.000 (0.391)	
[11/123]	Time 0.024 (0.437)	Data 0.001 (0.355)	
[12/123]	Time 0.027 (0.403)	Data 0.001 (0.326)	
[13/123]	Time 0.067 (0.377)	Data 0.016 (0.302)	
[14/123]	Time 0.053 (0.354)	Data 0.001 (0.280)	
[15/123]	Time 0.035 (0.333)	Data 0.006 (0.262)	
[16/123]	Time 0.059 (0.316)	Data 0.001 (0.246)	
[17/123]	Time 0.056 (0.300)	Data 0.008 (0.232)	
[18/123]	Time 0.027 (0.285)	Data 0.003 (0.219)	
[19/123]	Time 0.056 (0.273)	Data 0.003 (0.208)	
[20/123]	Time 0.032 (0.261)	Data 0.001 (0.197)	
[21/123]	Time 0.062 (0.252)	Data 0.001 (0.188)	
[22/123]	Time 0.026 (0.241)	Data 0.001 (0.180)	
[23/123]	Time 0.056 (0.233)	Data 0.013 (0.172)	
[24/123]	Time 0.055 (0.226)	Data 0.013 (0.166)	
[25/123]	Time 0.044 (0.219)	Data 0.004 (0.159)	
[26/123]	Time 0.054 (0.212)	Data 0.015 (0.154)	
[27/123]	Time 0.041 (0.206)	Data 0.001 (0.148)	
[28/123]	Time 0.058 (0.201)	Data 0.019 (0.143)	
[29/123]	Time 0.053 (0.196)	Data 0.011 (0.139)	
[30/123]	Time 0.057 (0.191)	Data 0.017 (0.135)	
[31/123]	Time 0.071 (0.187)	Data 0.016 (0.131)	
[32/123]	Time 0.080 (0.184)	Data 0.020 (0.127)	
[33/123]	Time 0.062 (0.180)	Data 0.013 (0.124)	
[34/123]	Time 0.022 (0.175)	Data 0.001 (0.120)	
[35/123]	Time 0.052 (0.172)	Data 0.014 (0.117)	
[36/123]	Time 0.137 (0.171)	Data 0.110 (0.117)	
[37/123]	Time 0.250 (0.173)	Data 0.210 (0.120)	
[38/123]	Time 0.033 (0.169)	Data 0.001 (0.116)	
[39/123]	Time 0.051 (0.166)	Data 0.001 (0.114)	
[40/123]	Time 0.045 (0.163)	Data 0.003 (0.111)	
[41/123]	Time 0.058 (0.161)	Data 0.013 (0.108)	
[42/123]	Time 0.061 (0.158)	Data 0.015 (0.106)	
[43/123]	Time 0.116 (0.157)	Data 0.074 (0.105)	
[44/123]	Time 0.093 (0.156)	Data 0.051 (0.104)	
[45/123]	Time 0.254 (0.158)	Data 0.188 (0.106)	
[46/123]	Time 0.058 (0.156)	Data 0.001 (0.104)	
[47/123]	Time 0.069 (0.154)	Data 0.011 (0.102)	
[48/123]	Time 0.052 (0.152)	Data 0.007 (0.100)	
[49/123]	Time 0.059 (0.150)	Data 0.012 (0.098)	
[50/123]	Time 0.078 (0.149)	Data 0.017 (0.096)	
[51/123]	Time 0.045 (0.147)	Data 0.001 (0.095)	
[52/123]	Time 0.143 (0.146)	Data 0.102 (0.095)	
[53/123]	Time 0.636 (0.156)	Data 0.574 (0.104)	
[54/123]	Time 0.042 (0.154)	Data 0.001 (0.102)	
[55/123]	Time 0.064 (0.152)	Data 0.009 (0.100)	
[56/123]	Time 0.052 (0.150)	Data 0.008 (0.098)	
[57/123]	Time 0.051 (0.148)	Data 0.017 (0.097)	
[58/123]	Time 0.065 (0.147)	Data 0.003 (0.095)	
[59/123]	Time 0.026 (0.145)	Data 0.001 (0.094)	
[60/123]	Time 0.060 (0.144)	Data 0.003 (0.092)	
[61/123]	Time 0.176 (0.144)	Data 0.153 (0.093)	
[62/123]	Time 0.059 (0.143)	Data 0.015 (0.092)	
[63/123]	Time 0.079 (0.142)	Data 0.013 (0.091)	
[64/123]	Time 0.036 (0.140)	Data 0.011 (0.089)	
[65/123]	Time 0.064 (0.139)	Data 0.016 (0.088)	
[66/123]	Time 0.042 (0.137)	Data 0.001 (0.087)	
[67/123]	Time 0.048 (0.136)	Data 0.006 (0.086)	
[68/123]	Time 0.064 (0.135)	Data 0.007 (0.085)	
[69/123]	Time 0.510 (0.140)	Data 0.474 (0.090)	
[70/123]	Time 0.066 (0.139)	Data 0.013 (0.089)	
[71/123]	Time 0.051 (0.138)	Data 0.011 (0.088)	
[72/123]	Time 0.051 (0.137)	Data 0.013 (0.087)	
[73/123]	Time 0.071 (0.136)	Data 0.006 (0.086)	
[74/123]	Time 0.059 (0.135)	Data 0.006 (0.085)	
[75/123]	Time 0.069 (0.134)	Data 0.001 (0.084)	
[76/123]	Time 0.046 (0.133)	Data 0.013 (0.083)	
[77/123]	Time 0.065 (0.132)	Data 0.005 (0.082)	
[78/123]	Time 0.056 (0.131)	Data 0.010 (0.081)	
[79/123]	Time 0.191 (0.132)	Data 0.167 (0.082)	
[80/123]	Time 0.042 (0.131)	Data 0.001 (0.081)	
[81/123]	Time 0.053 (0.130)	Data 0.011 (0.080)	
[82/123]	Time 0.073 (0.129)	Data 0.018 (0.079)	
[83/123]	Time 0.076 (0.128)	Data 0.001 (0.078)	
[84/123]	Time 0.215 (0.129)	Data 0.164 (0.079)	
[85/123]	Time 0.382 (0.132)	Data 0.339 (0.082)	
[86/123]	Time 0.092 (0.132)	Data 0.018 (0.082)	
[87/123]	Time 0.054 (0.131)	Data 0.001 (0.081)	
[88/123]	Time 0.049 (0.130)	Data 0.009 (0.080)	
[89/123]	Time 0.056 (0.129)	Data 0.006 (0.079)	
[90/123]	Time 0.028 (0.128)	Data 0.001 (0.078)	
[91/123]	Time 0.034 (0.127)	Data 0.001 (0.077)	
[92/123]	Time 0.070 (0.127)	Data 0.001 (0.077)	
[93/123]	Time 0.054 (0.126)	Data 0.001 (0.076)	
[94/123]	Time 0.051 (0.125)	Data 0.001 (0.075)	
[95/123]	Time 0.035 (0.124)	Data 0.001 (0.074)	
[96/123]	Time 0.460 (0.127)	Data 0.434 (0.078)	
[97/123]	Time 0.057 (0.127)	Data 0.001 (0.077)	
[98/123]	Time 0.035 (0.126)	Data 0.009 (0.076)	
[99/123]	Time 0.036 (0.125)	Data 0.001 (0.076)	
[100/123]	Time 0.045 (0.124)	Data 0.001 (0.075)	
[101/123]	Time 0.059 (0.123)	Data 0.026 (0.074)	
[102/123]	Time 0.040 (0.123)	Data 0.000 (0.074)	
[103/123]	Time 0.030 (0.122)	Data 0.000 (0.073)	
[104/123]	Time 0.032 (0.121)	Data 0.001 (0.072)	
[105/123]	Time 0.037 (0.120)	Data 0.001 (0.072)	
[106/123]	Time 0.102 (0.120)	Data 0.063 (0.072)	
[107/123]	Time 0.034 (0.119)	Data 0.001 (0.071)	
[108/123]	Time 0.019 (0.118)	Data 0.001 (0.070)	
[109/123]	Time 0.019 (0.117)	Data 0.001 (0.070)	
[110/123]	Time 0.018 (0.116)	Data 0.000 (0.069)	
[111/123]	Time 0.143 (0.117)	Data 0.125 (0.069)	
[112/123]	Time 0.176 (0.117)	Data 0.158 (0.070)	
[113/123]	Time 0.017 (0.116)	Data 0.000 (0.070)	
[114/123]	Time 0.017 (0.115)	Data 0.000 (0.069)	
[115/123]	Time 0.017 (0.115)	Data 0.000 (0.068)	
[116/123]	Time 0.017 (0.114)	Data 0.000 (0.068)	
[117/123]	Time 0.038 (0.113)	Data 0.021 (0.067)	
[118/123]	Time 0.017 (0.112)	Data 0.000 (0.067)	
[119/123]	Time 0.017 (0.111)	Data 0.000 (0.066)	
[120/123]	Time 0.017 (0.111)	Data 0.000 (0.066)	
[121/123]	Time 0.018 (0.110)	Data 0.000 (0.065)	
[122/123]	Time 0.017 (0.109)	Data 0.000 (0.065)	
[123/123]	Time 0.017 (0.108)	Data 0.000 (0.064)	
end bs16
start bs32
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.1', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.1, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=32, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.1/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.1/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.320 (4.320)	Data 3.370 (3.370)	
[2/123]	Time 0.015 (2.167)	Data 0.001 (1.686)	
[3/123]	Time 0.014 (1.449)	Data 0.000 (1.124)	
[4/123]	Time 0.014 (1.091)	Data 0.000 (0.843)	
[5/123]	Time 0.015 (0.875)	Data 0.001 (0.674)	
[6/123]	Time 0.015 (0.732)	Data 0.001 (0.562)	
[7/123]	Time 0.014 (0.630)	Data 0.000 (0.482)	
[8/123]	Time 0.015 (0.553)	Data 0.001 (0.422)	
[9/123]	Time 0.015 (0.493)	Data 0.001 (0.375)	
[10/123]	Time 0.022 (0.446)	Data 0.007 (0.338)	
[11/123]	Time 0.110 (0.415)	Data 0.096 (0.316)	
[12/123]	Time 0.018 (0.382)	Data 0.001 (0.290)	
[13/123]	Time 0.033 (0.355)	Data 0.010 (0.268)	
[14/123]	Time 0.041 (0.333)	Data 0.016 (0.250)	
[15/123]	Time 0.027 (0.313)	Data 0.001 (0.234)	
[16/123]	Time 0.020 (0.294)	Data 0.001 (0.219)	
[17/123]	Time 0.030 (0.279)	Data 0.003 (0.206)	
[18/123]	Time 0.025 (0.265)	Data 0.001 (0.195)	
[19/123]	Time 0.029 (0.252)	Data 0.013 (0.185)	
[20/123]	Time 0.018 (0.241)	Data 0.005 (0.176)	
[21/123]	Time 0.056 (0.232)	Data 0.041 (0.170)	
[22/123]	Time 0.019 (0.222)	Data 0.006 (0.163)	
[23/123]	Time 0.025 (0.213)	Data 0.011 (0.156)	
[24/123]	Time 0.043 (0.206)	Data 0.030 (0.151)	
[25/123]	Time 0.025 (0.199)	Data 0.010 (0.145)	
[26/123]	Time 0.030 (0.193)	Data 0.012 (0.140)	
[27/123]	Time 0.078 (0.188)	Data 0.065 (0.137)	
[28/123]	Time 0.014 (0.182)	Data 0.001 (0.132)	
[29/123]	Time 0.014 (0.176)	Data 0.001 (0.128)	
[30/123]	Time 0.065 (0.173)	Data 0.044 (0.125)	
[31/123]	Time 0.014 (0.168)	Data 0.001 (0.121)	
[32/123]	Time 0.023 (0.163)	Data 0.009 (0.117)	
[33/123]	Time 0.033 (0.159)	Data 0.020 (0.114)	
[34/123]	Time 0.574 (0.171)	Data 0.560 (0.128)	
[35/123]	Time 0.029 (0.167)	Data 0.015 (0.124)	
[36/123]	Time 0.020 (0.163)	Data 0.006 (0.121)	
[37/123]	Time 0.341 (0.168)	Data 0.326 (0.127)	
[38/123]	Time 0.054 (0.165)	Data 0.025 (0.124)	
[39/123]	Time 0.014 (0.161)	Data 0.001 (0.121)	
[40/123]	Time 0.026 (0.158)	Data 0.001 (0.118)	
[41/123]	Time 0.042 (0.155)	Data 0.005 (0.115)	
[42/123]	Time 0.017 (0.152)	Data 0.001 (0.112)	
[43/123]	Time 0.035 (0.149)	Data 0.005 (0.110)	
[44/123]	Time 0.042 (0.146)	Data 0.002 (0.107)	
[45/123]	Time 0.480 (0.154)	Data 0.458 (0.115)	
[46/123]	Time 0.036 (0.151)	Data 0.000 (0.113)	
[47/123]	Time 0.034 (0.149)	Data 0.001 (0.110)	
[48/123]	Time 0.034 (0.146)	Data 0.004 (0.108)	
[49/123]	Time 0.048 (0.144)	Data 0.006 (0.106)	
[50/123]	Time 0.299 (0.147)	Data 0.284 (0.110)	
[51/123]	Time 0.042 (0.145)	Data 0.017 (0.108)	
[52/123]	Time 0.025 (0.143)	Data 0.010 (0.106)	
[53/123]	Time 0.136 (0.143)	Data 0.121 (0.106)	
[54/123]	Time 0.050 (0.141)	Data 0.016 (0.104)	
[55/123]	Time 0.036 (0.139)	Data 0.001 (0.103)	
[56/123]	Time 0.030 (0.137)	Data 0.001 (0.101)	
[57/123]	Time 0.035 (0.136)	Data 0.001 (0.099)	
[58/123]	Time 0.018 (0.134)	Data 0.004 (0.097)	
[59/123]	Time 0.019 (0.132)	Data 0.001 (0.096)	
[60/123]	Time 0.383 (0.136)	Data 0.337 (0.100)	
[61/123]	Time 0.287 (0.138)	Data 0.259 (0.102)	
[62/123]	Time 0.028 (0.137)	Data 0.001 (0.101)	
[63/123]	Time 0.032 (0.135)	Data 0.001 (0.099)	
[64/123]	Time 0.015 (0.133)	Data 0.001 (0.098)	
[65/123]	Time 0.015 (0.131)	Data 0.001 (0.096)	
[66/123]	Time 0.377 (0.135)	Data 0.347 (0.100)	
[67/123]	Time 0.032 (0.133)	Data 0.001 (0.098)	
[68/123]	Time 0.028 (0.132)	Data 0.001 (0.097)	
[69/123]	Time 0.054 (0.131)	Data 0.002 (0.096)	
[70/123]	Time 0.046 (0.129)	Data 0.010 (0.094)	
[71/123]	Time 0.291 (0.132)	Data 0.277 (0.097)	
[72/123]	Time 0.036 (0.130)	Data 0.012 (0.096)	
[73/123]	Time 0.028 (0.129)	Data 0.006 (0.095)	
[74/123]	Time 0.032 (0.128)	Data 0.006 (0.093)	
[75/123]	Time 0.024 (0.126)	Data 0.009 (0.092)	
[76/123]	Time 0.269 (0.128)	Data 0.254 (0.094)	
[77/123]	Time 0.072 (0.127)	Data 0.057 (0.094)	
[78/123]	Time 0.044 (0.126)	Data 0.008 (0.093)	
[79/123]	Time 0.016 (0.125)	Data 0.001 (0.092)	
[80/123]	Time 0.142 (0.125)	Data 0.115 (0.092)	
[81/123]	Time 0.020 (0.124)	Data 0.000 (0.091)	
[82/123]	Time 0.149 (0.124)	Data 0.134 (0.091)	
[83/123]	Time 0.029 (0.123)	Data 0.014 (0.090)	
[84/123]	Time 0.031 (0.122)	Data 0.006 (0.089)	
[85/123]	Time 0.029 (0.121)	Data 0.014 (0.089)	
[86/123]	Time 0.038 (0.120)	Data 0.000 (0.088)	
[87/123]	Time 0.547 (0.125)	Data 0.533 (0.093)	
[88/123]	Time 0.030 (0.124)	Data 0.016 (0.092)	
[89/123]	Time 0.020 (0.123)	Data 0.006 (0.091)	
[90/123]	Time 0.031 (0.122)	Data 0.017 (0.090)	
[91/123]	Time 0.033 (0.121)	Data 0.013 (0.089)	
[92/123]	Time 0.123 (0.121)	Data 0.108 (0.089)	
[93/123]	Time 0.364 (0.123)	Data 0.341 (0.092)	
[94/123]	Time 0.019 (0.122)	Data 0.001 (0.091)	
[95/123]	Time 0.027 (0.121)	Data 0.001 (0.090)	
[96/123]	Time 0.266 (0.123)	Data 0.252 (0.092)	
[97/123]	Time 0.031 (0.122)	Data 0.000 (0.091)	
[98/123]	Time 0.028 (0.121)	Data 0.000 (0.090)	
[99/123]	Time 0.022 (0.120)	Data 0.000 (0.089)	
[100/123]	Time 0.015 (0.119)	Data 0.001 (0.088)	
[101/123]	Time 0.023 (0.118)	Data 0.001 (0.087)	
[102/123]	Time 0.017 (0.117)	Data 0.003 (0.086)	
[103/123]	Time 0.396 (0.119)	Data 0.382 (0.089)	
[104/123]	Time 0.014 (0.118)	Data 0.000 (0.088)	
[105/123]	Time 0.015 (0.117)	Data 0.001 (0.088)	
[106/123]	Time 0.015 (0.116)	Data 0.001 (0.087)	
[107/123]	Time 0.014 (0.116)	Data 0.001 (0.086)	
[108/123]	Time 0.014 (0.115)	Data 0.000 (0.085)	
[109/123]	Time 0.095 (0.114)	Data 0.081 (0.085)	
[110/123]	Time 0.015 (0.114)	Data 0.001 (0.084)	
[111/123]	Time 0.014 (0.113)	Data 0.000 (0.084)	
[112/123]	Time 0.169 (0.113)	Data 0.156 (0.084)	
[113/123]	Time 0.012 (0.112)	Data 0.000 (0.084)	
[114/123]	Time 0.013 (0.111)	Data 0.000 (0.083)	
[115/123]	Time 0.013 (0.110)	Data 0.000 (0.082)	
[116/123]	Time 0.013 (0.110)	Data 0.000 (0.081)	
[117/123]	Time 0.013 (0.109)	Data 0.000 (0.081)	
[118/123]	Time 0.013 (0.108)	Data 0.000 (0.080)	
[119/123]	Time 0.124 (0.108)	Data 0.111 (0.080)	
[120/123]	Time 0.012 (0.107)	Data 0.000 (0.080)	
[121/123]	Time 0.013 (0.107)	Data 0.000 (0.079)	
[122/123]	Time 0.013 (0.106)	Data 0.000 (0.078)	
[123/123]	Time 0.013 (0.105)	Data 0.000 (0.078)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.1', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.1, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=32, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.1/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.1/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 5.107 (5.107)	Data 4.474 (4.474)	
[2/123]	Time 0.026 (2.566)	Data 0.001 (2.237)	
[3/123]	Time 0.018 (1.717)	Data 0.000 (1.492)	
[4/123]	Time 0.018 (1.292)	Data 0.000 (1.119)	
[5/123]	Time 0.018 (1.037)	Data 0.000 (0.895)	
[6/123]	Time 0.018 (0.868)	Data 0.001 (0.746)	
[7/123]	Time 0.018 (0.746)	Data 0.001 (0.640)	
[8/123]	Time 0.018 (0.655)	Data 0.001 (0.560)	
[9/123]	Time 0.018 (0.584)	Data 0.000 (0.498)	
[10/123]	Time 0.020 (0.528)	Data 0.001 (0.448)	
[11/123]	Time 0.023 (0.482)	Data 0.001 (0.407)	
[12/123]	Time 0.022 (0.444)	Data 0.001 (0.373)	
[13/123]	Time 0.030 (0.412)	Data 0.001 (0.345)	
[14/123]	Time 0.031 (0.385)	Data 0.001 (0.320)	
[15/123]	Time 0.036 (0.361)	Data 0.001 (0.299)	
[16/123]	Time 0.031 (0.341)	Data 0.001 (0.280)	
[17/123]	Time 0.034 (0.323)	Data 0.001 (0.264)	
[18/123]	Time 0.035 (0.307)	Data 0.001 (0.249)	
[19/123]	Time 0.031 (0.292)	Data 0.001 (0.236)	
[20/123]	Time 0.032 (0.279)	Data 0.001 (0.224)	
[21/123]	Time 0.053 (0.268)	Data 0.011 (0.214)	
[22/123]	Time 0.048 (0.258)	Data 0.001 (0.205)	
[23/123]	Time 0.044 (0.249)	Data 0.001 (0.196)	
[24/123]	Time 0.055 (0.241)	Data 0.003 (0.188)	
[25/123]	Time 0.054 (0.233)	Data 0.001 (0.180)	
[26/123]	Time 0.051 (0.226)	Data 0.005 (0.173)	
[27/123]	Time 0.036 (0.219)	Data 0.001 (0.167)	
[28/123]	Time 0.029 (0.213)	Data 0.001 (0.161)	
[29/123]	Time 0.032 (0.206)	Data 0.001 (0.156)	
[30/123]	Time 0.030 (0.201)	Data 0.001 (0.150)	
[31/123]	Time 0.031 (0.195)	Data 0.001 (0.146)	
[32/123]	Time 0.032 (0.190)	Data 0.001 (0.141)	
[33/123]	Time 0.034 (0.185)	Data 0.001 (0.137)	
[34/123]	Time 0.221 (0.186)	Data 0.176 (0.138)	
[35/123]	Time 0.508 (0.195)	Data 0.480 (0.148)	
[36/123]	Time 0.061 (0.192)	Data 0.002 (0.144)	
[37/123]	Time 0.071 (0.188)	Data 0.001 (0.140)	
[38/123]	Time 0.037 (0.184)	Data 0.001 (0.136)	
[39/123]	Time 0.053 (0.181)	Data 0.001 (0.133)	
[40/123]	Time 0.027 (0.177)	Data 0.000 (0.129)	
[41/123]	Time 0.226 (0.178)	Data 0.175 (0.131)	
[42/123]	Time 0.052 (0.175)	Data 0.015 (0.128)	
[43/123]	Time 0.046 (0.172)	Data 0.001 (0.125)	
[44/123]	Time 0.035 (0.169)	Data 0.013 (0.122)	
[45/123]	Time 0.035 (0.166)	Data 0.001 (0.120)	
[46/123]	Time 0.069 (0.164)	Data 0.001 (0.117)	
[47/123]	Time 0.035 (0.161)	Data 0.004 (0.115)	
[48/123]	Time 0.033 (0.159)	Data 0.001 (0.112)	
[49/123]	Time 0.100 (0.158)	Data 0.002 (0.110)	
[50/123]	Time 0.266 (0.160)	Data 0.204 (0.112)	
[51/123]	Time 0.238 (0.161)	Data 0.194 (0.114)	
[52/123]	Time 0.411 (0.166)	Data 0.373 (0.119)	
[53/123]	Time 0.066 (0.164)	Data 0.014 (0.117)	
[54/123]	Time 0.049 (0.162)	Data 0.010 (0.115)	
[55/123]	Time 0.069 (0.160)	Data 0.006 (0.113)	
[56/123]	Time 0.059 (0.159)	Data 0.000 (0.111)	
[57/123]	Time 0.041 (0.157)	Data 0.001 (0.109)	
[58/123]	Time 0.028 (0.154)	Data 0.001 (0.107)	
[59/123]	Time 0.027 (0.152)	Data 0.001 (0.105)	
[60/123]	Time 0.055 (0.151)	Data 0.016 (0.104)	
[61/123]	Time 0.051 (0.149)	Data 0.001 (0.102)	
[62/123]	Time 0.054 (0.147)	Data 0.001 (0.100)	
[63/123]	Time 0.047 (0.146)	Data 0.001 (0.099)	
[64/123]	Time 0.055 (0.144)	Data 0.016 (0.097)	
[65/123]	Time 0.091 (0.144)	Data 0.001 (0.096)	
[66/123]	Time 0.692 (0.152)	Data 0.640 (0.104)	
[67/123]	Time 0.044 (0.150)	Data 0.000 (0.103)	
[68/123]	Time 0.057 (0.149)	Data 0.008 (0.101)	
[69/123]	Time 0.073 (0.148)	Data 0.016 (0.100)	
[70/123]	Time 0.039 (0.146)	Data 0.001 (0.099)	
[71/123]	Time 0.053 (0.145)	Data 0.009 (0.097)	
[72/123]	Time 0.065 (0.144)	Data 0.022 (0.096)	
[73/123]	Time 0.080 (0.143)	Data 0.028 (0.095)	
[74/123]	Time 0.056 (0.142)	Data 0.015 (0.094)	
[75/123]	Time 0.056 (0.141)	Data 0.015 (0.093)	
[76/123]	Time 0.052 (0.139)	Data 0.001 (0.092)	
[77/123]	Time 0.055 (0.138)	Data 0.010 (0.091)	
[78/123]	Time 0.055 (0.137)	Data 0.015 (0.090)	
[79/123]	Time 0.045 (0.136)	Data 0.005 (0.089)	
[80/123]	Time 0.060 (0.135)	Data 0.001 (0.088)	
[81/123]	Time 0.055 (0.134)	Data 0.001 (0.087)	
[82/123]	Time 0.689 (0.141)	Data 0.662 (0.094)	
[83/123]	Time 0.045 (0.140)	Data 0.014 (0.093)	
[84/123]	Time 0.064 (0.139)	Data 0.001 (0.092)	
[85/123]	Time 0.055 (0.138)	Data 0.006 (0.091)	
[86/123]	Time 0.063 (0.137)	Data 0.001 (0.090)	
[87/123]	Time 0.056 (0.136)	Data 0.014 (0.089)	
[88/123]	Time 0.070 (0.135)	Data 0.013 (0.088)	
[89/123]	Time 0.061 (0.134)	Data 0.001 (0.087)	
[90/123]	Time 0.045 (0.133)	Data 0.001 (0.086)	
[91/123]	Time 0.057 (0.133)	Data 0.007 (0.085)	
[92/123]	Time 0.074 (0.132)	Data 0.000 (0.084)	
[93/123]	Time 0.040 (0.131)	Data 0.000 (0.083)	
[94/123]	Time 0.041 (0.130)	Data 0.001 (0.082)	
[95/123]	Time 0.057 (0.129)	Data 0.001 (0.081)	
[96/123]	Time 0.041 (0.128)	Data 0.000 (0.081)	
[97/123]	Time 0.032 (0.127)	Data 0.001 (0.080)	
[98/123]	Time 0.673 (0.133)	Data 0.630 (0.085)	
[99/123]	Time 0.055 (0.132)	Data 0.000 (0.085)	
[100/123]	Time 0.066 (0.131)	Data 0.024 (0.084)	
[101/123]	Time 0.047 (0.131)	Data 0.000 (0.083)	
[102/123]	Time 0.032 (0.130)	Data 0.001 (0.082)	
[103/123]	Time 0.035 (0.129)	Data 0.000 (0.082)	
[104/123]	Time 0.018 (0.128)	Data 0.000 (0.081)	
[105/123]	Time 0.018 (0.127)	Data 0.000 (0.080)	
[106/123]	Time 0.018 (0.126)	Data 0.000 (0.079)	
[107/123]	Time 0.018 (0.125)	Data 0.000 (0.078)	
[108/123]	Time 0.018 (0.124)	Data 0.000 (0.078)	
[109/123]	Time 0.018 (0.123)	Data 0.000 (0.077)	
[110/123]	Time 0.050 (0.122)	Data 0.032 (0.077)	
[111/123]	Time 0.018 (0.121)	Data 0.000 (0.076)	
[112/123]	Time 0.018 (0.120)	Data 0.000 (0.075)	
[113/123]	Time 0.017 (0.119)	Data 0.000 (0.075)	
[114/123]	Time 0.228 (0.120)	Data 0.212 (0.076)	
[115/123]	Time 0.016 (0.119)	Data 0.000 (0.075)	
[116/123]	Time 0.016 (0.118)	Data 0.000 (0.075)	
[117/123]	Time 0.016 (0.118)	Data 0.000 (0.074)	
[118/123]	Time 0.016 (0.117)	Data 0.000 (0.073)	
[119/123]	Time 0.016 (0.116)	Data 0.000 (0.073)	
[120/123]	Time 0.016 (0.115)	Data 0.000 (0.072)	
[121/123]	Time 0.016 (0.114)	Data 0.000 (0.071)	
[122/123]	Time 0.016 (0.113)	Data 0.000 (0.071)	
[123/123]	Time 0.016 (0.113)	Data 0.000 (0.070)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.01', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.01, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=32, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.01/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.01/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 5.006 (5.006)	Data 4.315 (4.315)	
[2/123]	Time 0.015 (2.511)	Data 0.000 (2.158)	
[3/123]	Time 0.014 (1.678)	Data 0.000 (1.438)	
[4/123]	Time 0.014 (1.262)	Data 0.000 (1.079)	
[5/123]	Time 0.015 (1.013)	Data 0.001 (0.863)	
[6/123]	Time 0.016 (0.847)	Data 0.002 (0.720)	
[7/123]	Time 0.015 (0.728)	Data 0.000 (0.617)	
[8/123]	Time 0.015 (0.639)	Data 0.001 (0.540)	
[9/123]	Time 0.015 (0.570)	Data 0.001 (0.480)	
[10/123]	Time 0.015 (0.514)	Data 0.000 (0.432)	
[11/123]	Time 0.016 (0.469)	Data 0.001 (0.393)	
[12/123]	Time 0.020 (0.431)	Data 0.004 (0.360)	
[13/123]	Time 0.018 (0.400)	Data 0.003 (0.333)	
[14/123]	Time 0.015 (0.372)	Data 0.001 (0.309)	
[15/123]	Time 0.015 (0.348)	Data 0.001 (0.289)	
[16/123]	Time 0.024 (0.328)	Data 0.010 (0.271)	
[17/123]	Time 0.034 (0.311)	Data 0.006 (0.256)	
[18/123]	Time 0.026 (0.295)	Data 0.012 (0.242)	
[19/123]	Time 0.026 (0.281)	Data 0.000 (0.229)	
[20/123]	Time 0.030 (0.268)	Data 0.016 (0.219)	
[21/123]	Time 0.028 (0.257)	Data 0.014 (0.209)	
[22/123]	Time 0.015 (0.246)	Data 0.001 (0.200)	
[23/123]	Time 0.015 (0.236)	Data 0.002 (0.191)	
[24/123]	Time 0.017 (0.227)	Data 0.001 (0.183)	
[25/123]	Time 0.014 (0.218)	Data 0.001 (0.176)	
[26/123]	Time 0.046 (0.212)	Data 0.009 (0.169)	
[27/123]	Time 0.028 (0.205)	Data 0.001 (0.163)	
[28/123]	Time 0.014 (0.198)	Data 0.001 (0.157)	
[29/123]	Time 0.020 (0.192)	Data 0.006 (0.152)	
[30/123]	Time 0.044 (0.187)	Data 0.017 (0.148)	
[31/123]	Time 0.015 (0.181)	Data 0.001 (0.143)	
[32/123]	Time 0.015 (0.176)	Data 0.001 (0.138)	
[33/123]	Time 0.014 (0.171)	Data 0.001 (0.134)	
[34/123]	Time 0.881 (0.192)	Data 0.868 (0.156)	
[35/123]	Time 0.029 (0.187)	Data 0.015 (0.152)	
[36/123]	Time 0.032 (0.183)	Data 0.006 (0.148)	
[37/123]	Time 0.185 (0.183)	Data 0.170 (0.148)	
[38/123]	Time 0.024 (0.179)	Data 0.009 (0.145)	
[39/123]	Time 0.206 (0.180)	Data 0.193 (0.146)	
[40/123]	Time 0.029 (0.176)	Data 0.003 (0.142)	
[41/123]	Time 0.026 (0.172)	Data 0.001 (0.139)	
[42/123]	Time 0.030 (0.169)	Data 0.001 (0.136)	
[43/123]	Time 0.020 (0.165)	Data 0.001 (0.132)	
[44/123]	Time 0.038 (0.163)	Data 0.017 (0.130)	
[45/123]	Time 0.031 (0.160)	Data 0.017 (0.127)	
[46/123]	Time 0.046 (0.157)	Data 0.018 (0.125)	
[47/123]	Time 0.014 (0.154)	Data 0.001 (0.122)	
[48/123]	Time 0.058 (0.152)	Data 0.006 (0.120)	
[49/123]	Time 0.053 (0.150)	Data 0.040 (0.118)	
[50/123]	Time 0.748 (0.162)	Data 0.734 (0.131)	
[51/123]	Time 0.056 (0.160)	Data 0.021 (0.128)	
[52/123]	Time 0.020 (0.157)	Data 0.004 (0.126)	
[53/123]	Time 0.162 (0.157)	Data 0.147 (0.126)	
[54/123]	Time 0.027 (0.155)	Data 0.012 (0.124)	
[55/123]	Time 0.109 (0.154)	Data 0.094 (0.124)	
[56/123]	Time 0.029 (0.152)	Data 0.013 (0.122)	
[57/123]	Time 0.037 (0.150)	Data 0.017 (0.120)	
[58/123]	Time 0.030 (0.148)	Data 0.016 (0.118)	
[59/123]	Time 0.042 (0.146)	Data 0.001 (0.116)	
[60/123]	Time 0.015 (0.144)	Data 0.001 (0.114)	
[61/123]	Time 0.016 (0.142)	Data 0.001 (0.112)	
[62/123]	Time 0.030 (0.140)	Data 0.007 (0.111)	
[63/123]	Time 0.040 (0.138)	Data 0.011 (0.109)	
[64/123]	Time 0.015 (0.136)	Data 0.001 (0.107)	
[65/123]	Time 0.512 (0.142)	Data 0.497 (0.113)	
[66/123]	Time 0.157 (0.142)	Data 0.143 (0.114)	
[67/123]	Time 0.165 (0.143)	Data 0.151 (0.114)	
[68/123]	Time 0.029 (0.141)	Data 0.013 (0.113)	
[69/123]	Time 0.254 (0.143)	Data 0.240 (0.115)	
[70/123]	Time 0.058 (0.141)	Data 0.043 (0.114)	
[71/123]	Time 0.101 (0.141)	Data 0.080 (0.113)	
[72/123]	Time 0.016 (0.139)	Data 0.000 (0.112)	
[73/123]	Time 0.036 (0.138)	Data 0.006 (0.110)	
[74/123]	Time 0.026 (0.136)	Data 0.001 (0.109)	
[75/123]	Time 0.029 (0.135)	Data 0.014 (0.107)	
[76/123]	Time 0.028 (0.133)	Data 0.014 (0.106)	
[77/123]	Time 0.416 (0.137)	Data 0.401 (0.110)	
[78/123]	Time 0.035 (0.136)	Data 0.012 (0.109)	
[79/123]	Time 0.023 (0.134)	Data 0.009 (0.108)	
[80/123]	Time 0.024 (0.133)	Data 0.008 (0.106)	
[81/123]	Time 0.037 (0.132)	Data 0.011 (0.105)	
[82/123]	Time 0.297 (0.134)	Data 0.283 (0.107)	
[83/123]	Time 0.044 (0.133)	Data 0.006 (0.106)	
[84/123]	Time 0.025 (0.131)	Data 0.010 (0.105)	
[85/123]	Time 0.462 (0.135)	Data 0.437 (0.109)	
[86/123]	Time 0.028 (0.134)	Data 0.001 (0.108)	
[87/123]	Time 0.038 (0.133)	Data 0.019 (0.107)	
[88/123]	Time 0.029 (0.132)	Data 0.005 (0.105)	
[89/123]	Time 0.026 (0.131)	Data 0.011 (0.104)	
[90/123]	Time 0.015 (0.129)	Data 0.001 (0.103)	
[91/123]	Time 0.017 (0.128)	Data 0.001 (0.102)	
[92/123]	Time 0.023 (0.127)	Data 0.001 (0.101)	
[93/123]	Time 0.149 (0.127)	Data 0.135 (0.101)	
[94/123]	Time 0.031 (0.126)	Data 0.000 (0.100)	
[95/123]	Time 0.032 (0.125)	Data 0.010 (0.099)	
[96/123]	Time 0.032 (0.124)	Data 0.001 (0.098)	
[97/123]	Time 0.045 (0.123)	Data 0.001 (0.097)	
[98/123]	Time 0.454 (0.127)	Data 0.440 (0.101)	
[99/123]	Time 0.123 (0.127)	Data 0.093 (0.101)	
[100/123]	Time 0.015 (0.126)	Data 0.000 (0.100)	
[101/123]	Time 0.432 (0.129)	Data 0.411 (0.103)	
[102/123]	Time 0.015 (0.128)	Data 0.000 (0.102)	
[103/123]	Time 0.015 (0.126)	Data 0.000 (0.101)	
[104/123]	Time 0.015 (0.125)	Data 0.000 (0.100)	
[105/123]	Time 0.015 (0.124)	Data 0.000 (0.099)	
[106/123]	Time 0.015 (0.123)	Data 0.000 (0.098)	
[107/123]	Time 0.015 (0.122)	Data 0.001 (0.097)	
[108/123]	Time 0.015 (0.121)	Data 0.000 (0.096)	
[109/123]	Time 0.014 (0.120)	Data 0.000 (0.095)	
[110/123]	Time 0.014 (0.119)	Data 0.000 (0.094)	
[111/123]	Time 0.014 (0.118)	Data 0.000 (0.094)	
[112/123]	Time 0.014 (0.117)	Data 0.000 (0.093)	
[113/123]	Time 0.014 (0.117)	Data 0.000 (0.092)	
[114/123]	Time 0.080 (0.116)	Data 0.068 (0.092)	
[115/123]	Time 0.012 (0.115)	Data 0.000 (0.091)	
[116/123]	Time 0.013 (0.114)	Data 0.000 (0.090)	
[117/123]	Time 0.223 (0.115)	Data 0.210 (0.091)	
[118/123]	Time 0.012 (0.114)	Data 0.000 (0.090)	
[119/123]	Time 0.013 (0.114)	Data 0.000 (0.090)	
[120/123]	Time 0.012 (0.113)	Data 0.000 (0.089)	
[121/123]	Time 0.012 (0.112)	Data 0.000 (0.088)	
[122/123]	Time 0.012 (0.111)	Data 0.000 (0.087)	
[123/123]	Time 0.012 (0.110)	Data 0.000 (0.087)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.01', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.01, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=32, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.01/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.01/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.454 (4.454)	Data 3.677 (3.677)	
[2/123]	Time 0.019 (2.237)	Data 0.001 (1.839)	
[3/123]	Time 0.018 (1.497)	Data 0.001 (1.226)	
[4/123]	Time 0.018 (1.127)	Data 0.001 (0.920)	
[5/123]	Time 0.018 (0.905)	Data 0.000 (0.736)	
[6/123]	Time 0.018 (0.757)	Data 0.000 (0.613)	
[7/123]	Time 0.019 (0.652)	Data 0.001 (0.526)	
[8/123]	Time 0.019 (0.573)	Data 0.001 (0.460)	
[9/123]	Time 0.076 (0.518)	Data 0.048 (0.414)	
[10/123]	Time 0.036 (0.469)	Data 0.001 (0.373)	
[11/123]	Time 0.034 (0.430)	Data 0.001 (0.339)	
[12/123]	Time 0.035 (0.397)	Data 0.002 (0.311)	
[13/123]	Time 0.043 (0.370)	Data 0.001 (0.287)	
[14/123]	Time 0.040 (0.346)	Data 0.005 (0.267)	
[15/123]	Time 0.045 (0.326)	Data 0.012 (0.250)	
[16/123]	Time 0.047 (0.309)	Data 0.015 (0.235)	
[17/123]	Time 0.051 (0.294)	Data 0.018 (0.223)	
[18/123]	Time 0.071 (0.281)	Data 0.009 (0.211)	
[19/123]	Time 0.029 (0.268)	Data 0.001 (0.200)	
[20/123]	Time 0.041 (0.257)	Data 0.001 (0.190)	
[21/123]	Time 0.050 (0.247)	Data 0.015 (0.181)	
[22/123]	Time 0.024 (0.237)	Data 0.001 (0.173)	
[23/123]	Time 0.025 (0.227)	Data 0.001 (0.166)	
[24/123]	Time 0.025 (0.219)	Data 0.001 (0.159)	
[25/123]	Time 0.058 (0.213)	Data 0.016 (0.153)	
[26/123]	Time 0.025 (0.205)	Data 0.001 (0.147)	
[27/123]	Time 0.031 (0.199)	Data 0.001 (0.142)	
[28/123]	Time 0.025 (0.193)	Data 0.001 (0.137)	
[29/123]	Time 0.029 (0.187)	Data 0.001 (0.132)	
[30/123]	Time 0.027 (0.182)	Data 0.001 (0.128)	
[31/123]	Time 0.057 (0.178)	Data 0.017 (0.124)	
[32/123]	Time 0.026 (0.173)	Data 0.001 (0.120)	
[33/123]	Time 0.047 (0.169)	Data 0.001 (0.117)	
[34/123]	Time 0.081 (0.166)	Data 0.016 (0.114)	
[35/123]	Time 0.801 (0.185)	Data 0.763 (0.132)	
[36/123]	Time 0.043 (0.181)	Data 0.001 (0.129)	
[37/123]	Time 0.134 (0.179)	Data 0.092 (0.128)	
[38/123]	Time 0.040 (0.176)	Data 0.017 (0.125)	
[39/123]	Time 0.029 (0.172)	Data 0.001 (0.122)	
[40/123]	Time 0.034 (0.169)	Data 0.001 (0.119)	
[41/123]	Time 0.060 (0.166)	Data 0.017 (0.116)	
[42/123]	Time 0.064 (0.163)	Data 0.009 (0.113)	
[43/123]	Time 0.053 (0.161)	Data 0.005 (0.111)	
[44/123]	Time 0.081 (0.159)	Data 0.024 (0.109)	
[45/123]	Time 0.039 (0.156)	Data 0.001 (0.107)	
[46/123]	Time 0.030 (0.154)	Data 0.001 (0.104)	
[47/123]	Time 0.055 (0.152)	Data 0.001 (0.102)	
[48/123]	Time 0.063 (0.150)	Data 0.015 (0.100)	
[49/123]	Time 0.062 (0.148)	Data 0.012 (0.098)	
[50/123]	Time 0.027 (0.146)	Data 0.000 (0.096)	
[51/123]	Time 1.067 (0.164)	Data 1.027 (0.115)	
[52/123]	Time 0.068 (0.162)	Data 0.001 (0.113)	
[53/123]	Time 0.081 (0.160)	Data 0.010 (0.111)	
[54/123]	Time 0.066 (0.158)	Data 0.001 (0.109)	
[55/123]	Time 0.067 (0.157)	Data 0.004 (0.107)	
[56/123]	Time 0.079 (0.155)	Data 0.001 (0.105)	
[57/123]	Time 0.031 (0.153)	Data 0.001 (0.103)	
[58/123]	Time 0.041 (0.151)	Data 0.001 (0.101)	
[59/123]	Time 0.031 (0.149)	Data 0.001 (0.100)	
[60/123]	Time 0.075 (0.148)	Data 0.015 (0.098)	
[61/123]	Time 0.055 (0.147)	Data 0.012 (0.097)	
[62/123]	Time 0.063 (0.145)	Data 0.012 (0.095)	
[63/123]	Time 0.051 (0.144)	Data 0.010 (0.094)	
[64/123]	Time 0.059 (0.142)	Data 0.015 (0.093)	
[65/123]	Time 0.061 (0.141)	Data 0.015 (0.092)	
[66/123]	Time 0.072 (0.140)	Data 0.027 (0.091)	
[67/123]	Time 0.724 (0.149)	Data 0.673 (0.099)	
[68/123]	Time 0.027 (0.147)	Data 0.001 (0.098)	
[69/123]	Time 0.151 (0.147)	Data 0.093 (0.098)	
[70/123]	Time 0.062 (0.146)	Data 0.001 (0.096)	
[71/123]	Time 0.028 (0.144)	Data 0.002 (0.095)	
[72/123]	Time 0.052 (0.143)	Data 0.001 (0.094)	
[73/123]	Time 0.036 (0.141)	Data 0.001 (0.092)	
[74/123]	Time 0.055 (0.140)	Data 0.001 (0.091)	
[75/123]	Time 0.038 (0.139)	Data 0.001 (0.090)	
[76/123]	Time 0.068 (0.138)	Data 0.006 (0.089)	
[77/123]	Time 0.045 (0.137)	Data 0.001 (0.088)	
[78/123]	Time 0.043 (0.136)	Data 0.001 (0.087)	
[79/123]	Time 0.118 (0.135)	Data 0.076 (0.086)	
[80/123]	Time 0.038 (0.134)	Data 0.010 (0.086)	
[81/123]	Time 0.058 (0.133)	Data 0.001 (0.084)	
[82/123]	Time 0.030 (0.132)	Data 0.001 (0.083)	
[83/123]	Time 0.658 (0.138)	Data 0.632 (0.090)	
[84/123]	Time 0.084 (0.138)	Data 0.030 (0.089)	
[85/123]	Time 0.044 (0.137)	Data 0.001 (0.088)	
[86/123]	Time 0.064 (0.136)	Data 0.016 (0.087)	
[87/123]	Time 0.044 (0.135)	Data 0.008 (0.087)	
[88/123]	Time 0.026 (0.133)	Data 0.001 (0.086)	
[89/123]	Time 0.077 (0.133)	Data 0.016 (0.085)	
[90/123]	Time 0.041 (0.132)	Data 0.001 (0.084)	
[91/123]	Time 0.046 (0.131)	Data 0.001 (0.083)	
[92/123]	Time 0.060 (0.130)	Data 0.001 (0.082)	
[93/123]	Time 0.026 (0.129)	Data 0.000 (0.081)	
[94/123]	Time 0.024 (0.128)	Data 0.000 (0.080)	
[95/123]	Time 0.092 (0.127)	Data 0.066 (0.080)	
[96/123]	Time 0.055 (0.127)	Data 0.000 (0.079)	
[97/123]	Time 0.027 (0.126)	Data 0.000 (0.079)	
[98/123]	Time 0.063 (0.125)	Data 0.001 (0.078)	
[99/123]	Time 0.319 (0.127)	Data 0.297 (0.080)	
[100/123]	Time 0.025 (0.126)	Data 0.001 (0.079)	
[101/123]	Time 0.030 (0.125)	Data 0.001 (0.078)	
[102/123]	Time 0.038 (0.124)	Data 0.000 (0.078)	
[103/123]	Time 0.028 (0.123)	Data 0.001 (0.077)	
[104/123]	Time 0.034 (0.122)	Data 0.000 (0.076)	
[105/123]	Time 0.019 (0.121)	Data 0.000 (0.075)	
[106/123]	Time 0.018 (0.120)	Data 0.000 (0.075)	
[107/123]	Time 0.018 (0.119)	Data 0.000 (0.074)	
[108/123]	Time 0.018 (0.118)	Data 0.000 (0.073)	
[109/123]	Time 0.018 (0.118)	Data 0.000 (0.073)	
[110/123]	Time 0.017 (0.117)	Data 0.000 (0.072)	
[111/123]	Time 0.017 (0.116)	Data 0.000 (0.071)	
[112/123]	Time 0.016 (0.115)	Data 0.000 (0.071)	
[113/123]	Time 0.016 (0.114)	Data 0.000 (0.070)	
[114/123]	Time 0.016 (0.113)	Data 0.000 (0.069)	
[115/123]	Time 0.250 (0.114)	Data 0.233 (0.071)	
[116/123]	Time 0.016 (0.113)	Data 0.000 (0.070)	
[117/123]	Time 0.016 (0.113)	Data 0.000 (0.070)	
[118/123]	Time 0.016 (0.112)	Data 0.000 (0.069)	
[119/123]	Time 0.016 (0.111)	Data 0.000 (0.069)	
[120/123]	Time 0.016 (0.110)	Data 0.000 (0.068)	
[121/123]	Time 0.016 (0.109)	Data 0.000 (0.067)	
[122/123]	Time 0.016 (0.109)	Data 0.000 (0.067)	
[123/123]	Time 0.016 (0.108)	Data 0.000 (0.066)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.001', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.001, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=32, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.001/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs32_lr0.001/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.872 (4.872)	Data 4.183 (4.183)	
[2/123]	Time 0.015 (2.444)	Data 0.001 (2.092)	
[3/123]	Time 0.014 (1.634)	Data 0.000 (1.395)	
[4/123]	Time 0.014 (1.229)	Data 0.000 (1.046)	
[5/123]	Time 0.014 (0.986)	Data 0.000 (0.837)	
[6/123]	Time 0.015 (0.824)	Data 0.000 (0.698)	
[7/123]	Time 0.015 (0.708)	Data 0.001 (0.598)	
[8/123]	Time 0.015 (0.622)	Data 0.001 (0.523)	
[9/123]	Time 0.021 (0.555)	Data 0.004 (0.466)	
[10/123]	Time 0.016 (0.501)	Data 0.001 (0.419)	
[11/123]	Time 0.015 (0.457)	Data 0.001 (0.381)	
[12/123]	Time 0.017 (0.420)	Data 0.001 (0.349)	
[13/123]	Time 0.015 (0.389)	Data 0.000 (0.323)	
[14/123]	Time 0.048 (0.365)	Data 0.017 (0.301)	
[15/123]	Time 0.019 (0.342)	Data 0.004 (0.281)	
[16/123]	Time 0.020 (0.322)	Data 0.006 (0.264)	
[17/123]	Time 0.021 (0.304)	Data 0.001 (0.248)	
[18/123]	Time 0.027 (0.288)	Data 0.013 (0.235)	
[19/123]	Time 0.028 (0.275)	Data 0.014 (0.224)	
[20/123]	Time 0.015 (0.262)	Data 0.001 (0.212)	
[21/123]	Time 0.015 (0.250)	Data 0.001 (0.202)	
[22/123]	Time 0.027 (0.240)	Data 0.013 (0.194)	
[23/123]	Time 0.039 (0.231)	Data 0.009 (0.186)	
[24/123]	Time 0.014 (0.222)	Data 0.001 (0.178)	
[25/123]	Time 0.014 (0.214)	Data 0.001 (0.171)	
[26/123]	Time 0.014 (0.206)	Data 0.001 (0.164)	
[27/123]	Time 0.014 (0.199)	Data 0.001 (0.158)	
[28/123]	Time 0.016 (0.192)	Data 0.001 (0.153)	
[29/123]	Time 0.014 (0.186)	Data 0.001 (0.147)	
[30/123]	Time 0.015 (0.181)	Data 0.001 (0.143)	
[31/123]	Time 0.028 (0.176)	Data 0.014 (0.138)	
[32/123]	Time 0.028 (0.171)	Data 0.014 (0.135)	
[33/123]	Time 0.025 (0.167)	Data 0.003 (0.131)	
[34/123]	Time 0.479 (0.176)	Data 0.465 (0.140)	
[35/123]	Time 0.316 (0.180)	Data 0.291 (0.145)	
[36/123]	Time 0.580 (0.191)	Data 0.550 (0.156)	
[37/123]	Time 0.014 (0.186)	Data 0.001 (0.152)	
[38/123]	Time 0.014 (0.182)	Data 0.001 (0.148)	
[39/123]	Time 0.021 (0.177)	Data 0.001 (0.144)	
[40/123]	Time 0.031 (0.174)	Data 0.001 (0.140)	
[41/123]	Time 0.027 (0.170)	Data 0.001 (0.137)	
[42/123]	Time 0.014 (0.166)	Data 0.000 (0.134)	
[43/123]	Time 0.015 (0.163)	Data 0.002 (0.131)	
[44/123]	Time 0.031 (0.160)	Data 0.001 (0.128)	
[45/123]	Time 0.014 (0.157)	Data 0.001 (0.125)	
[46/123]	Time 0.039 (0.154)	Data 0.026 (0.123)	
[47/123]	Time 0.023 (0.151)	Data 0.001 (0.120)	
[48/123]	Time 0.024 (0.149)	Data 0.001 (0.118)	
[49/123]	Time 0.031 (0.146)	Data 0.002 (0.115)	
[50/123]	Time 0.204 (0.147)	Data 0.184 (0.117)	
[51/123]	Time 0.388 (0.152)	Data 0.374 (0.122)	
[52/123]	Time 0.504 (0.159)	Data 0.490 (0.129)	
[53/123]	Time 0.129 (0.158)	Data 0.116 (0.129)	
[54/123]	Time 0.014 (0.156)	Data 0.001 (0.126)	
[55/123]	Time 0.034 (0.154)	Data 0.001 (0.124)	
[56/123]	Time 0.025 (0.151)	Data 0.012 (0.122)	
[57/123]	Time 0.032 (0.149)	Data 0.018 (0.120)	
[58/123]	Time 0.039 (0.147)	Data 0.001 (0.118)	
[59/123]	Time 0.020 (0.145)	Data 0.001 (0.116)	
[60/123]	Time 0.022 (0.143)	Data 0.001 (0.114)	
[61/123]	Time 0.036 (0.141)	Data 0.006 (0.112)	
[62/123]	Time 0.014 (0.139)	Data 0.001 (0.111)	
[63/123]	Time 0.041 (0.138)	Data 0.011 (0.109)	
[64/123]	Time 0.026 (0.136)	Data 0.012 (0.108)	
[65/123]	Time 0.035 (0.134)	Data 0.001 (0.106)	
[66/123]	Time 0.136 (0.134)	Data 0.112 (0.106)	
[67/123]	Time 0.349 (0.138)	Data 0.335 (0.109)	
[68/123]	Time 0.337 (0.141)	Data 0.324 (0.113)	
[69/123]	Time 0.347 (0.144)	Data 0.324 (0.116)	
[70/123]	Time 0.016 (0.142)	Data 0.002 (0.114)	
[71/123]	Time 0.040 (0.140)	Data 0.003 (0.112)	
[72/123]	Time 0.021 (0.139)	Data 0.001 (0.111)	
[73/123]	Time 0.037 (0.137)	Data 0.007 (0.109)	
[74/123]	Time 0.049 (0.136)	Data 0.003 (0.108)	
[75/123]	Time 0.027 (0.135)	Data 0.012 (0.107)	
[76/123]	Time 0.028 (0.133)	Data 0.010 (0.105)	
[77/123]	Time 0.015 (0.132)	Data 0.001 (0.104)	
[78/123]	Time 0.045 (0.131)	Data 0.017 (0.103)	
[79/123]	Time 0.042 (0.129)	Data 0.015 (0.102)	
[80/123]	Time 0.028 (0.128)	Data 0.001 (0.101)	
[81/123]	Time 0.024 (0.127)	Data 0.010 (0.099)	
[82/123]	Time 0.028 (0.126)	Data 0.014 (0.098)	
[83/123]	Time 0.491 (0.130)	Data 0.461 (0.103)	
[84/123]	Time 0.139 (0.130)	Data 0.125 (0.103)	
[85/123]	Time 0.220 (0.131)	Data 0.205 (0.104)	
[86/123]	Time 0.049 (0.130)	Data 0.012 (0.103)	
[87/123]	Time 0.357 (0.133)	Data 0.342 (0.106)	
[88/123]	Time 0.029 (0.132)	Data 0.001 (0.105)	
[89/123]	Time 0.016 (0.130)	Data 0.001 (0.104)	
[90/123]	Time 0.041 (0.129)	Data 0.015 (0.103)	
[91/123]	Time 0.019 (0.128)	Data 0.001 (0.101)	
[92/123]	Time 0.035 (0.127)	Data 0.001 (0.100)	
[93/123]	Time 0.015 (0.126)	Data 0.000 (0.099)	
[94/123]	Time 0.015 (0.125)	Data 0.001 (0.098)	
[95/123]	Time 0.018 (0.124)	Data 0.001 (0.097)	
[96/123]	Time 0.029 (0.123)	Data 0.001 (0.096)	
[97/123]	Time 0.032 (0.122)	Data 0.001 (0.095)	
[98/123]	Time 0.019 (0.121)	Data 0.006 (0.094)	
[99/123]	Time 0.533 (0.125)	Data 0.519 (0.099)	
[100/123]	Time 0.014 (0.124)	Data 0.000 (0.098)	
[101/123]	Time 0.200 (0.124)	Data 0.178 (0.098)	
[102/123]	Time 0.033 (0.124)	Data 0.000 (0.097)	
[103/123]	Time 0.236 (0.125)	Data 0.222 (0.099)	
[104/123]	Time 0.014 (0.124)	Data 0.000 (0.098)	
[105/123]	Time 0.014 (0.123)	Data 0.000 (0.097)	
[106/123]	Time 0.014 (0.122)	Data 0.000 (0.096)	
[107/123]	Time 0.013 (0.121)	Data 0.000 (0.095)	
[108/123]	Time 0.014 (0.120)	Data 0.000 (0.094)	
[109/123]	Time 0.013 (0.119)	Data 0.000 (0.093)	
[110/123]	Time 0.013 (0.118)	Data 0.000 (0.092)	
[111/123]	Time 0.013 (0.117)	Data 0.000 (0.092)	
[112/123]	Time 0.013 (0.116)	Data 0.000 (0.091)	
[113/123]	Time 0.013 (0.115)	Data 0.000 (0.090)	
[114/123]	Time 0.013 (0.114)	Data 0.000 (0.089)	
[115/123]	Time 0.123 (0.114)	Data 0.110 (0.089)	
[116/123]	Time 0.013 (0.113)	Data 0.000 (0.089)	
[117/123]	Time 0.082 (0.113)	Data 0.069 (0.088)	
[118/123]	Time 0.012 (0.112)	Data 0.000 (0.088)	
[119/123]	Time 0.149 (0.112)	Data 0.136 (0.088)	
[120/123]	Time 0.012 (0.111)	Data 0.000 (0.087)	
[121/123]	Time 0.012 (0.111)	Data 0.000 (0.087)	
[122/123]	Time 0.012 (0.110)	Data 0.000 (0.086)	
[123/123]	Time 0.012 (0.109)	Data 0.000 (0.085)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.001', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.001, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=32, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.001/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs32_lr0.001/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.495 (4.495)	Data 3.816 (3.816)	
[2/123]	Time 0.017 (2.256)	Data 0.000 (1.908)	
[3/123]	Time 0.250 (1.587)	Data 0.232 (1.350)	
[4/123]	Time 0.017 (1.195)	Data 0.000 (1.012)	
[5/123]	Time 0.018 (0.959)	Data 0.000 (0.810)	
[6/123]	Time 0.019 (0.803)	Data 0.001 (0.675)	
[7/123]	Time 0.018 (0.691)	Data 0.001 (0.579)	
[8/123]	Time 0.027 (0.608)	Data 0.001 (0.506)	
[9/123]	Time 0.029 (0.543)	Data 0.000 (0.450)	
[10/123]	Time 0.020 (0.491)	Data 0.001 (0.405)	
[11/123]	Time 0.042 (0.450)	Data 0.001 (0.369)	
[12/123]	Time 0.037 (0.416)	Data 0.001 (0.338)	
[13/123]	Time 0.058 (0.388)	Data 0.015 (0.313)	
[14/123]	Time 0.054 (0.364)	Data 0.009 (0.291)	
[15/123]	Time 0.071 (0.345)	Data 0.010 (0.273)	
[16/123]	Time 0.038 (0.326)	Data 0.000 (0.256)	
[17/123]	Time 0.035 (0.308)	Data 0.000 (0.241)	
[18/123]	Time 0.053 (0.294)	Data 0.014 (0.228)	
[19/123]	Time 0.038 (0.281)	Data 0.000 (0.216)	
[20/123]	Time 0.029 (0.268)	Data 0.001 (0.205)	
[21/123]	Time 0.050 (0.258)	Data 0.001 (0.196)	
[22/123]	Time 0.029 (0.247)	Data 0.001 (0.187)	
[23/123]	Time 0.028 (0.238)	Data 0.001 (0.179)	
[24/123]	Time 0.031 (0.229)	Data 0.001 (0.171)	
[25/123]	Time 0.028 (0.221)	Data 0.001 (0.164)	
[26/123]	Time 0.031 (0.214)	Data 0.001 (0.158)	
[27/123]	Time 0.027 (0.207)	Data 0.001 (0.152)	
[28/123]	Time 0.030 (0.201)	Data 0.001 (0.147)	
[29/123]	Time 0.057 (0.196)	Data 0.016 (0.142)	
[30/123]	Time 0.066 (0.191)	Data 0.001 (0.138)	
[31/123]	Time 0.086 (0.188)	Data 0.027 (0.134)	
[32/123]	Time 0.060 (0.184)	Data 0.022 (0.131)	
[33/123]	Time 0.057 (0.180)	Data 0.015 (0.127)	
[34/123]	Time 0.058 (0.177)	Data 0.001 (0.123)	
[35/123]	Time 0.052 (0.173)	Data 0.012 (0.120)	
[36/123]	Time 0.043 (0.169)	Data 0.001 (0.117)	
[37/123]	Time 0.054 (0.166)	Data 0.013 (0.114)	
[38/123]	Time 0.214 (0.167)	Data 0.189 (0.116)	
[39/123]	Time 0.072 (0.165)	Data 0.017 (0.114)	
[40/123]	Time 0.049 (0.162)	Data 0.012 (0.111)	
[41/123]	Time 0.079 (0.160)	Data 0.038 (0.109)	
[42/123]	Time 0.058 (0.158)	Data 0.006 (0.107)	
[43/123]	Time 0.061 (0.155)	Data 0.014 (0.105)	
[44/123]	Time 0.121 (0.155)	Data 0.096 (0.104)	
[45/123]	Time 0.053 (0.152)	Data 0.018 (0.102)	
[46/123]	Time 0.072 (0.151)	Data 0.032 (0.101)	
[47/123]	Time 0.238 (0.153)	Data 0.214 (0.103)	
[48/123]	Time 0.050 (0.150)	Data 0.016 (0.102)	
[49/123]	Time 0.078 (0.149)	Data 0.004 (0.100)	
[50/123]	Time 0.045 (0.147)	Data 0.001 (0.098)	
[51/123]	Time 0.151 (0.147)	Data 0.107 (0.098)	
[52/123]	Time 0.052 (0.145)	Data 0.006 (0.096)	
[53/123]	Time 0.064 (0.144)	Data 0.002 (0.094)	
[54/123]	Time 0.368 (0.148)	Data 0.309 (0.098)	
[55/123]	Time 0.056 (0.146)	Data 0.001 (0.096)	
[56/123]	Time 0.056 (0.144)	Data 0.001 (0.095)	
[57/123]	Time 0.043 (0.143)	Data 0.001 (0.093)	
[58/123]	Time 0.079 (0.142)	Data 0.001 (0.091)	
[59/123]	Time 0.111 (0.141)	Data 0.071 (0.091)	
[60/123]	Time 0.059 (0.140)	Data 0.032 (0.090)	
[61/123]	Time 0.059 (0.138)	Data 0.001 (0.089)	
[62/123]	Time 0.044 (0.137)	Data 0.001 (0.087)	
[63/123]	Time 0.342 (0.140)	Data 0.304 (0.091)	
[64/123]	Time 0.058 (0.139)	Data 0.010 (0.089)	
[65/123]	Time 0.062 (0.138)	Data 0.011 (0.088)	
[66/123]	Time 0.059 (0.136)	Data 0.006 (0.087)	
[67/123]	Time 0.046 (0.135)	Data 0.012 (0.086)	
[68/123]	Time 0.058 (0.134)	Data 0.016 (0.085)	
[69/123]	Time 0.062 (0.133)	Data 0.001 (0.084)	
[70/123]	Time 0.472 (0.138)	Data 0.435 (0.089)	
[71/123]	Time 0.054 (0.137)	Data 0.016 (0.088)	
[72/123]	Time 0.062 (0.136)	Data 0.001 (0.086)	
[73/123]	Time 0.051 (0.134)	Data 0.001 (0.085)	
[74/123]	Time 0.047 (0.133)	Data 0.001 (0.084)	
[75/123]	Time 0.070 (0.132)	Data 0.001 (0.083)	
[76/123]	Time 0.051 (0.131)	Data 0.011 (0.082)	
[77/123]	Time 0.060 (0.130)	Data 0.001 (0.081)	
[78/123]	Time 0.061 (0.129)	Data 0.013 (0.080)	
[79/123]	Time 0.397 (0.133)	Data 0.372 (0.084)	
[80/123]	Time 0.059 (0.132)	Data 0.017 (0.083)	
[81/123]	Time 0.066 (0.131)	Data 0.015 (0.082)	
[82/123]	Time 0.055 (0.130)	Data 0.021 (0.081)	
[83/123]	Time 0.070 (0.129)	Data 0.001 (0.080)	
[84/123]	Time 0.083 (0.129)	Data 0.016 (0.080)	
[85/123]	Time 0.060 (0.128)	Data 0.001 (0.079)	
[86/123]	Time 0.112 (0.128)	Data 0.040 (0.078)	
[87/123]	Time 0.071 (0.127)	Data 0.012 (0.078)	
[88/123]	Time 0.054 (0.126)	Data 0.012 (0.077)	
[89/123]	Time 0.058 (0.126)	Data 0.017 (0.076)	
[90/123]	Time 0.065 (0.125)	Data 0.016 (0.075)	
[91/123]	Time 0.365 (0.128)	Data 0.334 (0.078)	
[92/123]	Time 0.046 (0.127)	Data 0.001 (0.077)	
[93/123]	Time 0.058 (0.126)	Data 0.000 (0.077)	
[94/123]	Time 0.056 (0.125)	Data 0.000 (0.076)	
[95/123]	Time 0.338 (0.127)	Data 0.294 (0.078)	
[96/123]	Time 0.052 (0.127)	Data 0.000 (0.077)	
[97/123]	Time 0.060 (0.126)	Data 0.009 (0.077)	
[98/123]	Time 0.059 (0.125)	Data 0.011 (0.076)	
[99/123]	Time 0.066 (0.125)	Data 0.015 (0.075)	
[100/123]	Time 0.062 (0.124)	Data 0.010 (0.075)	
[101/123]	Time 0.066 (0.124)	Data 0.001 (0.074)	
[102/123]	Time 0.030 (0.123)	Data 0.001 (0.073)	
[103/123]	Time 0.023 (0.122)	Data 0.000 (0.073)	
[104/123]	Time 0.025 (0.121)	Data 0.000 (0.072)	
[105/123]	Time 0.027 (0.120)	Data 0.000 (0.071)	
[106/123]	Time 0.032 (0.119)	Data 0.001 (0.070)	
[107/123]	Time 0.300 (0.121)	Data 0.282 (0.072)	
[108/123]	Time 0.017 (0.120)	Data 0.000 (0.072)	
[109/123]	Time 0.017 (0.119)	Data 0.000 (0.071)	
[110/123]	Time 0.018 (0.118)	Data 0.000 (0.070)	
[111/123]	Time 0.133 (0.118)	Data 0.115 (0.071)	
[112/123]	Time 0.018 (0.117)	Data 0.000 (0.070)	
[113/123]	Time 0.017 (0.116)	Data 0.000 (0.070)	
[114/123]	Time 0.017 (0.115)	Data 0.000 (0.069)	
[115/123]	Time 0.017 (0.115)	Data 0.000 (0.068)	
[116/123]	Time 0.017 (0.114)	Data 0.000 (0.068)	
[117/123]	Time 0.016 (0.113)	Data 0.000 (0.067)	
[118/123]	Time 0.017 (0.112)	Data 0.000 (0.067)	
[119/123]	Time 0.016 (0.111)	Data 0.000 (0.066)	
[120/123]	Time 0.016 (0.110)	Data 0.000 (0.066)	
[121/123]	Time 0.016 (0.110)	Data 0.000 (0.065)	
[122/123]	Time 0.016 (0.109)	Data 0.000 (0.065)	
[123/123]	Time 0.124 (0.109)	Data 0.108 (0.065)	
end bs32
start bs64
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.1', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.1, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=64, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.1/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.1/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.651 (4.651)	Data 3.947 (3.947)	
[2/123]	Time 0.014 (2.333)	Data 0.000 (1.974)	
[3/123]	Time 0.014 (1.560)	Data 0.001 (1.316)	
[4/123]	Time 0.014 (1.173)	Data 0.000 (0.987)	
[5/123]	Time 0.015 (0.942)	Data 0.001 (0.790)	
[6/123]	Time 0.015 (0.787)	Data 0.001 (0.658)	
[7/123]	Time 0.014 (0.677)	Data 0.000 (0.564)	
[8/123]	Time 0.015 (0.594)	Data 0.001 (0.494)	
[9/123]	Time 0.019 (0.530)	Data 0.005 (0.439)	
[10/123]	Time 0.014 (0.479)	Data 0.000 (0.396)	
[11/123]	Time 0.014 (0.436)	Data 0.001 (0.360)	
[12/123]	Time 0.014 (0.401)	Data 0.001 (0.330)	
[13/123]	Time 0.043 (0.374)	Data 0.013 (0.305)	
[14/123]	Time 0.028 (0.349)	Data 0.013 (0.285)	
[15/123]	Time 0.017 (0.327)	Data 0.001 (0.266)	
[16/123]	Time 0.024 (0.308)	Data 0.010 (0.250)	
[17/123]	Time 0.035 (0.292)	Data 0.006 (0.235)	
[18/123]	Time 0.015 (0.276)	Data 0.001 (0.222)	
[19/123]	Time 0.084 (0.266)	Data 0.068 (0.214)	
[20/123]	Time 0.030 (0.255)	Data 0.001 (0.204)	
[21/123]	Time 0.014 (0.243)	Data 0.001 (0.194)	
[22/123]	Time 0.041 (0.234)	Data 0.013 (0.186)	
[23/123]	Time 0.023 (0.225)	Data 0.001 (0.178)	
[24/123]	Time 0.038 (0.217)	Data 0.013 (0.171)	
[25/123]	Time 0.018 (0.209)	Data 0.001 (0.164)	
[26/123]	Time 0.041 (0.203)	Data 0.005 (0.158)	
[27/123]	Time 0.077 (0.198)	Data 0.063 (0.154)	
[28/123]	Time 0.020 (0.192)	Data 0.006 (0.149)	
[29/123]	Time 0.050 (0.187)	Data 0.037 (0.145)	
[30/123]	Time 0.043 (0.182)	Data 0.016 (0.141)	
[31/123]	Time 0.027 (0.177)	Data 0.001 (0.136)	
[32/123]	Time 0.015 (0.172)	Data 0.001 (0.132)	
[33/123]	Time 0.022 (0.167)	Data 0.008 (0.128)	
[34/123]	Time 0.239 (0.169)	Data 0.225 (0.131)	
[35/123]	Time 0.477 (0.178)	Data 0.449 (0.140)	
[36/123]	Time 0.250 (0.180)	Data 0.236 (0.143)	
[37/123]	Time 0.028 (0.176)	Data 0.015 (0.140)	
[38/123]	Time 0.035 (0.172)	Data 0.006 (0.136)	
[39/123]	Time 0.021 (0.168)	Data 0.007 (0.133)	
[40/123]	Time 0.039 (0.165)	Data 0.012 (0.130)	
[41/123]	Time 0.254 (0.167)	Data 0.224 (0.132)	
[42/123]	Time 0.042 (0.164)	Data 0.006 (0.129)	
[43/123]	Time 0.103 (0.163)	Data 0.088 (0.128)	
[44/123]	Time 0.027 (0.160)	Data 0.009 (0.125)	
[45/123]	Time 0.020 (0.157)	Data 0.001 (0.123)	
[46/123]	Time 0.025 (0.154)	Data 0.010 (0.120)	
[47/123]	Time 0.036 (0.151)	Data 0.021 (0.118)	
[48/123]	Time 0.062 (0.150)	Data 0.047 (0.117)	
[49/123]	Time 0.037 (0.147)	Data 0.016 (0.114)	
[50/123]	Time 0.772 (0.160)	Data 0.758 (0.127)	
[51/123]	Time 0.016 (0.157)	Data 0.001 (0.125)	
[52/123]	Time 0.048 (0.155)	Data 0.026 (0.123)	
[53/123]	Time 0.028 (0.152)	Data 0.011 (0.121)	
[54/123]	Time 0.027 (0.150)	Data 0.013 (0.119)	
[55/123]	Time 0.121 (0.150)	Data 0.107 (0.119)	
[56/123]	Time 0.047 (0.148)	Data 0.014 (0.117)	
[57/123]	Time 0.054 (0.146)	Data 0.032 (0.115)	
[58/123]	Time 0.021 (0.144)	Data 0.001 (0.113)	
[59/123]	Time 0.029 (0.142)	Data 0.001 (0.111)	
[60/123]	Time 0.015 (0.140)	Data 0.001 (0.110)	
[61/123]	Time 0.029 (0.138)	Data 0.014 (0.108)	
[62/123]	Time 0.154 (0.138)	Data 0.140 (0.109)	
[63/123]	Time 0.072 (0.137)	Data 0.035 (0.107)	
[64/123]	Time 0.036 (0.136)	Data 0.013 (0.106)	
[65/123]	Time 0.018 (0.134)	Data 0.001 (0.104)	
[66/123]	Time 0.524 (0.140)	Data 0.510 (0.110)	
[67/123]	Time 0.110 (0.139)	Data 0.091 (0.110)	
[68/123]	Time 0.030 (0.138)	Data 0.015 (0.109)	
[69/123]	Time 0.048 (0.136)	Data 0.015 (0.107)	
[70/123]	Time 0.015 (0.135)	Data 0.001 (0.106)	
[71/123]	Time 0.213 (0.136)	Data 0.199 (0.107)	
[72/123]	Time 0.031 (0.134)	Data 0.016 (0.106)	
[73/123]	Time 0.050 (0.133)	Data 0.013 (0.105)	
[74/123]	Time 0.015 (0.132)	Data 0.000 (0.103)	
[75/123]	Time 0.030 (0.130)	Data 0.008 (0.102)	
[76/123]	Time 0.044 (0.129)	Data 0.022 (0.101)	
[77/123]	Time 0.031 (0.128)	Data 0.001 (0.100)	
[78/123]	Time 0.030 (0.127)	Data 0.001 (0.098)	
[79/123]	Time 0.027 (0.125)	Data 0.001 (0.097)	
[80/123]	Time 0.036 (0.124)	Data 0.021 (0.096)	
[81/123]	Time 0.034 (0.123)	Data 0.019 (0.095)	
[82/123]	Time 0.539 (0.128)	Data 0.524 (0.100)	
[83/123]	Time 0.187 (0.129)	Data 0.173 (0.101)	
[84/123]	Time 0.034 (0.128)	Data 0.001 (0.100)	
[85/123]	Time 0.030 (0.127)	Data 0.001 (0.099)	
[86/123]	Time 0.020 (0.125)	Data 0.001 (0.098)	
[87/123]	Time 0.167 (0.126)	Data 0.152 (0.098)	
[88/123]	Time 0.052 (0.125)	Data 0.016 (0.097)	
[89/123]	Time 0.058 (0.124)	Data 0.036 (0.097)	
[90/123]	Time 0.080 (0.124)	Data 0.065 (0.096)	
[91/123]	Time 0.032 (0.123)	Data 0.013 (0.096)	
[92/123]	Time 0.030 (0.122)	Data 0.001 (0.094)	
[93/123]	Time 0.018 (0.121)	Data 0.001 (0.093)	
[94/123]	Time 0.015 (0.119)	Data 0.001 (0.092)	
[95/123]	Time 0.016 (0.118)	Data 0.001 (0.092)	
[96/123]	Time 0.101 (0.118)	Data 0.067 (0.091)	
[97/123]	Time 0.028 (0.117)	Data 0.000 (0.090)	
[98/123]	Time 0.428 (0.120)	Data 0.413 (0.094)	
[99/123]	Time 0.167 (0.121)	Data 0.152 (0.094)	
[100/123]	Time 0.030 (0.120)	Data 0.016 (0.093)	
[101/123]	Time 0.050 (0.119)	Data 0.004 (0.093)	
[102/123]	Time 0.025 (0.118)	Data 0.001 (0.092)	
[103/123]	Time 0.301 (0.120)	Data 0.287 (0.094)	
[104/123]	Time 0.016 (0.119)	Data 0.001 (0.093)	
[105/123]	Time 0.097 (0.119)	Data 0.082 (0.093)	
[106/123]	Time 0.015 (0.118)	Data 0.000 (0.092)	
[107/123]	Time 0.016 (0.117)	Data 0.001 (0.091)	
[108/123]	Time 0.015 (0.116)	Data 0.000 (0.090)	
[109/123]	Time 0.015 (0.115)	Data 0.001 (0.089)	
[110/123]	Time 0.014 (0.114)	Data 0.000 (0.088)	
[111/123]	Time 0.014 (0.113)	Data 0.000 (0.088)	
[112/123]	Time 0.014 (0.112)	Data 0.001 (0.087)	
[113/123]	Time 0.014 (0.112)	Data 0.000 (0.086)	
[114/123]	Time 0.237 (0.113)	Data 0.223 (0.087)	
[115/123]	Time 0.082 (0.112)	Data 0.069 (0.087)	
[116/123]	Time 0.013 (0.112)	Data 0.000 (0.086)	
[117/123]	Time 0.013 (0.111)	Data 0.000 (0.086)	
[118/123]	Time 0.013 (0.110)	Data 0.000 (0.085)	
[119/123]	Time 0.079 (0.110)	Data 0.066 (0.085)	
[120/123]	Time 0.013 (0.109)	Data 0.000 (0.084)	
[121/123]	Time 0.045 (0.108)	Data 0.032 (0.084)	
[122/123]	Time 0.012 (0.108)	Data 0.000 (0.083)	
[123/123]	Time 0.012 (0.107)	Data 0.000 (0.082)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.1', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.1, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=64, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.1/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.1/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 5.215 (5.215)	Data 4.585 (4.585)	
[2/123]	Time 0.019 (2.617)	Data 0.000 (2.293)	
[3/123]	Time 0.017 (1.750)	Data 0.000 (1.529)	
[4/123]	Time 0.018 (1.317)	Data 0.000 (1.146)	
[5/123]	Time 0.018 (1.057)	Data 0.000 (0.917)	
[6/123]	Time 0.018 (0.884)	Data 0.000 (0.764)	
[7/123]	Time 0.018 (0.760)	Data 0.000 (0.655)	
[8/123]	Time 0.018 (0.667)	Data 0.000 (0.573)	
[9/123]	Time 0.019 (0.595)	Data 0.000 (0.510)	
[10/123]	Time 0.019 (0.538)	Data 0.000 (0.459)	
[11/123]	Time 0.032 (0.492)	Data 0.014 (0.418)	
[12/123]	Time 0.026 (0.453)	Data 0.001 (0.384)	
[13/123]	Time 0.024 (0.420)	Data 0.001 (0.354)	
[14/123]	Time 0.047 (0.393)	Data 0.008 (0.329)	
[15/123]	Time 0.077 (0.372)	Data 0.013 (0.308)	
[16/123]	Time 0.047 (0.352)	Data 0.001 (0.289)	
[17/123]	Time 0.075 (0.336)	Data 0.022 (0.273)	
[18/123]	Time 0.043 (0.319)	Data 0.001 (0.258)	
[19/123]	Time 0.054 (0.305)	Data 0.014 (0.245)	
[20/123]	Time 0.048 (0.293)	Data 0.001 (0.233)	
[21/123]	Time 0.049 (0.281)	Data 0.024 (0.223)	
[22/123]	Time 0.027 (0.269)	Data 0.001 (0.213)	
[23/123]	Time 0.055 (0.260)	Data 0.001 (0.204)	
[24/123]	Time 0.045 (0.251)	Data 0.001 (0.195)	
[25/123]	Time 0.057 (0.243)	Data 0.006 (0.188)	
[26/123]	Time 0.072 (0.237)	Data 0.001 (0.181)	
[27/123]	Time 0.101 (0.232)	Data 0.015 (0.174)	
[28/123]	Time 0.095 (0.227)	Data 0.000 (0.168)	
[29/123]	Time 0.079 (0.222)	Data 0.001 (0.162)	
[30/123]	Time 0.075 (0.217)	Data 0.029 (0.158)	
[31/123]	Time 0.076 (0.212)	Data 0.007 (0.153)	
[32/123]	Time 0.055 (0.207)	Data 0.001 (0.148)	
[33/123]	Time 0.036 (0.202)	Data 0.013 (0.144)	
[34/123]	Time 0.031 (0.197)	Data 0.001 (0.140)	
[35/123]	Time 0.051 (0.193)	Data 0.006 (0.136)	
[36/123]	Time 0.045 (0.189)	Data 0.020 (0.133)	
[37/123]	Time 0.025 (0.184)	Data 0.001 (0.129)	
[38/123]	Time 0.189 (0.185)	Data 0.120 (0.129)	
[39/123]	Time 0.055 (0.181)	Data 0.001 (0.126)	
[40/123]	Time 0.307 (0.184)	Data 0.266 (0.129)	
[41/123]	Time 0.038 (0.181)	Data 0.001 (0.126)	
[42/123]	Time 0.043 (0.178)	Data 0.014 (0.124)	
[43/123]	Time 0.052 (0.175)	Data 0.024 (0.121)	
[44/123]	Time 0.051 (0.172)	Data 0.016 (0.119)	
[45/123]	Time 0.205 (0.173)	Data 0.166 (0.120)	
[46/123]	Time 0.038 (0.170)	Data 0.001 (0.117)	
[47/123]	Time 0.034 (0.167)	Data 0.001 (0.115)	
[48/123]	Time 0.039 (0.164)	Data 0.001 (0.112)	
[49/123]	Time 0.040 (0.162)	Data 0.002 (0.110)	
[50/123]	Time 0.609 (0.171)	Data 0.545 (0.119)	
[51/123]	Time 0.066 (0.168)	Data 0.001 (0.117)	
[52/123]	Time 0.065 (0.166)	Data 0.001 (0.114)	
[53/123]	Time 0.042 (0.164)	Data 0.001 (0.112)	
[54/123]	Time 0.130 (0.163)	Data 0.089 (0.112)	
[55/123]	Time 0.052 (0.161)	Data 0.016 (0.110)	
[56/123]	Time 0.099 (0.160)	Data 0.028 (0.109)	
[57/123]	Time 0.046 (0.158)	Data 0.006 (0.107)	
[58/123]	Time 0.057 (0.157)	Data 0.002 (0.105)	
[59/123]	Time 0.040 (0.155)	Data 0.001 (0.103)	
[60/123]	Time 0.031 (0.153)	Data 0.001 (0.102)	
[61/123]	Time 0.159 (0.153)	Data 0.095 (0.101)	
[62/123]	Time 0.038 (0.151)	Data 0.001 (0.100)	
[63/123]	Time 0.047 (0.149)	Data 0.001 (0.098)	
[64/123]	Time 0.033 (0.147)	Data 0.007 (0.097)	
[65/123]	Time 0.053 (0.146)	Data 0.001 (0.095)	
[66/123]	Time 0.760 (0.155)	Data 0.696 (0.104)	
[67/123]	Time 0.037 (0.153)	Data 0.001 (0.103)	
[68/123]	Time 0.046 (0.152)	Data 0.001 (0.101)	
[69/123]	Time 0.058 (0.150)	Data 0.012 (0.100)	
[70/123]	Time 0.048 (0.149)	Data 0.012 (0.099)	
[71/123]	Time 0.079 (0.148)	Data 0.024 (0.098)	
[72/123]	Time 0.044 (0.147)	Data 0.001 (0.096)	
[73/123]	Time 0.085 (0.146)	Data 0.025 (0.095)	
[74/123]	Time 0.078 (0.145)	Data 0.023 (0.094)	
[75/123]	Time 0.051 (0.144)	Data 0.013 (0.093)	
[76/123]	Time 0.040 (0.142)	Data 0.014 (0.092)	
[77/123]	Time 0.035 (0.141)	Data 0.001 (0.091)	
[78/123]	Time 0.054 (0.140)	Data 0.015 (0.090)	
[79/123]	Time 0.050 (0.139)	Data 0.000 (0.089)	
[80/123]	Time 0.054 (0.138)	Data 0.011 (0.088)	
[81/123]	Time 0.029 (0.136)	Data 0.001 (0.087)	
[82/123]	Time 0.875 (0.145)	Data 0.810 (0.096)	
[83/123]	Time 0.052 (0.144)	Data 0.001 (0.095)	
[84/123]	Time 0.054 (0.143)	Data 0.001 (0.094)	
[85/123]	Time 0.087 (0.142)	Data 0.001 (0.092)	
[86/123]	Time 0.024 (0.141)	Data 0.001 (0.091)	
[87/123]	Time 0.071 (0.140)	Data 0.001 (0.090)	
[88/123]	Time 0.058 (0.139)	Data 0.011 (0.089)	
[89/123]	Time 0.043 (0.138)	Data 0.012 (0.089)	
[90/123]	Time 0.048 (0.137)	Data 0.002 (0.088)	
[91/123]	Time 0.052 (0.136)	Data 0.009 (0.087)	
[92/123]	Time 0.056 (0.135)	Data 0.000 (0.086)	
[93/123]	Time 0.050 (0.134)	Data 0.000 (0.085)	
[94/123]	Time 0.031 (0.133)	Data 0.001 (0.084)	
[95/123]	Time 0.026 (0.132)	Data 0.001 (0.083)	
[96/123]	Time 0.030 (0.131)	Data 0.001 (0.082)	
[97/123]	Time 0.030 (0.130)	Data 0.001 (0.081)	
[98/123]	Time 0.559 (0.134)	Data 0.533 (0.086)	
[99/123]	Time 0.031 (0.133)	Data 0.001 (0.085)	
[100/123]	Time 0.021 (0.132)	Data 0.001 (0.084)	
[101/123]	Time 0.025 (0.131)	Data 0.000 (0.084)	
[102/123]	Time 0.019 (0.130)	Data 0.000 (0.083)	
[103/123]	Time 0.019 (0.129)	Data 0.000 (0.082)	
[104/123]	Time 0.023 (0.128)	Data 0.000 (0.081)	
[105/123]	Time 0.018 (0.127)	Data 0.000 (0.080)	
[106/123]	Time 0.018 (0.126)	Data 0.000 (0.080)	
[107/123]	Time 0.018 (0.125)	Data 0.000 (0.079)	
[108/123]	Time 0.018 (0.124)	Data 0.000 (0.078)	
[109/123]	Time 0.017 (0.123)	Data 0.000 (0.077)	
[110/123]	Time 0.016 (0.122)	Data 0.000 (0.077)	
[111/123]	Time 0.017 (0.121)	Data 0.000 (0.076)	
[112/123]	Time 0.016 (0.120)	Data 0.000 (0.075)	
[113/123]	Time 0.016 (0.119)	Data 0.000 (0.075)	
[114/123]	Time 0.322 (0.121)	Data 0.306 (0.077)	
[115/123]	Time 0.016 (0.120)	Data 0.000 (0.076)	
[116/123]	Time 0.016 (0.119)	Data 0.000 (0.075)	
[117/123]	Time 0.016 (0.118)	Data 0.000 (0.075)	
[118/123]	Time 0.016 (0.117)	Data 0.000 (0.074)	
[119/123]	Time 0.016 (0.117)	Data 0.000 (0.074)	
[120/123]	Time 0.016 (0.116)	Data 0.000 (0.073)	
[121/123]	Time 0.015 (0.115)	Data 0.000 (0.072)	
[122/123]	Time 0.016 (0.114)	Data 0.000 (0.072)	
[123/123]	Time 0.016 (0.113)	Data 0.000 (0.071)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.01', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.01, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=64, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.01/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.01/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.355 (4.355)	Data 3.377 (3.377)	
[2/123]	Time 0.014 (2.185)	Data 0.000 (1.689)	
[3/123]	Time 0.014 (1.461)	Data 0.000 (1.126)	
[4/123]	Time 0.028 (1.103)	Data 0.014 (0.848)	
[5/123]	Time 0.319 (0.946)	Data 0.305 (0.739)	
[6/123]	Time 0.014 (0.791)	Data 0.000 (0.616)	
[7/123]	Time 0.015 (0.680)	Data 0.001 (0.528)	
[8/123]	Time 0.016 (0.597)	Data 0.002 (0.462)	
[9/123]	Time 0.015 (0.532)	Data 0.001 (0.411)	
[10/123]	Time 0.016 (0.481)	Data 0.001 (0.370)	
[11/123]	Time 0.015 (0.438)	Data 0.001 (0.337)	
[12/123]	Time 0.015 (0.403)	Data 0.001 (0.309)	
[13/123]	Time 0.037 (0.375)	Data 0.015 (0.286)	
[14/123]	Time 0.024 (0.350)	Data 0.008 (0.266)	
[15/123]	Time 0.029 (0.328)	Data 0.014 (0.249)	
[16/123]	Time 0.026 (0.310)	Data 0.013 (0.235)	
[17/123]	Time 0.024 (0.293)	Data 0.011 (0.221)	
[18/123]	Time 0.014 (0.277)	Data 0.001 (0.209)	
[19/123]	Time 0.014 (0.263)	Data 0.001 (0.198)	
[20/123]	Time 0.284 (0.264)	Data 0.269 (0.202)	
[21/123]	Time 0.126 (0.258)	Data 0.078 (0.196)	
[22/123]	Time 0.028 (0.247)	Data 0.012 (0.188)	
[23/123]	Time 0.019 (0.238)	Data 0.003 (0.179)	
[24/123]	Time 0.027 (0.229)	Data 0.014 (0.173)	
[25/123]	Time 0.043 (0.221)	Data 0.007 (0.166)	
[26/123]	Time 0.036 (0.214)	Data 0.011 (0.160)	
[27/123]	Time 0.024 (0.207)	Data 0.011 (0.155)	
[28/123]	Time 0.051 (0.202)	Data 0.016 (0.150)	
[29/123]	Time 0.036 (0.196)	Data 0.001 (0.144)	
[30/123]	Time 0.014 (0.190)	Data 0.001 (0.140)	
[31/123]	Time 0.056 (0.186)	Data 0.006 (0.135)	
[32/123]	Time 0.015 (0.180)	Data 0.001 (0.131)	
[33/123]	Time 0.031 (0.176)	Data 0.001 (0.127)	
[34/123]	Time 0.028 (0.171)	Data 0.001 (0.123)	
[35/123]	Time 0.022 (0.167)	Data 0.001 (0.120)	
[36/123]	Time 0.021 (0.163)	Data 0.008 (0.117)	
[37/123]	Time 0.157 (0.163)	Data 0.144 (0.118)	
[38/123]	Time 0.908 (0.182)	Data 0.893 (0.138)	
[39/123]	Time 0.015 (0.178)	Data 0.001 (0.134)	
[40/123]	Time 0.022 (0.174)	Data 0.007 (0.131)	
[41/123]	Time 0.046 (0.171)	Data 0.016 (0.128)	
[42/123]	Time 0.015 (0.167)	Data 0.000 (0.125)	
[43/123]	Time 0.043 (0.165)	Data 0.017 (0.123)	
[44/123]	Time 0.025 (0.161)	Data 0.010 (0.120)	
[45/123]	Time 0.029 (0.158)	Data 0.004 (0.118)	
[46/123]	Time 0.023 (0.155)	Data 0.008 (0.115)	
[47/123]	Time 0.033 (0.153)	Data 0.019 (0.113)	
[48/123]	Time 0.040 (0.151)	Data 0.018 (0.111)	
[49/123]	Time 0.025 (0.148)	Data 0.011 (0.109)	
[50/123]	Time 0.030 (0.146)	Data 0.008 (0.107)	
[51/123]	Time 0.022 (0.143)	Data 0.008 (0.105)	
[52/123]	Time 0.069 (0.142)	Data 0.021 (0.104)	
[53/123]	Time 0.541 (0.149)	Data 0.521 (0.112)	
[54/123]	Time 0.249 (0.151)	Data 0.235 (0.114)	
[55/123]	Time 0.029 (0.149)	Data 0.014 (0.112)	
[56/123]	Time 0.026 (0.147)	Data 0.012 (0.110)	
[57/123]	Time 0.026 (0.145)	Data 0.010 (0.109)	
[58/123]	Time 0.031 (0.143)	Data 0.017 (0.107)	
[59/123]	Time 0.042 (0.141)	Data 0.011 (0.105)	
[60/123]	Time 0.017 (0.139)	Data 0.003 (0.104)	
[61/123]	Time 0.029 (0.137)	Data 0.014 (0.102)	
[62/123]	Time 0.037 (0.135)	Data 0.014 (0.101)	
[63/123]	Time 0.031 (0.134)	Data 0.003 (0.099)	
[64/123]	Time 0.036 (0.132)	Data 0.001 (0.098)	
[65/123]	Time 0.022 (0.131)	Data 0.007 (0.096)	
[66/123]	Time 0.045 (0.129)	Data 0.018 (0.095)	
[67/123]	Time 0.015 (0.128)	Data 0.001 (0.094)	
[68/123]	Time 0.028 (0.126)	Data 0.006 (0.092)	
[69/123]	Time 0.384 (0.130)	Data 0.371 (0.096)	
[70/123]	Time 0.703 (0.138)	Data 0.689 (0.105)	
[71/123]	Time 0.036 (0.137)	Data 0.001 (0.103)	
[72/123]	Time 0.015 (0.135)	Data 0.001 (0.102)	
[73/123]	Time 0.036 (0.134)	Data 0.022 (0.101)	
[74/123]	Time 0.047 (0.132)	Data 0.014 (0.100)	
[75/123]	Time 0.025 (0.131)	Data 0.004 (0.098)	
[76/123]	Time 0.031 (0.130)	Data 0.001 (0.097)	
[77/123]	Time 0.017 (0.128)	Data 0.003 (0.096)	
[78/123]	Time 0.054 (0.127)	Data 0.016 (0.095)	
[79/123]	Time 0.015 (0.126)	Data 0.001 (0.094)	
[80/123]	Time 0.031 (0.125)	Data 0.017 (0.093)	
[81/123]	Time 0.020 (0.123)	Data 0.006 (0.092)	
[82/123]	Time 0.040 (0.122)	Data 0.026 (0.091)	
[83/123]	Time 0.033 (0.121)	Data 0.018 (0.090)	
[84/123]	Time 0.024 (0.120)	Data 0.010 (0.089)	
[85/123]	Time 0.259 (0.122)	Data 0.245 (0.091)	
[86/123]	Time 0.846 (0.130)	Data 0.831 (0.099)	
[87/123]	Time 0.044 (0.129)	Data 0.014 (0.098)	
[88/123]	Time 0.033 (0.128)	Data 0.001 (0.097)	
[89/123]	Time 0.016 (0.127)	Data 0.001 (0.096)	
[90/123]	Time 0.017 (0.126)	Data 0.001 (0.095)	
[91/123]	Time 0.015 (0.124)	Data 0.001 (0.094)	
[92/123]	Time 0.016 (0.123)	Data 0.001 (0.093)	
[93/123]	Time 0.023 (0.122)	Data 0.000 (0.092)	
[94/123]	Time 0.030 (0.121)	Data 0.000 (0.091)	
[95/123]	Time 0.014 (0.120)	Data 0.000 (0.090)	
[96/123]	Time 0.058 (0.119)	Data 0.001 (0.089)	
[97/123]	Time 0.014 (0.118)	Data 0.000 (0.088)	
[98/123]	Time 0.042 (0.117)	Data 0.000 (0.088)	
[99/123]	Time 0.014 (0.116)	Data 0.000 (0.087)	
[100/123]	Time 0.046 (0.116)	Data 0.000 (0.086)	
[101/123]	Time 0.057 (0.115)	Data 0.030 (0.085)	
[102/123]	Time 0.847 (0.122)	Data 0.834 (0.093)	
[103/123]	Time 0.014 (0.121)	Data 0.000 (0.092)	
[104/123]	Time 0.013 (0.120)	Data 0.000 (0.091)	
[105/123]	Time 0.014 (0.119)	Data 0.000 (0.090)	
[106/123]	Time 0.013 (0.118)	Data 0.000 (0.089)	
[107/123]	Time 0.013 (0.117)	Data 0.000 (0.088)	
[108/123]	Time 0.013 (0.116)	Data 0.000 (0.087)	
[109/123]	Time 0.013 (0.115)	Data 0.000 (0.087)	
[110/123]	Time 0.013 (0.114)	Data 0.000 (0.086)	
[111/123]	Time 0.013 (0.113)	Data 0.000 (0.085)	
[112/123]	Time 0.013 (0.113)	Data 0.000 (0.084)	
[113/123]	Time 0.013 (0.112)	Data 0.000 (0.084)	
[114/123]	Time 0.013 (0.111)	Data 0.000 (0.083)	
[115/123]	Time 0.013 (0.110)	Data 0.000 (0.082)	
[116/123]	Time 0.013 (0.109)	Data 0.000 (0.081)	
[117/123]	Time 0.013 (0.108)	Data 0.000 (0.081)	
[118/123]	Time 0.288 (0.110)	Data 0.275 (0.082)	
[119/123]	Time 0.012 (0.109)	Data 0.000 (0.082)	
[120/123]	Time 0.012 (0.108)	Data 0.000 (0.081)	
[121/123]	Time 0.012 (0.107)	Data 0.000 (0.080)	
[122/123]	Time 0.012 (0.107)	Data 0.000 (0.080)	
[123/123]	Time 0.012 (0.106)	Data 0.000 (0.079)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.01', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.01, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=64, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.01/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.01/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.439 (4.439)	Data 3.825 (3.825)	
[2/123]	Time 0.020 (2.229)	Data 0.000 (1.913)	
[3/123]	Time 0.017 (1.492)	Data 0.000 (1.275)	
[4/123]	Time 0.017 (1.123)	Data 0.000 (0.956)	
[5/123]	Time 0.018 (0.902)	Data 0.000 (0.765)	
[6/123]	Time 0.018 (0.755)	Data 0.001 (0.638)	
[7/123]	Time 0.018 (0.650)	Data 0.001 (0.547)	
[8/123]	Time 0.018 (0.571)	Data 0.000 (0.478)	
[9/123]	Time 0.021 (0.510)	Data 0.001 (0.425)	
[10/123]	Time 0.033 (0.462)	Data 0.001 (0.383)	
[11/123]	Time 0.038 (0.423)	Data 0.009 (0.349)	
[12/123]	Time 0.043 (0.392)	Data 0.001 (0.320)	
[13/123]	Time 0.028 (0.364)	Data 0.001 (0.295)	
[14/123]	Time 0.050 (0.341)	Data 0.008 (0.275)	
[15/123]	Time 0.074 (0.323)	Data 0.013 (0.257)	
[16/123]	Time 0.061 (0.307)	Data 0.006 (0.242)	
[17/123]	Time 0.042 (0.291)	Data 0.001 (0.227)	
[18/123]	Time 0.052 (0.278)	Data 0.004 (0.215)	
[19/123]	Time 0.081 (0.268)	Data 0.013 (0.204)	
[20/123]	Time 0.048 (0.257)	Data 0.012 (0.195)	
[21/123]	Time 0.054 (0.247)	Data 0.014 (0.186)	
[22/123]	Time 0.052 (0.238)	Data 0.012 (0.178)	
[23/123]	Time 0.046 (0.230)	Data 0.000 (0.170)	
[24/123]	Time 0.041 (0.222)	Data 0.001 (0.163)	
[25/123]	Time 0.064 (0.216)	Data 0.019 (0.158)	
[26/123]	Time 0.048 (0.209)	Data 0.006 (0.152)	
[27/123]	Time 0.045 (0.203)	Data 0.012 (0.147)	
[28/123]	Time 0.027 (0.197)	Data 0.001 (0.141)	
[29/123]	Time 0.030 (0.191)	Data 0.001 (0.137)	
[30/123]	Time 0.032 (0.186)	Data 0.001 (0.132)	
[31/123]	Time 0.051 (0.182)	Data 0.001 (0.128)	
[32/123]	Time 0.058 (0.178)	Data 0.012 (0.124)	
[33/123]	Time 0.037 (0.173)	Data 0.001 (0.120)	
[34/123]	Time 0.349 (0.179)	Data 0.300 (0.126)	
[35/123]	Time 0.092 (0.176)	Data 0.000 (0.122)	
[36/123]	Time 0.056 (0.173)	Data 0.000 (0.119)	
[37/123]	Time 0.086 (0.170)	Data 0.015 (0.116)	
[38/123]	Time 0.189 (0.171)	Data 0.148 (0.117)	
[39/123]	Time 0.061 (0.168)	Data 0.007 (0.114)	
[40/123]	Time 0.292 (0.171)	Data 0.236 (0.117)	
[41/123]	Time 0.041 (0.168)	Data 0.009 (0.114)	
[42/123]	Time 0.066 (0.166)	Data 0.014 (0.112)	
[43/123]	Time 0.060 (0.163)	Data 0.021 (0.110)	
[44/123]	Time 0.061 (0.161)	Data 0.006 (0.108)	
[45/123]	Time 0.055 (0.158)	Data 0.001 (0.105)	
[46/123]	Time 0.053 (0.156)	Data 0.011 (0.103)	
[47/123]	Time 0.054 (0.154)	Data 0.006 (0.101)	
[48/123]	Time 0.071 (0.152)	Data 0.004 (0.099)	
[49/123]	Time 0.043 (0.150)	Data 0.000 (0.097)	
[50/123]	Time 0.185 (0.151)	Data 0.147 (0.098)	
[51/123]	Time 0.065 (0.149)	Data 0.010 (0.096)	
[52/123]	Time 0.053 (0.147)	Data 0.000 (0.094)	
[53/123]	Time 0.281 (0.150)	Data 0.238 (0.097)	
[54/123]	Time 0.406 (0.154)	Data 0.363 (0.102)	
[55/123]	Time 0.060 (0.153)	Data 0.016 (0.101)	
[56/123]	Time 0.060 (0.151)	Data 0.019 (0.099)	
[57/123]	Time 0.080 (0.150)	Data 0.019 (0.098)	
[58/123]	Time 0.060 (0.148)	Data 0.001 (0.096)	
[59/123]	Time 0.034 (0.146)	Data 0.001 (0.094)	
[60/123]	Time 0.055 (0.145)	Data 0.014 (0.093)	
[61/123]	Time 0.073 (0.144)	Data 0.011 (0.092)	
[62/123]	Time 0.061 (0.142)	Data 0.001 (0.090)	
[63/123]	Time 0.049 (0.141)	Data 0.014 (0.089)	
[64/123]	Time 0.048 (0.139)	Data 0.009 (0.088)	
[65/123]	Time 0.054 (0.138)	Data 0.008 (0.087)	
[66/123]	Time 0.052 (0.137)	Data 0.010 (0.085)	
[67/123]	Time 0.045 (0.135)	Data 0.014 (0.084)	
[68/123]	Time 0.041 (0.134)	Data 0.001 (0.083)	
[69/123]	Time 0.304 (0.136)	Data 0.236 (0.085)	
[70/123]	Time 0.356 (0.140)	Data 0.329 (0.089)	
[71/123]	Time 0.082 (0.139)	Data 0.000 (0.088)	
[72/123]	Time 0.035 (0.137)	Data 0.010 (0.086)	
[73/123]	Time 0.034 (0.136)	Data 0.001 (0.085)	
[74/123]	Time 0.057 (0.135)	Data 0.001 (0.084)	
[75/123]	Time 0.053 (0.134)	Data 0.015 (0.083)	
[76/123]	Time 0.051 (0.133)	Data 0.001 (0.082)	
[77/123]	Time 0.044 (0.132)	Data 0.001 (0.081)	
[78/123]	Time 0.068 (0.131)	Data 0.018 (0.080)	
[79/123]	Time 0.084 (0.130)	Data 0.001 (0.079)	
[80/123]	Time 0.047 (0.129)	Data 0.001 (0.078)	
[81/123]	Time 0.049 (0.128)	Data 0.013 (0.078)	
[82/123]	Time 0.035 (0.127)	Data 0.001 (0.077)	
[83/123]	Time 0.204 (0.128)	Data 0.160 (0.078)	
[84/123]	Time 0.064 (0.127)	Data 0.006 (0.077)	
[85/123]	Time 0.114 (0.127)	Data 0.070 (0.077)	
[86/123]	Time 0.417 (0.130)	Data 0.358 (0.080)	
[87/123]	Time 0.050 (0.129)	Data 0.007 (0.079)	
[88/123]	Time 0.079 (0.129)	Data 0.005 (0.078)	
[89/123]	Time 0.060 (0.128)	Data 0.006 (0.077)	
[90/123]	Time 0.062 (0.127)	Data 0.001 (0.077)	
[91/123]	Time 0.051 (0.126)	Data 0.001 (0.076)	
[92/123]	Time 0.038 (0.126)	Data 0.001 (0.075)	
[93/123]	Time 0.064 (0.125)	Data 0.000 (0.074)	
[94/123]	Time 0.050 (0.124)	Data 0.001 (0.073)	
[95/123]	Time 0.058 (0.123)	Data 0.000 (0.073)	
[96/123]	Time 0.052 (0.123)	Data 0.000 (0.072)	
[97/123]	Time 0.044 (0.122)	Data 0.000 (0.071)	
[98/123]	Time 0.058 (0.121)	Data 0.000 (0.070)	
[99/123]	Time 0.516 (0.125)	Data 0.466 (0.074)	
[100/123]	Time 0.066 (0.125)	Data 0.000 (0.074)	
[101/123]	Time 0.052 (0.124)	Data 0.000 (0.073)	
[102/123]	Time 0.028 (0.123)	Data 0.001 (0.072)	
[103/123]	Time 0.027 (0.122)	Data 0.001 (0.072)	
[104/123]	Time 0.027 (0.121)	Data 0.001 (0.071)	
[105/123]	Time 0.025 (0.120)	Data 0.000 (0.070)	
[106/123]	Time 0.021 (0.119)	Data 0.001 (0.069)	
[107/123]	Time 0.028 (0.118)	Data 0.000 (0.069)	
[108/123]	Time 0.028 (0.117)	Data 0.000 (0.068)	
[109/123]	Time 0.023 (0.117)	Data 0.001 (0.068)	
[110/123]	Time 0.017 (0.116)	Data 0.000 (0.067)	
[111/123]	Time 0.018 (0.115)	Data 0.002 (0.066)	
[112/123]	Time 0.017 (0.114)	Data 0.000 (0.066)	
[113/123]	Time 0.017 (0.113)	Data 0.000 (0.065)	
[114/123]	Time 0.064 (0.113)	Data 0.048 (0.065)	
[115/123]	Time 0.156 (0.113)	Data 0.139 (0.066)	
[116/123]	Time 0.016 (0.112)	Data 0.000 (0.065)	
[117/123]	Time 0.016 (0.111)	Data 0.000 (0.065)	
[118/123]	Time 0.101 (0.111)	Data 0.085 (0.065)	
[119/123]	Time 0.016 (0.111)	Data 0.000 (0.064)	
[120/123]	Time 0.016 (0.110)	Data 0.000 (0.064)	
[121/123]	Time 0.016 (0.109)	Data 0.000 (0.063)	
[122/123]	Time 0.016 (0.108)	Data 0.000 (0.063)	
[123/123]	Time 0.016 (0.107)	Data 0.000 (0.062)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.001', store_name='ucf101_mobilenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.001, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=64, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.001/ucf101_mobilenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='mobilenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='mobilenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  879486
DataParallel(
  (module): MobileNet(
    (features): Sequential(
      (0): Sequential(
        (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Block(
        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Block(
        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)
        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): Block(
        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (6): Block(
        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (7): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (8): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (9): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (10): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (11): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (12): Block(
        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (13): Block(
        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=512, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/result_mobilenet_bs64_lr0.001/ucf101_mobilenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.462 (4.462)	Data 3.690 (3.690)	
[2/123]	Time 0.014 (2.238)	Data 0.000 (1.845)	
[3/123]	Time 0.014 (1.497)	Data 0.000 (1.230)	
[4/123]	Time 0.014 (1.126)	Data 0.000 (0.923)	
[5/123]	Time 0.014 (0.904)	Data 0.001 (0.738)	
[6/123]	Time 0.014 (0.755)	Data 0.001 (0.615)	
[7/123]	Time 0.014 (0.649)	Data 0.000 (0.527)	
[8/123]	Time 0.018 (0.571)	Data 0.003 (0.462)	
[9/123]	Time 0.015 (0.509)	Data 0.001 (0.411)	
[10/123]	Time 0.015 (0.459)	Data 0.001 (0.370)	
[11/123]	Time 0.016 (0.419)	Data 0.001 (0.336)	
[12/123]	Time 0.025 (0.386)	Data 0.001 (0.308)	
[13/123]	Time 0.030 (0.359)	Data 0.010 (0.285)	
[14/123]	Time 0.016 (0.334)	Data 0.001 (0.265)	
[15/123]	Time 0.032 (0.314)	Data 0.005 (0.248)	
[16/123]	Time 0.023 (0.296)	Data 0.008 (0.233)	
[17/123]	Time 0.042 (0.281)	Data 0.013 (0.220)	
[18/123]	Time 0.015 (0.266)	Data 0.001 (0.208)	
[19/123]	Time 0.252 (0.265)	Data 0.238 (0.209)	
[20/123]	Time 0.027 (0.254)	Data 0.013 (0.199)	
[21/123]	Time 0.020 (0.242)	Data 0.006 (0.190)	
[22/123]	Time 0.040 (0.233)	Data 0.026 (0.183)	
[23/123]	Time 0.238 (0.233)	Data 0.210 (0.184)	
[24/123]	Time 0.014 (0.224)	Data 0.001 (0.176)	
[25/123]	Time 0.030 (0.217)	Data 0.001 (0.169)	
[26/123]	Time 0.014 (0.209)	Data 0.001 (0.163)	
[27/123]	Time 0.014 (0.202)	Data 0.001 (0.157)	
[28/123]	Time 0.014 (0.195)	Data 0.001 (0.151)	
[29/123]	Time 0.014 (0.189)	Data 0.001 (0.146)	
[30/123]	Time 0.014 (0.183)	Data 0.001 (0.141)	
[31/123]	Time 0.014 (0.177)	Data 0.001 (0.137)	
[32/123]	Time 0.028 (0.173)	Data 0.014 (0.133)	
[33/123]	Time 0.028 (0.168)	Data 0.014 (0.129)	
[34/123]	Time 0.683 (0.183)	Data 0.669 (0.145)	
[35/123]	Time 0.015 (0.179)	Data 0.001 (0.141)	
[36/123]	Time 0.046 (0.175)	Data 0.001 (0.137)	
[37/123]	Time 0.036 (0.171)	Data 0.007 (0.134)	
[38/123]	Time 0.014 (0.167)	Data 0.001 (0.130)	
[39/123]	Time 0.098 (0.165)	Data 0.076 (0.129)	
[40/123]	Time 0.025 (0.162)	Data 0.011 (0.126)	
[41/123]	Time 0.028 (0.158)	Data 0.014 (0.123)	
[42/123]	Time 0.041 (0.156)	Data 0.012 (0.120)	
[43/123]	Time 0.088 (0.154)	Data 0.074 (0.119)	
[44/123]	Time 0.029 (0.151)	Data 0.011 (0.117)	
[45/123]	Time 0.111 (0.150)	Data 0.098 (0.116)	
[46/123]	Time 0.035 (0.148)	Data 0.013 (0.114)	
[47/123]	Time 0.030 (0.145)	Data 0.014 (0.112)	
[48/123]	Time 0.024 (0.143)	Data 0.001 (0.110)	
[49/123]	Time 0.030 (0.141)	Data 0.014 (0.108)	
[50/123]	Time 1.463 (0.167)	Data 1.449 (0.135)	
[51/123]	Time 0.020 (0.164)	Data 0.001 (0.132)	
[52/123]	Time 0.027 (0.161)	Data 0.009 (0.130)	
[53/123]	Time 0.028 (0.159)	Data 0.014 (0.127)	
[54/123]	Time 0.034 (0.157)	Data 0.005 (0.125)	
[55/123]	Time 0.036 (0.154)	Data 0.007 (0.123)	
[56/123]	Time 0.020 (0.152)	Data 0.001 (0.121)	
[57/123]	Time 0.030 (0.150)	Data 0.016 (0.119)	
[58/123]	Time 0.019 (0.148)	Data 0.004 (0.117)	
[59/123]	Time 0.031 (0.146)	Data 0.001 (0.115)	
[60/123]	Time 0.023 (0.144)	Data 0.008 (0.113)	
[61/123]	Time 0.034 (0.142)	Data 0.020 (0.112)	
[62/123]	Time 0.028 (0.140)	Data 0.014 (0.110)	
[63/123]	Time 0.047 (0.138)	Data 0.009 (0.109)	
[64/123]	Time 0.015 (0.137)	Data 0.000 (0.107)	
[65/123]	Time 0.031 (0.135)	Data 0.017 (0.105)	
[66/123]	Time 0.691 (0.143)	Data 0.678 (0.114)	
[67/123]	Time 0.024 (0.142)	Data 0.010 (0.113)	
[68/123]	Time 0.020 (0.140)	Data 0.006 (0.111)	
[69/123]	Time 0.040 (0.138)	Data 0.026 (0.110)	
[70/123]	Time 0.028 (0.137)	Data 0.014 (0.108)	
[71/123]	Time 0.032 (0.135)	Data 0.018 (0.107)	
[72/123]	Time 0.027 (0.134)	Data 0.001 (0.106)	
[73/123]	Time 0.031 (0.132)	Data 0.001 (0.104)	
[74/123]	Time 0.016 (0.131)	Data 0.001 (0.103)	
[75/123]	Time 0.045 (0.130)	Data 0.013 (0.102)	
[76/123]	Time 0.014 (0.128)	Data 0.001 (0.100)	
[77/123]	Time 0.031 (0.127)	Data 0.017 (0.099)	
[78/123]	Time 0.040 (0.126)	Data 0.026 (0.098)	
[79/123]	Time 0.029 (0.125)	Data 0.014 (0.097)	
[80/123]	Time 0.042 (0.124)	Data 0.014 (0.096)	
[81/123]	Time 0.014 (0.122)	Data 0.001 (0.095)	
[82/123]	Time 1.214 (0.135)	Data 1.200 (0.109)	
[83/123]	Time 0.035 (0.134)	Data 0.014 (0.107)	
[84/123]	Time 0.014 (0.133)	Data 0.001 (0.106)	
[85/123]	Time 0.047 (0.132)	Data 0.024 (0.105)	
[86/123]	Time 0.028 (0.131)	Data 0.001 (0.104)	
[87/123]	Time 0.028 (0.129)	Data 0.013 (0.103)	
[88/123]	Time 0.034 (0.128)	Data 0.016 (0.102)	
[89/123]	Time 0.020 (0.127)	Data 0.001 (0.101)	
[90/123]	Time 0.030 (0.126)	Data 0.016 (0.100)	
[91/123]	Time 0.024 (0.125)	Data 0.011 (0.099)	
[92/123]	Time 0.030 (0.124)	Data 0.000 (0.098)	
[93/123]	Time 0.029 (0.123)	Data 0.000 (0.097)	
[94/123]	Time 0.028 (0.122)	Data 0.001 (0.096)	
[95/123]	Time 0.029 (0.121)	Data 0.000 (0.095)	
[96/123]	Time 0.030 (0.120)	Data 0.000 (0.094)	
[97/123]	Time 0.014 (0.119)	Data 0.000 (0.093)	
[98/123]	Time 1.137 (0.129)	Data 1.124 (0.103)	
[99/123]	Time 0.013 (0.128)	Data 0.000 (0.102)	
[100/123]	Time 0.013 (0.127)	Data 0.000 (0.101)	
[101/123]	Time 0.016 (0.126)	Data 0.000 (0.100)	
[102/123]	Time 0.013 (0.125)	Data 0.000 (0.099)	
[103/123]	Time 0.013 (0.124)	Data 0.000 (0.098)	
[104/123]	Time 0.012 (0.123)	Data 0.000 (0.097)	
[105/123]	Time 0.012 (0.122)	Data 0.000 (0.096)	
[106/123]	Time 0.012 (0.120)	Data 0.000 (0.095)	
[107/123]	Time 0.012 (0.119)	Data 0.000 (0.095)	
[108/123]	Time 0.012 (0.118)	Data 0.000 (0.094)	
[109/123]	Time 0.012 (0.118)	Data 0.000 (0.093)	
[110/123]	Time 0.012 (0.117)	Data 0.000 (0.092)	
[111/123]	Time 0.012 (0.116)	Data 0.000 (0.091)	
[112/123]	Time 0.012 (0.115)	Data 0.000 (0.090)	
[113/123]	Time 0.012 (0.114)	Data 0.000 (0.090)	
[114/123]	Time 0.084 (0.114)	Data 0.071 (0.089)	
[115/123]	Time 0.012 (0.113)	Data 0.000 (0.089)	
[116/123]	Time 0.012 (0.112)	Data 0.000 (0.088)	
[117/123]	Time 0.012 (0.111)	Data 0.000 (0.087)	
[118/123]	Time 0.012 (0.110)	Data 0.000 (0.086)	
[119/123]	Time 0.012 (0.109)	Data 0.000 (0.086)	
[120/123]	Time 0.012 (0.108)	Data 0.000 (0.085)	
[121/123]	Time 0.012 (0.108)	Data 0.000 (0.084)	
[122/123]	Time 0.012 (0.107)	Data 0.000 (0.084)	
[123/123]	Time 0.012 (0.106)	Data 0.000 (0.083)	
Namespace(root_path='/home/matthew/', video_path='/home/matthew/Thesis/FSL105_jpg_30', annotation_path='/home/matthew/Thesis/FSL105_anno_30/ucf101_01.json', result_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.001', store_name='ucf101_shufflenet_0.5x_RGB_16', modality='RGB', dataset='ucf101', n_classes=30, n_finetune_classes=400, sample_size=112, sample_duration=16, downsample=2, initial_scale=1.0, n_scales=5, scale_step=0.84089641525, train_crop='center', learning_rate=0.001, lr_steps=[40, 55, 65, 70, 200, 250], momentum=0.9, dampening=0.9, weight_decay=0.001, mean_dataset='activitynet', no_mean_norm=False, std_norm=False, nesterov=False, optimizer='sgd', lr_patience=10, batch_size=64, n_epochs=500, begin_epoch=1, n_val_samples=1, resume_path='/home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.001/ucf101_shufflenet_0.5x_RGB_16_best.pth', pretrain_path='', ft_portion='complete', no_train=True, no_val=True, test=True, test_subset='val', scale_in_test=1.0, crop_position_in_test='c', no_softmax_in_test=False, no_cuda=False, n_threads=16, checkpoint=1, no_hflip=False, norm_value=1, model='shufflenet', version=1.1, model_depth=18, resnet_shortcut='B', wide_resnet_k=2, resnext_cardinality=32, groups=3, width_mult=0.5, manual_seed=1, scales=[1.0, 0.84089641525, 0.7071067811803005, 0.5946035574934808, 0.4999999999911653], arch='shufflenet', mean=[114.7748, 107.7354, 99.475], std=[38.7568578, 37.88248729, 40.02898126])
Total number of trainable parameters:  271602
DataParallel(
  (module): ShuffleNet(
    (conv1): Sequential(
      (0): Conv3d(3, 12, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)
      (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(12, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(120, 30, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(30, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=30, bias=False)
        (bn2): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(30, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(120, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv3d(240, 60, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(60, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=60, bias=False)
        (bn2): BatchNorm3d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(60, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(240, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (shortcut): AvgPool3d(kernel_size=(2, 3, 3), stride=2, padding=(0, 1, 1))
      )
      (1): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(480, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (bn2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(120, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), groups=3, bias=False)
        (bn3): BatchNorm3d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=480, out_features=30, bias=True)
    )
  )
)
loading checkpoint /home/matthew/Efficient-3DCNNs_epoch500/results_shufflenet_bs64_lr0.001/ucf101_shufflenet_0.5x_RGB_16_best.pth
run
dataset loading [0/136]
/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthew/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/matthew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
test
[1/123]	Time 4.515 (4.515)	Data 3.824 (3.824)	
[2/123]	Time 0.020 (2.267)	Data 0.000 (1.912)	
[3/123]	Time 0.018 (1.517)	Data 0.000 (1.275)	
[4/123]	Time 0.018 (1.143)	Data 0.000 (0.956)	
[5/123]	Time 0.019 (0.918)	Data 0.001 (0.765)	
[6/123]	Time 0.018 (0.768)	Data 0.000 (0.638)	
[7/123]	Time 0.018 (0.661)	Data 0.001 (0.547)	
[8/123]	Time 0.018 (0.580)	Data 0.001 (0.478)	
[9/123]	Time 0.024 (0.519)	Data 0.000 (0.425)	
[10/123]	Time 0.022 (0.469)	Data 0.001 (0.383)	
[11/123]	Time 0.028 (0.429)	Data 0.001 (0.348)	
[12/123]	Time 0.039 (0.396)	Data 0.001 (0.319)	
[13/123]	Time 0.047 (0.369)	Data 0.001 (0.295)	
[14/123]	Time 0.086 (0.349)	Data 0.015 (0.275)	
[15/123]	Time 0.040 (0.329)	Data 0.001 (0.256)	
[16/123]	Time 0.055 (0.312)	Data 0.010 (0.241)	
[17/123]	Time 0.054 (0.296)	Data 0.005 (0.227)	
[18/123]	Time 0.040 (0.282)	Data 0.001 (0.215)	
[19/123]	Time 0.051 (0.270)	Data 0.016 (0.204)	
[20/123]	Time 0.051 (0.259)	Data 0.010 (0.194)	
[21/123]	Time 0.063 (0.250)	Data 0.005 (0.185)	
[22/123]	Time 0.038 (0.240)	Data 0.000 (0.177)	
[23/123]	Time 0.087 (0.233)	Data 0.022 (0.170)	
[24/123]	Time 0.067 (0.226)	Data 0.006 (0.163)	
[25/123]	Time 0.036 (0.219)	Data 0.001 (0.157)	
[26/123]	Time 0.043 (0.212)	Data 0.001 (0.151)	
[27/123]	Time 0.057 (0.206)	Data 0.016 (0.146)	
[28/123]	Time 0.060 (0.201)	Data 0.015 (0.141)	
[29/123]	Time 0.048 (0.196)	Data 0.006 (0.137)	
[30/123]	Time 0.074 (0.192)	Data 0.015 (0.133)	
[31/123]	Time 0.037 (0.187)	Data 0.001 (0.128)	
[32/123]	Time 0.077 (0.183)	Data 0.023 (0.125)	
[33/123]	Time 0.089 (0.180)	Data 0.001 (0.121)	
[34/123]	Time 0.048 (0.177)	Data 0.007 (0.118)	
[35/123]	Time 0.059 (0.173)	Data 0.022 (0.115)	
[36/123]	Time 0.223 (0.175)	Data 0.178 (0.117)	
[37/123]	Time 0.262 (0.177)	Data 0.238 (0.120)	
[38/123]	Time 0.052 (0.174)	Data 0.001 (0.117)	
[39/123]	Time 0.219 (0.175)	Data 0.177 (0.119)	
[40/123]	Time 0.058 (0.172)	Data 0.012 (0.116)	
[41/123]	Time 0.073 (0.169)	Data 0.012 (0.113)	
[42/123]	Time 0.043 (0.166)	Data 0.001 (0.111)	
[43/123]	Time 0.037 (0.163)	Data 0.013 (0.108)	
[44/123]	Time 0.031 (0.160)	Data 0.001 (0.106)	
[45/123]	Time 0.047 (0.158)	Data 0.006 (0.104)	
[46/123]	Time 0.071 (0.156)	Data 0.015 (0.102)	
[47/123]	Time 0.036 (0.153)	Data 0.001 (0.100)	
[48/123]	Time 0.035 (0.151)	Data 0.001 (0.098)	
[49/123]	Time 0.077 (0.150)	Data 0.011 (0.096)	
[50/123]	Time 0.056 (0.148)	Data 0.001 (0.094)	
[51/123]	Time 0.393 (0.152)	Data 0.349 (0.099)	
[52/123]	Time 0.050 (0.150)	Data 0.006 (0.097)	
[53/123]	Time 0.056 (0.149)	Data 0.016 (0.096)	
[54/123]	Time 0.065 (0.147)	Data 0.001 (0.094)	
[55/123]	Time 0.318 (0.150)	Data 0.291 (0.097)	
[56/123]	Time 0.052 (0.148)	Data 0.001 (0.096)	
[57/123]	Time 0.045 (0.147)	Data 0.017 (0.094)	
[58/123]	Time 0.079 (0.146)	Data 0.011 (0.093)	
[59/123]	Time 0.042 (0.144)	Data 0.006 (0.091)	
[60/123]	Time 0.055 (0.142)	Data 0.001 (0.090)	
[61/123]	Time 0.055 (0.141)	Data 0.001 (0.088)	
[62/123]	Time 0.039 (0.139)	Data 0.001 (0.087)	
[63/123]	Time 0.043 (0.138)	Data 0.012 (0.086)	
[64/123]	Time 0.055 (0.136)	Data 0.014 (0.085)	
[65/123]	Time 0.078 (0.136)	Data 0.011 (0.084)	
[66/123]	Time 0.035 (0.134)	Data 0.001 (0.082)	
[67/123]	Time 0.534 (0.140)	Data 0.494 (0.089)	
[68/123]	Time 0.071 (0.139)	Data 0.006 (0.087)	
[69/123]	Time 0.056 (0.138)	Data 0.015 (0.086)	
[70/123]	Time 0.064 (0.137)	Data 0.012 (0.085)	
[71/123]	Time 0.431 (0.141)	Data 0.392 (0.090)	
[72/123]	Time 0.054 (0.140)	Data 0.001 (0.088)	
[73/123]	Time 0.059 (0.139)	Data 0.001 (0.087)	
[74/123]	Time 0.054 (0.137)	Data 0.012 (0.086)	
[75/123]	Time 0.049 (0.136)	Data 0.006 (0.085)	
[76/123]	Time 0.062 (0.135)	Data 0.033 (0.084)	
[77/123]	Time 0.061 (0.134)	Data 0.022 (0.084)	
[78/123]	Time 0.055 (0.133)	Data 0.013 (0.083)	
[79/123]	Time 0.041 (0.132)	Data 0.001 (0.082)	
[80/123]	Time 0.061 (0.131)	Data 0.006 (0.081)	
[81/123]	Time 0.057 (0.130)	Data 0.016 (0.080)	
[82/123]	Time 0.057 (0.129)	Data 0.001 (0.079)	
[83/123]	Time 0.242 (0.131)	Data 0.198 (0.080)	
[84/123]	Time 0.033 (0.130)	Data 0.006 (0.079)	
[85/123]	Time 0.023 (0.128)	Data 0.001 (0.078)	
[86/123]	Time 0.042 (0.127)	Data 0.012 (0.078)	
[87/123]	Time 0.686 (0.134)	Data 0.659 (0.084)	
[88/123]	Time 0.050 (0.133)	Data 0.015 (0.084)	
[89/123]	Time 0.050 (0.132)	Data 0.003 (0.083)	
[90/123]	Time 0.053 (0.131)	Data 0.011 (0.082)	
[91/123]	Time 0.055 (0.130)	Data 0.014 (0.081)	
[92/123]	Time 0.020 (0.129)	Data 0.001 (0.080)	
[93/123]	Time 0.026 (0.128)	Data 0.001 (0.079)	
[94/123]	Time 0.029 (0.127)	Data 0.001 (0.079)	
[95/123]	Time 0.032 (0.126)	Data 0.001 (0.078)	
[96/123]	Time 0.032 (0.125)	Data 0.001 (0.077)	
[97/123]	Time 0.060 (0.124)	Data 0.001 (0.076)	
[98/123]	Time 0.041 (0.123)	Data 0.000 (0.075)	
[99/123]	Time 0.267 (0.125)	Data 0.226 (0.077)	
[100/123]	Time 0.055 (0.124)	Data 0.000 (0.076)	
[101/123]	Time 0.068 (0.124)	Data 0.001 (0.075)	
[102/123]	Time 0.028 (0.123)	Data 0.001 (0.075)	
[103/123]	Time 0.332 (0.125)	Data 0.315 (0.077)	
[104/123]	Time 0.017 (0.124)	Data 0.000 (0.076)	
[105/123]	Time 0.017 (0.123)	Data 0.000 (0.076)	
[106/123]	Time 0.016 (0.122)	Data 0.000 (0.075)	
[107/123]	Time 0.016 (0.121)	Data 0.000 (0.074)	
[108/123]	Time 0.016 (0.120)	Data 0.000 (0.073)	
[109/123]	Time 0.016 (0.119)	Data 0.000 (0.073)	
[110/123]	Time 0.016 (0.118)	Data 0.000 (0.072)	
[111/123]	Time 0.016 (0.117)	Data 0.000 (0.072)	
[112/123]	Time 0.016 (0.116)	Data 0.000 (0.071)	
[113/123]	Time 0.016 (0.115)	Data 0.000 (0.070)	
[114/123]	Time 0.017 (0.114)	Data 0.000 (0.070)	
[115/123]	Time 0.016 (0.113)	Data 0.000 (0.069)	
[116/123]	Time 0.016 (0.112)	Data 0.000 (0.068)	
[117/123]	Time 0.016 (0.112)	Data 0.000 (0.068)	
[118/123]	Time 0.016 (0.111)	Data 0.000 (0.067)	
[119/123]	Time 0.203 (0.112)	Data 0.186 (0.068)	
[120/123]	Time 0.016 (0.111)	Data 0.000 (0.068)	
[121/123]	Time 0.016 (0.110)	Data 0.000 (0.067)	
[122/123]	Time 0.016 (0.109)	Data 0.000 (0.067)	
[123/123]	Time 0.016 (0.109)	Data 0.000 (0.066)	
end bs64
end all test

